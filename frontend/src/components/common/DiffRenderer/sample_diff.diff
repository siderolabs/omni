diff --git a/.github/workflows/ci.yaml b/.github/workflows/ci.yaml
index 5ec990b8..4c445064 100644
--- a/.github/workflows/ci.yaml
+++ b/.github/workflows/ci.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-27T13:47:31Z by kres f189649.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -57,7 +57,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -109,7 +109,7 @@ jobs:
           make omni
       - name: Login to registry
         if: github.event_name != 'pull_request'
-        uses: docker/login-action@5e57cd118135c172c3672efd75eb46360885c0ef # version: v3.6.0
+        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # version: v3.7.0
         with:
           password: ${{ secrets.GITHUB_TOKEN }}
           registry: ghcr.io
@@ -139,7 +139,7 @@ jobs:
           make integration-test
       - name: Login to registry
         if: github.event_name != 'pull_request'
-        uses: docker/login-action@5e57cd118135c172c3672efd75eb46360885c0ef # version: v3.6.0
+        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # version: v3.7.0
         with:
           password: ${{ secrets.GITHUB_TOKEN }}
           registry: ghcr.io
@@ -215,7 +215,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -284,7 +284,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -355,7 +355,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -424,7 +424,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -494,7 +494,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -563,7 +563,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -633,7 +633,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -701,7 +701,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -772,7 +772,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -841,7 +841,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -910,7 +910,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -979,7 +979,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1054,7 +1054,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1123,7 +1123,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1192,7 +1192,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1260,7 +1260,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1347,7 +1347,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1420,7 +1420,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -1473,7 +1473,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-backups-cron.yaml b/.github/workflows/e2e-backups-cron.yaml
index 82dd3b95..a6897327 100644
--- a/.github/workflows/e2e-backups-cron.yaml
+++ b/.github/workflows/e2e-backups-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-cluster-import-cron.yaml b/.github/workflows/e2e-cluster-import-cron.yaml
index d53d1f97..89a2ffb3 100644
--- a/.github/workflows/e2e-cluster-import-cron.yaml
+++ b/.github/workflows/e2e-cluster-import-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-forced-removal-cron.yaml b/.github/workflows/e2e-forced-removal-cron.yaml
index 022eb929..457158b1 100644
--- a/.github/workflows/e2e-forced-removal-cron.yaml
+++ b/.github/workflows/e2e-forced-removal-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-minor-talos-upgrade-cron.yaml b/.github/workflows/e2e-minor-talos-upgrade-cron.yaml
index b7b43c9e..a88e2755 100644
--- a/.github/workflows/e2e-minor-talos-upgrade-cron.yaml
+++ b/.github/workflows/e2e-minor-talos-upgrade-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-misc-upgrades-cron.yaml b/.github/workflows/e2e-misc-upgrades-cron.yaml
index de97f015..afd58407 100644
--- a/.github/workflows/e2e-misc-upgrades-cron.yaml
+++ b/.github/workflows/e2e-misc-upgrades-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-17T11:22:27Z by kres 1ffefb6.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-omni-upgrade-cron.yaml b/.github/workflows/e2e-omni-upgrade-cron.yaml
index f772ac5d..396c4ed7 100644
--- a/.github/workflows/e2e-omni-upgrade-cron.yaml
+++ b/.github/workflows/e2e-omni-upgrade-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-rotate-ca-cron.yaml b/.github/workflows/e2e-rotate-ca-cron.yaml
index 6b618211..ee8e4d6d 100644
--- a/.github/workflows/e2e-rotate-ca-cron.yaml
+++ b/.github/workflows/e2e-rotate-ca-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-19T09:37:12Z by kres 1ffefb6.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-scaling-cron.yaml b/.github/workflows/e2e-scaling-cron.yaml
index 3964b491..61e9c0cc 100644
--- a/.github/workflows/e2e-scaling-cron.yaml
+++ b/.github/workflows/e2e-scaling-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-short-cron.yaml b/.github/workflows/e2e-short-cron.yaml
index 8ffa468e..792bc6da 100644
--- a/.github/workflows/e2e-short-cron.yaml
+++ b/.github/workflows/e2e-short-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-short-secureboot-cron.yaml b/.github/workflows/e2e-short-secureboot-cron.yaml
index 971b4c44..ef7c387e 100644
--- a/.github/workflows/e2e-short-secureboot-cron.yaml
+++ b/.github/workflows/e2e-short-secureboot-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-templates-cron.yaml b/.github/workflows/e2e-templates-cron.yaml
index b78c94bd..048c2e4d 100644
--- a/.github/workflows/e2e-templates-cron.yaml
+++ b/.github/workflows/e2e-templates-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-upgrades-cron.yaml b/.github/workflows/e2e-upgrades-cron.yaml
index 7a2f105d..bb2122b5 100644
--- a/.github/workflows/e2e-upgrades-cron.yaml
+++ b/.github/workflows/e2e-upgrades-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-17T11:22:16Z by kres 1ffefb6.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/e2e-workload-proxy-cron.yaml b/.github/workflows/e2e-workload-proxy-cron.yaml
index b3034fcd..0d78dbe6 100644
--- a/.github/workflows/e2e-workload-proxy-cron.yaml
+++ b/.github/workflows/e2e-workload-proxy-cron.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-14T13:36:25Z by kres 8b6181b-dirty.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: ${{ github.head_ref || github.run_id }}
@@ -40,7 +40,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
diff --git a/.github/workflows/helm.yaml b/.github/workflows/helm.yaml
index efa08c5a..8fecb311 100644
--- a/.github/workflows/helm.yaml
+++ b/.github/workflows/helm.yaml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-30T12:27:48Z by kres dc032d7.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 concurrency:
   group: helm-${{ github.head_ref || github.run_id }}
@@ -54,7 +54,7 @@ jobs:
           done
         continue-on-error: true
       - name: checkout
-        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # version: v6.0.1
+        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # version: v6.0.2
       - name: Unshallow
         run: |
           git fetch --prune --unshallow
@@ -72,7 +72,7 @@ jobs:
         uses: sigstore/cosign-installer@faadad0cce49287aee09b3a48701e75088a2c6ad # version: v4.0.0
       - name: Login to registry
         if: github.event_name != 'pull_request'
-        uses: docker/login-action@5e57cd118135c172c3672efd75eb46360885c0ef # version: v3.6.0
+        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # version: v3.7.0
         with:
           password: ${{ secrets.GITHUB_TOKEN }}
           registry: ghcr.io
diff --git a/.golangci.yml b/.golangci.yml
index 543c1953..cffab4fc 100644
--- a/.golangci.yml
+++ b/.golangci.yml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-16T11:36:20Z by kres 1ffefb6.
+# Generated on 2026-02-13T09:56:48Z by kres 6458cfd.
 
 version: "2"
 
@@ -55,6 +55,10 @@ linters:
     - embeddedstructfieldcheck # fighting in many places with fieldalignment
   # all available settings of specific linters
   settings:
+    staticcheck:
+      checks:
+        - all
+        - '-SA4006' # disable until https://github.com/golangci/golangci-lint/issues/6363 is resolved
     cyclop:
       # the maximal code complexity to report
       max-complexity: 20
diff --git a/.kres.yaml b/.kres.yaml
index 7be19f04..f5e7178f 100644
--- a/.kres.yaml
+++ b/.kres.yaml
@@ -626,10 +626,10 @@ spec:
     - source: https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/status.proto
       subdirectory: google/rpc/
       genGateway: true
-    - source: https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/common/common.proto
+    - source: https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/common/common.proto
       subdirectory: common/
       genGateway: true
-    - source: https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/machine/machine.proto
+    - source: https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/machine/machine.proto
       subdirectory: talos/machine/
       genGateway: true
     - source: https://raw.githubusercontent.com/cosi-project/specification/a25fac056c642b32468b030387ab94c17bc3ba1d/proto/v1alpha1/resource.proto
@@ -716,7 +716,7 @@ spec:
     - source: https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/status.proto
       subdirectory: google/rpc/
       genGateway: true
-    - source: https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/machine/machine.proto
+    - source: https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/machine/machine.proto
       subdirectory: talos/machine
       genGateway: true
     - source: https://raw.githubusercontent.com/protocolbuffers/protobuf/master/src/google/protobuf/any.proto
@@ -734,7 +734,7 @@ spec:
     - source: https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/code.proto
       subdirectory: google/rpc/
       genGateway: true
-    - source: https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/common/common.proto
+    - source: https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/common/common.proto
       subdirectory: common/
       genGateway: true
     - source: https://raw.githubusercontent.com/cosi-project/specification/a25fac056c642b32468b030387ab94c17bc3ba1d/proto/v1alpha1/resource.proto
diff --git a/Dockerfile b/Dockerfile
index e3f30573..c2d20093 100644
--- a/Dockerfile
+++ b/Dockerfile
@@ -1,8 +1,8 @@
-# syntax = docker/dockerfile-upstream:1.20.0-labs
+# syntax = docker/dockerfile-upstream:1.21.0-labs
 
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-02-10T13:20:54Z by kres f3ab59e.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 ARG JS_TOOLCHAIN
 ARG TOOLCHAIN=scratch
@@ -26,9 +26,9 @@ ENV GOPATH=/go
 ENV PATH=${PATH}:/usr/local/go/bin
 
 # runs markdownlint
-FROM docker.io/oven/bun:1.3.6-alpine AS lint-markdown
+FROM docker.io/oven/bun:1.3.9-alpine AS lint-markdown
 WORKDIR /src
-RUN bun i markdownlint-cli@0.47.0 sentences-per-line@0.5.0
+RUN bun i markdownlint-cli@0.47.0 sentences-per-line@0.5.1
 COPY .markdownlint.json .
 COPY ./docs ./docs
 COPY ./CHANGELOG.md ./CHANGELOG.md
@@ -53,8 +53,8 @@ ADD client/api/omni/specs/omni.proto /client/api/omni/specs/
 ADD client/api/omni/specs/siderolink.proto /client/api/omni/specs/
 ADD client/api/omni/specs/system.proto /client/api/omni/specs/
 ADD https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/status.proto /client/api/google/rpc/
-ADD https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/common/common.proto /client/api/common/
-ADD https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/machine/machine.proto /client/api/talos/machine/
+ADD https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/common/common.proto /client/api/common/
+ADD https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/machine/machine.proto /client/api/talos/machine/
 ADD https://raw.githubusercontent.com/cosi-project/specification/a25fac056c642b32468b030387ab94c17bc3ba1d/proto/v1alpha1/resource.proto /client/api/v1alpha1/
 
 # collects proto specs
@@ -72,13 +72,13 @@ ADD client/api/omni/specs/infra.proto /frontend/src/api/omni/specs/
 ADD client/api/omni/specs/virtual.proto /frontend/src/api/omni/specs/
 ADD client/api/omni/specs/ephemeral.proto /frontend/src/api/omni/specs/
 ADD https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/status.proto /frontend/src/api/google/rpc/
-ADD https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/machine/machine.proto /frontend/src/api/talos/machine/
+ADD https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/machine/machine.proto /frontend/src/api/talos/machine/
 ADD https://raw.githubusercontent.com/protocolbuffers/protobuf/master/src/google/protobuf/any.proto /frontend/src/api/google/protobuf/
 ADD https://raw.githubusercontent.com/protocolbuffers/protobuf/master/src/google/protobuf/duration.proto /frontend/src/api/google/protobuf/
 ADD https://raw.githubusercontent.com/protocolbuffers/protobuf/master/src/google/protobuf/empty.proto /frontend/src/api/google/protobuf/
 ADD https://raw.githubusercontent.com/protocolbuffers/protobuf/master/src/google/protobuf/timestamp.proto /frontend/src/api/google/protobuf/
 ADD https://raw.githubusercontent.com/googleapis/googleapis/master/google/rpc/code.proto /frontend/src/api/google/rpc/
-ADD https://raw.githubusercontent.com/siderolabs/talos/96e604874b17e7aa8b62bfb25737f349e539bc5a/api/common/common.proto /frontend/src/api/common/
+ADD https://raw.githubusercontent.com/siderolabs/talos/a16392559a488993c3e26810df57da3cae5c24c5/api/common/common.proto /frontend/src/api/common/
 ADD https://raw.githubusercontent.com/cosi-project/specification/a25fac056c642b32468b030387ab94c17bc3ba1d/proto/v1alpha1/resource.proto /frontend/src/api/v1alpha1/
 
 # base toolchain image
diff --git a/Makefile b/Makefile
index 68035a82..b74e6eca 100644
--- a/Makefile
+++ b/Makefile
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-30T12:27:48Z by kres dc032d7.
+# Generated on 2026-02-12T19:13:29Z by kres 84d286e.
 
 # common variables
 
@@ -22,15 +22,15 @@ PROTOBUF_GRPC_GATEWAY_TS_VERSION ?= 1.3.1
 TESTPKGS ?= ./...
 JS_BUILD_ARGS ?=
 PROTOBUF_GO_VERSION ?= 1.36.11
-GRPC_GO_VERSION ?= 1.6.0
-GRPC_GATEWAY_VERSION ?= 2.27.4
+GRPC_GO_VERSION ?= 1.6.1
+GRPC_GATEWAY_VERSION ?= 2.27.8
 VTPROTOBUF_VERSION ?= 0.6.0
-GOIMPORTS_VERSION ?= 0.41.0
+GOIMPORTS_VERSION ?= 0.42.0
 GOMOCK_VERSION ?= 0.6.0
 DEEPCOPY_VERSION ?= v0.5.8
-GOLANGCILINT_VERSION ?= v2.8.0
+GOLANGCILINT_VERSION ?= v2.9.0
 GOFUMPT_VERSION ?= v0.9.2
-GO_VERSION ?= 1.25.6
+GO_VERSION ?= 1.26.0
 GO_BUILDFLAGS ?=
 GO_BUILDTAGS ?= ,
 GO_LDFLAGS ?=
@@ -86,7 +86,7 @@ COMMON_ARGS += --build-arg=GOFUMPT_VERSION="$(GOFUMPT_VERSION)"
 COMMON_ARGS += --build-arg=TESTPKGS="$(TESTPKGS)"
 COMMON_ARGS += --build-arg=HELMDOCS_VERSION="$(HELMDOCS_VERSION)"
 JS_TOOLCHAIN ?= docker.io/node:24.13.0-alpine
-TOOLCHAIN ?= docker.io/golang:1.25-alpine
+TOOLCHAIN ?= docker.io/golang:1.26-alpine
 
 # extra variables
 
diff --git a/client/.golangci.yml b/client/.golangci.yml
index 543c1953..cffab4fc 100644
--- a/client/.golangci.yml
+++ b/client/.golangci.yml
@@ -1,6 +1,6 @@
 # THIS FILE WAS AUTOMATICALLY GENERATED, PLEASE DO NOT EDIT.
 #
-# Generated on 2026-01-16T11:36:20Z by kres 1ffefb6.
+# Generated on 2026-02-13T09:56:48Z by kres 6458cfd.
 
 version: "2"
 
@@ -55,6 +55,10 @@ linters:
     - embeddedstructfieldcheck # fighting in many places with fieldalignment
   # all available settings of specific linters
   settings:
+    staticcheck:
+      checks:
+        - all
+        - '-SA4006' # disable until https://github.com/golangci/golangci-lint/issues/6363 is resolved
     cyclop:
       # the maximal code complexity to report
       max-complexity: 20
diff --git a/client/api/common/common.proto b/client/api/common/common.proto
index 30a6b23e..1b155bd8 100644
--- a/client/api/common/common.proto
+++ b/client/api/common/common.proto
@@ -95,6 +95,13 @@ enum ContainerdNamespace {
   NS_CRI = 2;
 }
 
+message ContainerdInstance {
+  // Containerd instance to use.
+  ContainerDriver driver = 1;
+  // Containerd namespace to use.
+  ContainerdNamespace namespace = 2;
+}
+
 message URL {
   string full_path = 1;
 }
diff --git a/client/api/omni/management/management_grpc.pb.go b/client/api/omni/management/management_grpc.pb.go
index 0a19e308..c06b07fc 100644
--- a/client/api/omni/management/management_grpc.pb.go
+++ b/client/api/omni/management/management_grpc.pb.go
@@ -1,6 +1,6 @@
 // Code generated by protoc-gen-go-grpc. DO NOT EDIT.
 // versions:
-// - protoc-gen-go-grpc v1.6.0
+// - protoc-gen-go-grpc v1.6.1
 // - protoc             v6.31.1
 // source: omni/management/management.proto
 
diff --git a/client/api/omni/oidc/oidc_grpc.pb.go b/client/api/omni/oidc/oidc_grpc.pb.go
index af9e9cf9..6770c872 100644
--- a/client/api/omni/oidc/oidc_grpc.pb.go
+++ b/client/api/omni/oidc/oidc_grpc.pb.go
@@ -1,6 +1,6 @@
 // Code generated by protoc-gen-go-grpc. DO NOT EDIT.
 // versions:
-// - protoc-gen-go-grpc v1.6.0
+// - protoc-gen-go-grpc v1.6.1
 // - protoc             v6.31.1
 // source: omni/oidc/oidc.proto
 
diff --git a/client/api/omni/resources/resources_grpc.pb.go b/client/api/omni/resources/resources_grpc.pb.go
index 02ca506b..58aaf403 100644
--- a/client/api/omni/resources/resources_grpc.pb.go
+++ b/client/api/omni/resources/resources_grpc.pb.go
@@ -1,6 +1,6 @@
 // Code generated by protoc-gen-go-grpc. DO NOT EDIT.
 // versions:
-// - protoc-gen-go-grpc v1.6.0
+// - protoc-gen-go-grpc v1.6.1
 // - protoc             v6.31.1
 // source: omni/resources/resources.proto
 
diff --git a/client/api/talos/machine/machine.proto b/client/api/talos/machine/machine.proto
index d8abddbf..10d92e82 100644
--- a/client/api/talos/machine/machine.proto
+++ b/client/api/talos/machine/machine.proto
@@ -100,9 +100,19 @@ service MachineService {
   // MetaDelete deletes a META key.
   rpc MetaDelete(MetaDeleteRequest) returns (MetaDeleteResponse);
   // ImageList lists images in the CRI.
-  rpc ImageList(ImageListRequest) returns (stream ImageListResponse);
+  //
+  // Use ImageService List RPC instead.
+  rpc ImageList(ImageListRequest) returns (stream ImageListResponse) {
+    option (common.remove_deprecated_method) = "v1.18";
+    option deprecated = true;
+  }
   // ImagePull pulls an image into the CRI.
-  rpc ImagePull(ImagePullRequest) returns (ImagePullResponse);
+  //
+  // Use ImageService Pull RPC instead.
+  rpc ImagePull(ImagePullRequest) returns (ImagePullResponse) {
+    option (common.remove_deprecated_method) = "v1.18";
+    option deprecated = true;
+  }
 }
 
 // rpc applyConfiguration
diff --git a/client/go.mod b/client/go.mod
index 5cb17d16..40874533 100644
--- a/client/go.mod
+++ b/client/go.mod
@@ -1,45 +1,45 @@
 module github.com/siderolabs/omni/client
 
-go 1.25.6
+go 1.26.0
 
 require (
 	github.com/ProtonMail/gopenpgp/v2 v2.9.0
 	github.com/adrg/xdg v0.5.3
 	github.com/blang/semver/v4 v4.0.0
 	github.com/containers/image/v5 v5.36.2
-	github.com/cosi-project/runtime v1.13.0
+	github.com/cosi-project/runtime v1.14.0
 	github.com/dustin/go-humanize v1.0.1
 	github.com/fatih/color v1.18.0
 	github.com/gertd/go-pluralize v0.2.1
 	github.com/google/uuid v1.6.0
 	github.com/gosuri/uiprogress v0.0.1
-	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7
+	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8
 	github.com/hashicorp/go-multierror v1.1.1
-	github.com/hexops/gotextdiff v1.0.3
 	github.com/jxskiss/base62 v1.1.0
-	github.com/klauspost/compress v1.18.3
+	github.com/klauspost/compress v1.18.4
 	github.com/mattn/go-isatty v0.0.20
+	github.com/neticdk/go-stdlib v1.0.0
 	github.com/planetscale/vtprotobuf v0.6.1-0.20250313105119-ba97887b0a25
 	github.com/sergi/go-diff v1.4.0
 	github.com/siderolabs/gen v0.8.6
 	github.com/siderolabs/go-api-signature v0.3.12
 	github.com/siderolabs/go-kubeconfig v0.1.1
 	github.com/siderolabs/go-pointer v1.0.1
-	github.com/siderolabs/image-factory v1.0.0
+	github.com/siderolabs/image-factory v1.0.3
 	github.com/siderolabs/proto-codec v0.1.3
 	github.com/siderolabs/siderolink v0.3.15
 	github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3
-	github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3
+	github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48
 	github.com/spf13/cobra v1.10.2
 	github.com/stretchr/testify v1.11.1
 	github.com/xlab/treeprint v1.2.0
 	go.uber.org/zap v1.27.1
-	go.yaml.in/yaml/v4 v4.0.0-rc.3
+	go.yaml.in/yaml/v4 v4.0.0-rc.4
 	golang.org/x/sync v0.19.0
-	golang.org/x/term v0.39.0
-	google.golang.org/grpc v1.78.0
+	golang.org/x/term v0.40.0
+	google.golang.org/grpc v1.79.0
 	google.golang.org/protobuf v1.36.11
-	k8s.io/client-go v0.35.0
+	k8s.io/client-go v0.35.1
 )
 
 require (
@@ -62,8 +62,9 @@ require (
 	github.com/google/go-cmp v0.7.0 // indirect
 	github.com/gosuri/uilive v0.0.4 // indirect
 	github.com/hashicorp/errwrap v1.1.0 // indirect
+	github.com/hexops/gotextdiff v1.0.3 // indirect
 	github.com/inconshreveable/mousetrap v1.1.0 // indirect
-	github.com/jsimonetti/rtnetlink/v2 v2.1.0 // indirect
+	github.com/jsimonetti/rtnetlink/v2 v2.2.0 // indirect
 	github.com/json-iterator/go v1.1.12 // indirect
 	github.com/mattn/go-colorable v0.1.14 // indirect
 	github.com/mdlayher/ethtool v0.5.1 // indirect
@@ -91,27 +92,27 @@ require (
 	go.yaml.in/yaml/v2 v2.4.3 // indirect
 	go.yaml.in/yaml/v3 v3.0.4 // indirect
 	go4.org/netipx v0.0.0-20231129151722-fdeea329fbba // indirect
-	golang.org/x/crypto v0.47.0 // indirect
-	golang.org/x/exp v0.0.0-20260112195511-716be5621a96 // indirect
-	golang.org/x/net v0.49.0 // indirect
-	golang.org/x/oauth2 v0.34.0 // indirect
-	golang.org/x/sys v0.40.0 // indirect
-	golang.org/x/text v0.33.0 // indirect
+	golang.org/x/crypto v0.48.0 // indirect
+	golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a // indirect
+	golang.org/x/net v0.50.0 // indirect
+	golang.org/x/oauth2 v0.35.0 // indirect
+	golang.org/x/sys v0.41.0 // indirect
+	golang.org/x/text v0.34.0 // indirect
 	golang.org/x/time v0.14.0 // indirect
 	golang.zx2c4.com/wintun v0.0.0-20230126152724-0fa3db229ce2 // indirect
 	golang.zx2c4.com/wireguard v0.0.0-20250521234502-f333402bd9cb // indirect
 	golang.zx2c4.com/wireguard/wgctrl v0.0.0-20241231184526-a9ab2273dd10 // indirect
-	google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b // indirect
-	google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b // indirect
+	google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57 // indirect
+	google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57 // indirect
 	gopkg.in/inf.v0 v0.9.1 // indirect
 	gopkg.in/yaml.v2 v2.4.0 // indirect
 	gopkg.in/yaml.v3 v3.0.1 // indirect
-	k8s.io/apimachinery v0.35.0 // indirect
+	k8s.io/apimachinery v0.35.1 // indirect
 	k8s.io/klog/v2 v2.130.1 // indirect
 	k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4 // indirect
-	k8s.io/utils v0.0.0-20260108192941-914a6e750570 // indirect
+	k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2 // indirect
 	sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730 // indirect
 	sigs.k8s.io/randfill v1.0.0 // indirect
-	sigs.k8s.io/structured-merge-diff/v6 v6.3.1 // indirect
+	sigs.k8s.io/structured-merge-diff/v6 v6.3.2 // indirect
 	sigs.k8s.io/yaml v1.6.0 // indirect
 )
diff --git a/client/go.sum b/client/go.sum
index cd02ef86..8a9fcb3c 100644
--- a/client/go.sum
+++ b/client/go.sum
@@ -12,16 +12,18 @@ github.com/adrg/xdg v0.5.3 h1:xRnxJXne7+oWDatRhR1JLnvuccuIeCoBu2rtuLqQB78=
 github.com/adrg/xdg v0.5.3/go.mod h1:nlTsY+NNiCBGCK2tpm09vRqfVzrc2fLmXGpBLF0zlTQ=
 github.com/antlr4-go/antlr/v4 v4.13.1 h1:SqQKkuVZ+zWkMMNkjy5FZe5mr5WURWnlpmOuzYWrPrQ=
 github.com/antlr4-go/antlr/v4 v4.13.1/go.mod h1:GKmUxMtwp6ZgGwZSva4eWPC5mS6vUAmOABFgjdkM7Nw=
+github.com/blang/semver v3.5.1+incompatible h1:cQNTCjp13qL8KC3Nbxr/y2Bqb63oX6wdnnjpJbkM4JQ=
 github.com/blang/semver/v4 v4.0.0 h1:1PFHFE6yCCTv8C1TeyNNarDzntLi7wMI5i/pzqYIsAM=
 github.com/blang/semver/v4 v4.0.0/go.mod h1:IbckMUScFkM3pff0VJDNKRiT6TG/YpiHIM2yvyW5YoQ=
 github.com/brianvoe/gofakeit/v7 v7.7.3 h1:RWOATEGpJ5EVg2nN8nlaEyaV/aB4d6c3GqYrbqQekss=
 github.com/brianvoe/gofakeit/v7 v7.7.3/go.mod h1:QXuPeBw164PJCzCUZVmgpgHJ3Llj49jSLVkKPMtxtxA=
+github.com/cenkalti/backoff v2.2.1+incompatible h1:tNowT99t7UNflLxfYYSlKYsBpXdEet03Pg2g16Swow4=
 github.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=
 github.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=
 github.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=
 github.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=
-github.com/cilium/ebpf v0.19.0 h1:Ro/rE64RmFBeA9FGjcTc+KmCeY6jXmryu6FfnzPRIao=
-github.com/cilium/ebpf v0.19.0/go.mod h1:fLCgMo3l8tZmAdM3B2XqdFzXBpwkcSTroaVqN08OWVY=
+github.com/cilium/ebpf v0.20.0 h1:atwWj9d3NffHyPZzVlx3hmw1on5CLe9eljR8VuHTwhM=
+github.com/cilium/ebpf v0.20.0/go.mod h1:pzLjFymM+uZPLk/IXZUL63xdx5VXEo+enTzxkZXdycw=
 github.com/cloudflare/circl v1.6.3 h1:9GPOhQGF9MCYUeXyMYlqTR6a5gTrgR/fBLXvUgtVcg8=
 github.com/cloudflare/circl v1.6.3/go.mod h1:2eXP6Qfat4O/Yhh8BznvKnJ+uzEoTQ6jVKJRn81BiS4=
 github.com/containerd/go-cni v1.1.13 h1:eFSGOKlhoYNxpJ51KRIMHZNlg5UgocXEIEBGkY7Hnis=
@@ -32,8 +34,8 @@ github.com/containers/image/v5 v5.36.2 h1:GcxYQyAHRF/pLqR4p4RpvKllnNL8mOBn0eZnqJ
 github.com/containers/image/v5 v5.36.2/go.mod h1:b4GMKH2z/5t6/09utbse2ZiLK/c72GuGLFdp7K69eA4=
 github.com/containers/storage v1.59.1 h1:11Zu68MXsEQGBBd+GadPrHPpWeqjKS8hJDGiAHgIqDs=
 github.com/containers/storage v1.59.1/go.mod h1:KoAYHnAjP3/cTsRS+mmWZGkufSY2GACiKQ4V3ZLQnR0=
-github.com/cosi-project/runtime v1.13.0 h1:EKy/GwhVTgq131w0g3pbB0bTEf6FiZFjbK6go/I0pmE=
-github.com/cosi-project/runtime v1.13.0/go.mod h1:/9fspODJfZrO5dQatMRgN440K8DjWP1jFSgiLX+FmQc=
+github.com/cosi-project/runtime v1.14.0 h1:puGI7sssk1h2KScC4ETjC+M7nyN+0ur44bAuSLdY91A=
+github.com/cosi-project/runtime v1.14.0/go.mod h1:sd2+E6DjC/QjrnlEEglINDZ4FUW7cVDMB5aG98Dl3LA=
 github.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
 github.com/cpuguy83/go-md2man/v2 v2.0.7 h1:zbFlGlXEAKlwXpmvle3d8Oe3YnkKIK4xSRTd3sHPnBo=
 github.com/cpuguy83/go-md2man/v2 v2.0.7/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
@@ -108,8 +110,8 @@ github.com/gosuri/uilive v0.0.4 h1:hUEBpQDj8D8jXgtCdBu7sWsy5sbW/5GhuO8KBwJ2jyY=
 github.com/gosuri/uilive v0.0.4/go.mod h1:V/epo5LjjlDE5RJUcqx8dbw+zc93y5Ya3yg8tfZ74VI=
 github.com/gosuri/uiprogress v0.0.1 h1:0kpv/XY/qTmFWl/SkaJykZXrBBzwwadmW8fRb7RJSxw=
 github.com/gosuri/uiprogress v0.0.1/go.mod h1:C1RTYn4Sc7iEyf6j8ft5dyoZ4212h8G1ol9QQluh5+0=
-github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7 h1:X+2YciYSxvMQK0UZ7sg45ZVabVZBeBuvMkmuI2V3Fak=
-github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7/go.mod h1:lW34nIZuQ8UDPdkon5fmfp2l3+ZkQ2me/+oecHYLOII=
+github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8 h1:NpbJl/eVbvrGE0MJ6X16X9SAifesl6Fwxg/YmCvubRI=
+github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8/go.mod h1:mi7YA+gCzVem12exXy46ZespvGtX/lZmD/RLnQhVW7U=
 github.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
 github.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=
 github.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
@@ -119,14 +121,14 @@ github.com/hexops/gotextdiff v1.0.3 h1:gitA9+qJrrTCsiCl7+kh75nPqQt1cx4ZkudSTLoUq
 github.com/hexops/gotextdiff v1.0.3/go.mod h1:pSWU5MAI3yDq+fZBTazCSJysOMbxWL1BSow5/V2vxeg=
 github.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=
 github.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=
-github.com/jsimonetti/rtnetlink/v2 v2.1.0 h1:3sSPD0k+Qvia3wbv6kZXCN0Dlz6Swv7RHjvvonuOcKE=
-github.com/jsimonetti/rtnetlink/v2 v2.1.0/go.mod h1:hPPUTE+ekH3HD+zCEGAGLxzFY9HrJCyD1aN7JJ3SHIY=
+github.com/jsimonetti/rtnetlink/v2 v2.2.0 h1:/KfZ310gOAFrXXol5VwnFEt+ucldD/0dsSRZwpHCP9w=
+github.com/jsimonetti/rtnetlink/v2 v2.2.0/go.mod h1:lbjDHxC+5RJ08lzPeA90Ls2pEoId3F08MoEMlhfHxeI=
 github.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=
 github.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=
 github.com/jxskiss/base62 v1.1.0 h1:A5zbF8v8WXx2xixnAKD2w+abC+sIzYJX+nxmhA6HWFw=
 github.com/jxskiss/base62 v1.1.0/go.mod h1:HhWAlUXvxKThfOlZbcuFzsqwtF5TcqS9ru3y5GfjWAc=
-github.com/klauspost/compress v1.18.3 h1:9PJRvfbmTabkOX8moIpXPbMMbYN60bWImDDU7L+/6zw=
-github.com/klauspost/compress v1.18.3/go.mod h1:R0h/fSBs8DE4ENlcrlib3PsXS61voFxhIs2DeRhCvJ4=
+github.com/klauspost/compress v1.18.4 h1:RPhnKRAQ4Fh8zU2FY/6ZFDwTVTxgJ/EMydqSTzE9a2c=
+github.com/klauspost/compress v1.18.4/go.mod h1:R0h/fSBs8DE4ENlcrlib3PsXS61voFxhIs2DeRhCvJ4=
 github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
 github.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=
 github.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=
@@ -156,6 +158,8 @@ github.com/modern-go/reflect2 v1.0.3-0.20250322232337-35a7c28c31ee h1:W5t00kpgFd
 github.com/modern-go/reflect2 v1.0.3-0.20250322232337-35a7c28c31ee/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=
 github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 h1:C3w9PqII01/Oq1c1nUAm88MOHcQC9l5mIlSMApZMrHA=
 github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822/go.mod h1:+n7T8mK8HuQTcFwEeznm/DIxMOiR9yIdICNftLE1DvQ=
+github.com/neticdk/go-stdlib v1.0.0 h1:9QCpoMpO5dBJGHJhumZrHzfJyvpVBd2Gc7ODJujfpXY=
+github.com/neticdk/go-stdlib v1.0.0/go.mod h1:rch+DEB6VtR972ZPTY6A5OyLmCrp2YlXP0WGjuDDdcw=
 github.com/onsi/ginkgo/v2 v2.27.2 h1:LzwLj0b89qtIy6SSASkzlNvX6WktqurSHwkk2ipF/Ns=
 github.com/onsi/ginkgo/v2 v2.27.2/go.mod h1:ArE1D/XhNXBXCBkKOLkbsb2c81dQHCRcF5zwn/ykDRo=
 github.com/onsi/gomega v1.38.2 h1:eZCjf2xjZAqe+LeWvKb5weQ+NcPwX84kqJ0cZNxok2A=
@@ -200,8 +204,8 @@ github.com/siderolabs/go-pointer v1.0.1 h1:f7Yi4IK1jptS8yrT9GEbwhmGcVxvPQgBUG/we
 github.com/siderolabs/go-pointer v1.0.1/go.mod h1:C8Q/3pNHT4RE9e4rYR9PHeS6KPMlStRBgYrJQJNy/vA=
 github.com/siderolabs/go-retry v0.3.3 h1:zKV+S1vumtO72E6sYsLlmIdV/G/GcYSBLiEx/c9oCEg=
 github.com/siderolabs/go-retry v0.3.3/go.mod h1:Ff/VGc7v7un4uQg3DybgrmOWHEmJ8BzZds/XNn/BqMI=
-github.com/siderolabs/image-factory v1.0.0 h1:35d9XPQrphgKcKolqaRZft7mhVx9dkpdaMPbPvsQrBE=
-github.com/siderolabs/image-factory v1.0.0/go.mod h1:rRMN+e4W4RjZRf+bRdyyscp7VLbkhyPmo9WFXLGfKEo=
+github.com/siderolabs/image-factory v1.0.3 h1:qcivcfaTNSnLMKMWH82r8oEmxymz3fzqxefZbk5lKx8=
+github.com/siderolabs/image-factory v1.0.3/go.mod h1:7ydfVZ4cfMgTAdaPdeqCADKc280GRyUHSygKQAxSfgQ=
 github.com/siderolabs/net v0.4.0 h1:1bOgVay/ijPkJz4qct98nHsiB/ysLQU0KLoBC4qLm7I=
 github.com/siderolabs/net v0.4.0/go.mod h1:/ibG+Hm9HU27agp5r9Q3eZicEfjquzNzQNux5uEk0kM=
 github.com/siderolabs/proto-codec v0.1.3 h1:tRzt2Rlc84Uv+Lx6vV2VmFpgHSV1fUNq/7nTXU892dM=
@@ -212,8 +216,8 @@ github.com/siderolabs/siderolink v0.3.15 h1:WSsgKQGJY/ObIKjTcYYGEaGfRMyox+r/Ft+9
 github.com/siderolabs/siderolink v0.3.15/go.mod h1:iWdlsHji90zotgDg4+a2zJL2ZMNJckQ8/VwqR39ThBM=
 github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3 h1:SXKyyQ76pUSHDNfZkwfXFJjVEjxIgrLSHzoovZHq2lc=
 github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3/go.mod h1:qOz9COzDsTohBYUAS3GWJttiUe6qhABYvw4g7TvUxjU=
-github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3 h1:ejFpLb7XgRordk94Zn3KxC9dq1cj9oqxjceCU810xPQ=
-github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3/go.mod h1:QKitWcS6eF4RnOUK7mJZEUwUTVi34hNKw4t4BFNpCoM=
+github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48 h1:b7/G7JMBMoElNg4CZraLihAHa7WtiI1ZsUzvU446l9Y=
+github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48/go.mod h1:hUAVw/bOMv0jyyGpgxu6AcvSBUzGGylGF7baIwwR2uI=
 github.com/spf13/cobra v1.10.2 h1:DMTTonx5m65Ic0GOoRY2c16WCbHxOOw6xxezuLaBpcU=
 github.com/spf13/cobra v1.10.2/go.mod h1:7C1pvHqHw5A4vrJfjNwvOdzYu0Gml16OCs2GRiTUUS4=
 github.com/spf13/pflag v1.0.9/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=
@@ -242,8 +246,10 @@ go.opentelemetry.io/otel/metric v1.39.0 h1:d1UzonvEZriVfpNKEVmHXbdf909uGTOQjA0HF
 go.opentelemetry.io/otel/metric v1.39.0/go.mod h1:jrZSWL33sD7bBxg1xjrqyDjnuzTUB0x1nBERXd7Ftcs=
 go.opentelemetry.io/otel/sdk v1.38.0 h1:l48sr5YbNf2hpCUj/FoGhW9yDkl+Ma+LrVl8qaM5b+E=
 go.opentelemetry.io/otel/sdk v1.38.0/go.mod h1:ghmNdGlVemJI3+ZB5iDEuk4bWA3GkTpW+DOoZMYBVVg=
+go.opentelemetry.io/otel/sdk v1.39.0 h1:nMLYcjVsvdui1B/4FRkwjzoRVsMK8uL/cj0OyhKzt18=
 go.opentelemetry.io/otel/sdk/metric v1.38.0 h1:aSH66iL0aZqo//xXzQLYozmWrXxyFkBJ6qT5wthqPoM=
 go.opentelemetry.io/otel/sdk/metric v1.38.0/go.mod h1:dg9PBnW9XdQ1Hd6ZnRz689CbtrUp0wMMs9iPcgT9EZA=
+go.opentelemetry.io/otel/sdk/metric v1.39.0 h1:cXMVVFVgsIf2YL6QkRF4Urbr/aMInf+2WKg+sEJTtB8=
 go.opentelemetry.io/otel/trace v1.39.0 h1:2d2vfpEDmCJ5zVYz7ijaJdOF59xLomrvj7bjt6/qCJI=
 go.opentelemetry.io/otel/trace v1.39.0/go.mod h1:88w4/PnZSazkGzz/w84VHpQafiU4EtqqlVdxWy+rNOA=
 go.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=
@@ -256,28 +262,30 @@ go.yaml.in/yaml/v2 v2.4.3 h1:6gvOSjQoTB3vt1l+CU+tSyi/HOjfOjRLJ4YwYZGwRO0=
 go.yaml.in/yaml/v2 v2.4.3/go.mod h1:zSxWcmIDjOzPXpjlTTbAsKokqkDNAVtZO0WOMiT90s8=
 go.yaml.in/yaml/v3 v3.0.4 h1:tfq32ie2Jv2UxXFdLJdh3jXuOzWiL1fo0bu/FbuKpbc=
 go.yaml.in/yaml/v3 v3.0.4/go.mod h1:DhzuOOF2ATzADvBadXxruRBLzYTpT36CKvDb3+aBEFg=
-go.yaml.in/yaml/v4 v4.0.0-rc.3 h1:3h1fjsh1CTAPjW7q/EMe+C8shx5d8ctzZTrLcs/j8Go=
-go.yaml.in/yaml/v4 v4.0.0-rc.3/go.mod h1:aZqd9kCMsGL7AuUv/m/PvWLdg5sjJsZ4oHDEnfPPfY0=
+go.yaml.in/yaml/v4 v4.0.0-rc.4 h1:UP4+v6fFrBIb1l934bDl//mmnoIZEDK0idg1+AIvX5U=
+go.yaml.in/yaml/v4 v4.0.0-rc.4/go.mod h1:aZqd9kCMsGL7AuUv/m/PvWLdg5sjJsZ4oHDEnfPPfY0=
 go4.org/netipx v0.0.0-20231129151722-fdeea329fbba h1:0b9z3AuHCjxk0x/opv64kcgZLBseWJUpBw5I82+2U4M=
 go4.org/netipx v0.0.0-20231129151722-fdeea329fbba/go.mod h1:PLyyIXexvUFg3Owu6p/WfdlivPbZJsZdgWZlrGope/Y=
 golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=
 golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=
-golang.org/x/crypto v0.47.0 h1:V6e3FRj+n4dbpw86FJ8Fv7XVOql7TEwpHapKoMJ/GO8=
-golang.org/x/crypto v0.47.0/go.mod h1:ff3Y9VzzKbwSSEzWqJsJVBnWmRwRSHt/6Op5n9bQc4A=
-golang.org/x/exp v0.0.0-20260112195511-716be5621a96 h1:Z/6YuSHTLOHfNFdb8zVZomZr7cqNgTJvA8+Qz75D8gU=
-golang.org/x/exp v0.0.0-20260112195511-716be5621a96/go.mod h1:nzimsREAkjBCIEFtHiYkrJyT+2uy9YZJB7H1k68CXZU=
+golang.org/x/crypto v0.48.0 h1:/VRzVqiRSggnhY7gNRxPauEQ5Drw9haKdM0jqfcCFts=
+golang.org/x/crypto v0.48.0/go.mod h1:r0kV5h3qnFPlQnBSrULhlsRfryS2pmewsg+XfMgkVos=
+golang.org/x/exp v0.0.0-20260211191109-2735e65f0518 h1:2E1CW7v5QB+Wi3N+MXllOtVR6SFmI8iJM8EdzgxrgrU=
+golang.org/x/exp v0.0.0-20260211191109-2735e65f0518/go.mod h1:K79w1Vqn7PoiZn+TkNpx3BUWUQksGO3JcVX6qIjytmA=
+golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a h1:ovFr6Z0MNmU7nH8VaX5xqw+05ST2uO1exVfZPVqRC5o=
+golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a/go.mod h1:K79w1Vqn7PoiZn+TkNpx3BUWUQksGO3JcVX6qIjytmA=
 golang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=
 golang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=
-golang.org/x/mod v0.32.0 h1:9F4d3PHLljb6x//jOyokMv3eX+YDeepZSEo3mFJy93c=
-golang.org/x/mod v0.32.0/go.mod h1:SgipZ/3h2Ci89DlEtEXWUk/HteuRin+HHhN+WbNhguU=
+golang.org/x/mod v0.33.0 h1:tHFzIWbBifEmbwtGz65eaWyGiGZatSrT9prnU8DbVL8=
+golang.org/x/mod v0.33.0/go.mod h1:swjeQEj+6r7fODbD2cqrnje9PnziFuw4bmLbBZFrQ5w=
 golang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=
 golang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=
 golang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
 golang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=
-golang.org/x/net v0.49.0 h1:eeHFmOGUTtaaPSGNmjBKpbng9MulQsJURQUAfUwY++o=
-golang.org/x/net v0.49.0/go.mod h1:/ysNB2EvaqvesRkuLAyjI1ycPZlQHM3q01F02UY/MV8=
-golang.org/x/oauth2 v0.34.0 h1:hqK/t4AKgbqWkdkcAeI8XLmbK+4m4G5YeQRrmiotGlw=
-golang.org/x/oauth2 v0.34.0/go.mod h1:lzm5WQJQwKZ3nwavOZ3IS5Aulzxi68dUSgRHujetwEA=
+golang.org/x/net v0.50.0 h1:ucWh9eiCGyDR3vtzso0WMQinm2Dnt8cFMuQa9K33J60=
+golang.org/x/net v0.50.0/go.mod h1:UgoSli3F/pBgdJBHCTc+tp3gmrU4XswgGRgtnwWTfyM=
+golang.org/x/oauth2 v0.35.0 h1:Mv2mzuHuZuY2+bkyWXIHMfhNdJAdwW3FuWeCPYN5GVQ=
+golang.org/x/oauth2 v0.35.0/go.mod h1:lzm5WQJQwKZ3nwavOZ3IS5Aulzxi68dUSgRHujetwEA=
 golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
@@ -291,28 +299,28 @@ golang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBc
 golang.org/x/sys v0.1.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
 golang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
 golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.40.0 h1:DBZZqJ2Rkml6QMQsZywtnjnnGvHza6BTfYFWY9kjEWQ=
-golang.org/x/sys v0.40.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
+golang.org/x/sys v0.41.0 h1:Ivj+2Cp/ylzLiEU89QhWblYnOE9zerudt9Ftecq2C6k=
+golang.org/x/sys v0.41.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
 golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=
 golang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=
 golang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=
-golang.org/x/term v0.39.0 h1:RclSuaJf32jOqZz74CkPA9qFuVTX7vhLlpfj/IGWlqY=
-golang.org/x/term v0.39.0/go.mod h1:yxzUCTP/U+FzoxfdKmLaA0RV1WgE0VY7hXBwKtY/4ww=
+golang.org/x/term v0.40.0 h1:36e4zGLqU4yhjlmxEaagx2KuYbJq3EwY8K943ZsHcvg=
+golang.org/x/term v0.40.0/go.mod h1:w2P8uVp06p2iyKKuvXIm7N/y0UCRt3UfJTfZ7oOpglM=
 golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
 golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
 golang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=
 golang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
 golang.org/x/text v0.8.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=
-golang.org/x/text v0.33.0 h1:B3njUFyqtHDUI5jMn1YIr5B0IE2U0qck04r6d4KPAxE=
-golang.org/x/text v0.33.0/go.mod h1:LuMebE6+rBincTi9+xWTY8TztLzKHc/9C1uBCG27+q8=
+golang.org/x/text v0.34.0 h1:oL/Qq0Kdaqxa1KbNeMKwQq0reLCCaFtqu2eNuSeNHbk=
+golang.org/x/text v0.34.0/go.mod h1:homfLqTYRFyVYemLBFl5GgL/DWEiH5wcsQ5gSh1yziA=
 golang.org/x/time v0.14.0 h1:MRx4UaLrDotUKUdCIqzPC48t1Y9hANFKIRpNx+Te8PI=
 golang.org/x/time v0.14.0/go.mod h1:eL/Oa2bBBK0TkX57Fyni+NgnyQQN4LitPmob2Hjnqw4=
 golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
 golang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=
 golang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=
 golang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=
-golang.org/x/tools v0.41.0 h1:a9b8iMweWG+S0OBnlU36rzLp20z1Rp10w+IY2czHTQc=
-golang.org/x/tools v0.41.0/go.mod h1:XSY6eDqxVNiYgezAVqqCeihT4j1U2CCsqvH3WhQpnlg=
+golang.org/x/tools v0.42.0 h1:uNgphsn75Tdz5Ji2q36v/nsFSfR/9BRFvqhGBaJGd5k=
+golang.org/x/tools v0.42.0/go.mod h1:Ma6lCIwGZvHK6XtgbswSoWroEkhugApmsXyrUmBhfr0=
 golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
 golang.zx2c4.com/wintun v0.0.0-20230126152724-0fa3db229ce2 h1:B82qJJgjvYKsXS9jeunTOisW56dUokqW/FOteYJJ/yg=
 golang.zx2c4.com/wintun v0.0.0-20230126152724-0fa3db229ce2/go.mod h1:deeaetjYA+DHMHg+sMSMI58GrEteJUUzzw7en6TJQcI=
@@ -322,12 +330,14 @@ golang.zx2c4.com/wireguard/wgctrl v0.0.0-20241231184526-a9ab2273dd10 h1:3GDAcqdI
 golang.zx2c4.com/wireguard/wgctrl v0.0.0-20241231184526-a9ab2273dd10/go.mod h1:T97yPqesLiNrOYxkwmhMI0ZIlJDm+p0PMR8eRVeR5tQ=
 gonum.org/v1/gonum v0.16.0 h1:5+ul4Swaf3ESvrOnidPp4GZbzf0mxVQpDCYUQE7OJfk=
 gonum.org/v1/gonum v0.16.0/go.mod h1:fef3am4MQ93R2HHpKnLk4/Tbh/s0+wqD5nfa6Pnwy4E=
-google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b h1:SGYyueaEovpqmWmtTvwtVgo638V/QFE2zlTCnRrR3jg=
-google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b/go.mod h1:ZdbssH/1SOVnjnDlXzxDHK2MCidiqXtbYccJNzNYPEE=
-google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b h1:GZxXGdFaHX27ZSMHudWc4FokdD+xl8BC2UJm1OVIEzs=
-google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b/go.mod h1:j9x/tPzZkyxcgEFkiKEEGxfvyumM01BEtsW8xzOahRQ=
+google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57 h1:JLQynH/LBHfCTSbDWl+py8C+Rg/k1OVH3xfcaiANuF0=
+google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57/go.mod h1:kSJwQxqmFXeo79zOmbrALdflXQeAYcUbgS7PbpMknCY=
+google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57 h1:mWPCjDEyshlQYzBpMNHaEof6UX1PmHcaUODUywQ0uac=
+google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57/go.mod h1:j9x/tPzZkyxcgEFkiKEEGxfvyumM01BEtsW8xzOahRQ=
 google.golang.org/grpc v1.78.0 h1:K1XZG/yGDJnzMdd/uZHAkVqJE+xIDOcmdSFZkBUicNc=
 google.golang.org/grpc v1.78.0/go.mod h1:I47qjTo4OKbMkjA/aOOwxDIiPSBofUtQUI5EfpWvW7U=
+google.golang.org/grpc v1.79.0 h1:6/+EFlxsMyoSbHbBoEDx94n/Ycx/bi0IhJ5Qh7b7LaA=
+google.golang.org/grpc v1.79.0/go.mod h1:KmT0Kjez+0dde/v2j9vzwoAScgEPx/Bw1CYChhHLrHQ=
 google.golang.org/protobuf v1.36.11 h1:fV6ZwhNocDyBLK0dj+fg8ektcVegBBuEolpbTQyBNVE=
 google.golang.org/protobuf v1.36.11/go.mod h1:HTf+CrKn2C3g5S8VImy6tdcUvCska2kB7j23XfzDpco=
 gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
@@ -346,23 +356,23 @@ gopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=
 gopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=
 gvisor.dev/gvisor v0.0.0-20250503011706-39ed1f5ac29c h1:m/r7OM+Y2Ty1sgBQ7Qb27VgIMBW8ZZhT4gLnUyDIhzI=
 gvisor.dev/gvisor v0.0.0-20250503011706-39ed1f5ac29c/go.mod h1:3r5CMtNQMKIvBlrmM9xWUNamjKBYPOWyXOjmg5Kts3g=
-k8s.io/api v0.35.0 h1:iBAU5LTyBI9vw3L5glmat1njFK34srdLmktWwLTprlY=
-k8s.io/api v0.35.0/go.mod h1:AQ0SNTzm4ZAczM03QH42c7l3bih1TbAXYo0DkF8ktnA=
-k8s.io/apimachinery v0.35.0 h1:Z2L3IHvPVv/MJ7xRxHEtk6GoJElaAqDCCU0S6ncYok8=
-k8s.io/apimachinery v0.35.0/go.mod h1:jQCgFZFR1F4Ik7hvr2g84RTJSZegBc8yHgFWKn//hns=
-k8s.io/client-go v0.35.0 h1:IAW0ifFbfQQwQmga0UdoH0yvdqrbwMdq9vIFEhRpxBE=
-k8s.io/client-go v0.35.0/go.mod h1:q2E5AAyqcbeLGPdoRB+Nxe3KYTfPce1Dnu1myQdqz9o=
+k8s.io/api v0.35.1 h1:0PO/1FhlK/EQNVK5+txc4FuhQibV25VLSdLMmGpDE/Q=
+k8s.io/api v0.35.1/go.mod h1:28uR9xlXWml9eT0uaGo6y71xK86JBELShLy4wR1XtxM=
+k8s.io/apimachinery v0.35.1 h1:yxO6gV555P1YV0SANtnTjXYfiivaTPvCTKX6w6qdDsU=
+k8s.io/apimachinery v0.35.1/go.mod h1:jQCgFZFR1F4Ik7hvr2g84RTJSZegBc8yHgFWKn//hns=
+k8s.io/client-go v0.35.1 h1:+eSfZHwuo/I19PaSxqumjqZ9l5XiTEKbIaJ+j1wLcLM=
+k8s.io/client-go v0.35.1/go.mod h1:1p1KxDt3a0ruRfc/pG4qT/3oHmUj1AhSHEcxNSGg+OA=
 k8s.io/klog/v2 v2.130.1 h1:n9Xl7H1Xvksem4KFG4PYbdQCQxqc/tTUyrgXaOhHSzk=
 k8s.io/klog/v2 v2.130.1/go.mod h1:3Jpz1GvMt720eyJH1ckRHK1EDfpxISzJ7I9OYgaDtPE=
 k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4 h1:HhDfevmPS+OalTjQRKbTHppRIz01AWi8s45TMXStgYY=
 k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4/go.mod h1:kdmbQkyfwUagLfXIad1y2TdrjPFWp2Q89B3qkRwf/pQ=
-k8s.io/utils v0.0.0-20260108192941-914a6e750570 h1:JT4W8lsdrGENg9W+YwwdLJxklIuKWdRm+BC+xt33FOY=
-k8s.io/utils v0.0.0-20260108192941-914a6e750570/go.mod h1:xDxuJ0whA3d0I4mf/C4ppKHxXynQ+fxnkmQH0vTHnuk=
+k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2 h1:AZYQSJemyQB5eRxqcPky+/7EdBj0xi3g0ZcxxJ7vbWU=
+k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2/go.mod h1:xDxuJ0whA3d0I4mf/C4ppKHxXynQ+fxnkmQH0vTHnuk=
 sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730 h1:IpInykpT6ceI+QxKBbEflcR5EXP7sU1kvOlxwZh5txg=
 sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730/go.mod h1:mdzfpAEoE6DHQEN0uh9ZbOCuHbLK5wOm7dK4ctXE9Tg=
 sigs.k8s.io/randfill v1.0.0 h1:JfjMILfT8A6RbawdsK2JXGBR5AQVfd+9TbzrlneTyrU=
 sigs.k8s.io/randfill v1.0.0/go.mod h1:XeLlZ/jmk4i1HRopwe7/aU3H5n1zNUcX6TM94b3QxOY=
-sigs.k8s.io/structured-merge-diff/v6 v6.3.1 h1:JrhdFMqOd/+3ByqlP2I45kTOZmTRLBUm5pvRjeheg7E=
-sigs.k8s.io/structured-merge-diff/v6 v6.3.1/go.mod h1:M3W8sfWvn2HhQDIbGWj3S099YozAsymCo/wrT5ohRUE=
+sigs.k8s.io/structured-merge-diff/v6 v6.3.2 h1:kwVWMx5yS1CrnFWA/2QHyRVJ8jM6dBA80uLmm0wJkk8=
+sigs.k8s.io/structured-merge-diff/v6 v6.3.2/go.mod h1:M3W8sfWvn2HhQDIbGWj3S099YozAsymCo/wrT5ohRUE=
 sigs.k8s.io/yaml v1.6.0 h1:G8fkbMSAFqgEFgh4b1wmtzDnioxFCUgTZhlbj5P9QYs=
 sigs.k8s.io/yaml v1.6.0/go.mod h1:796bPqUfzR/0jLAl6XjHl3Ck7MiyVv8dbTdyT3/pMf4=
diff --git a/client/pkg/clusterimport/clusterimport.go b/client/pkg/clusterimport/clusterimport.go
index 41f0ee94..30d7a419 100644
--- a/client/pkg/clusterimport/clusterimport.go
+++ b/client/pkg/clusterimport/clusterimport.go
@@ -373,18 +373,18 @@ func newContext(input Input, talosCli talosClientWrapper, imageFactoryClient Ima
 				return nil, fmt.Errorf("failed to sanitize config patch for node %q: %w", node, patchErr)
 			}
 
-			configPatchId := fmt.Sprintf("%d-%s", (i+1)*10, info.machineID)
-			configPatch := omni.NewConfigPatch(configPatchId)
+			configPatchID := fmt.Sprintf("%d-%s", (i+1)*10, info.machineID)
+			configPatch := omni.NewConfigPatch(configPatchID)
 			configPatch.Metadata().Labels().Set(omni.LabelCluster, clusterID)
 			configPatch.Metadata().Labels().Set(omni.LabelClusterMachine, info.machineID)
 			configPatch.Metadata().Annotations().Set(omni.ConfigPatchName, "User defined patch")
 			configPatch.Metadata().Annotations().Set(omni.ConfigPatchDescription, "Config patch imported from existing Talos node")
 
 			if patchErr = configPatch.TypedSpec().Value.SetUncompressedData(sanitizedDiffBytes); patchErr != nil {
-				return nil, fmt.Errorf("failed to set data for config patch %q: %w", configPatchId, patchErr)
+				return nil, fmt.Errorf("failed to set data for config patch %q: %w", configPatchID, patchErr)
 			}
 
-			configPatchesMap[configPatchId] = configPatch
+			configPatchesMap[configPatchID] = configPatch
 		}
 	}
 
diff --git a/client/pkg/constants/constants.go b/client/pkg/constants/constants.go
index f93e29c5..606ab716 100644
--- a/client/pkg/constants/constants.go
+++ b/client/pkg/constants/constants.go
@@ -13,7 +13,7 @@ const SecureBoot = "secureboot"
 
 // DefaultTalosVersion is pre-selected in the UI, default image and used in the integration tests.
 // tsgen:DefaultTalosVersion
-const DefaultTalosVersion = "1.12.1"
+const DefaultTalosVersion = "1.12.3"
 
 // MinTalosVersion allowed to be used when creating the cluster.
 // tsgen:MinTalosVersion
diff --git a/client/pkg/diff/diff.go b/client/pkg/diff/diff.go
new file mode 100644
index 00000000..c05c40ed
--- /dev/null
+++ b/client/pkg/diff/diff.go
@@ -0,0 +1,58 @@
+// This Source Code Form is subject to the terms of the Mozilla Public
+// License, v. 2.0. If a copy of the MPL was not distributed with this
+// file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+// Package diff provides a memory-safe unified diff computation.
+package diff
+
+import (
+	"bytes"
+	"fmt"
+	"strings"
+
+	"github.com/neticdk/go-stdlib/diff/myers"
+)
+
+// MaxLines is the maximum total number of lines (old + new) for which a full
+// structural diff is computed. Beyond this the diff is summarized because no
+// human can meaningfully review it and the algorithmic cost becomes prohibitive.
+const MaxLines = 75_000
+
+// Compute returns a unified diff (without the --- / +++ header) between two
+// byte slices. For inputs whose combined line count exceeds MaxLines it returns
+// a short summary instead.
+func Compute(previousData, newData []byte) (string, error) {
+	if bytes.Equal(previousData, newData) {
+		return "", nil
+	}
+
+	prevLines := bytes.Count(previousData, []byte("\n"))
+	newLines := bytes.Count(newData, []byte("\n"))
+
+	if prevLines+newLines > MaxLines {
+		return fmt.Sprintf("@@ -%d,%d +%d,%d @@ diff too large to display\n", 1, prevLines, 1, newLines), nil
+	}
+
+	result, err := myers.Diff(string(previousData), string(newData),
+		myers.WithUnifiedFormatter(),
+		myers.WithLinearSpace(true),
+		// Disable the library's standard-Myers and LCS fallback paths:
+		// - Standard Myers (< smallInputThreshold) is O((N+M)) when inputs are asymmetric.
+		// - LCS (> largeInputThreshold) is O(N*M) for the DP table.
+		// By setting these to 0 and MaxLines respectively, only Hirschberg's
+		// O(N+M) linear-space algorithm runs. Our MaxLines guard above ensures
+		// inputs never exceed largeInputThreshold.
+		myers.WithSmallInputThreshold(0),
+		myers.WithLargeInputThreshold(MaxLines),
+	)
+	if err != nil {
+		return "", err
+	}
+
+	// Strip the "--- a\n+++ b\n" header that the library always prepends.
+	if after, ok := strings.CutPrefix(result, "--- a\n+++ b\n"); ok {
+		result = after
+	}
+
+	return result, nil
+}
diff --git a/client/pkg/diff/diff_test.go b/client/pkg/diff/diff_test.go
new file mode 100644
index 00000000..cfc79b8f
--- /dev/null
+++ b/client/pkg/diff/diff_test.go
@@ -0,0 +1,405 @@
+// This Source Code Form is subject to the terms of the Mozilla Public
+// License, v. 2.0. If a copy of the MPL was not distributed with this
+// file, You can obtain one at http://mozilla.org/MPL/2.0/.
+
+package diff_test
+
+import (
+	"bytes"
+	_ "embed"
+	"fmt"
+	"runtime"
+	"strings"
+	"testing"
+
+	"github.com/siderolabs/talos/pkg/machinery/config/configloader"
+	"github.com/siderolabs/talos/pkg/machinery/config/container"
+	"github.com/siderolabs/talos/pkg/machinery/config/encoder"
+	"github.com/siderolabs/talos/pkg/machinery/config/types/v1alpha1"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+
+	"github.com/siderolabs/omni/client/pkg/diff"
+)
+
+// BenchmarkComputeDiff tests various state transitions of the diff logic.
+func BenchmarkComputeDiff(b *testing.B) {
+	modifiedConfigBytes := modifyConfig(b, baseConfigBytes, func(c *v1alpha1.Config) {
+		c.MachineConfig.MachineFiles = append(c.MachineConfig.MachineFiles,
+			&v1alpha1.MachineFile{
+				FileContent:     "aaa",
+				FilePermissions: 0o777,
+				FilePath:        "/var/f",
+				FileOp:          "create",
+			},
+		)
+	})
+
+	installChangeConfigBytes := modifyConfig(b, baseConfigBytes, func(c *v1alpha1.Config) {
+		c.MachineConfig.MachineInstall.InstallDisk = "/dev/sdb"
+	})
+
+	b.ResetTimer()
+
+	b.Run("EmptyToEmpty", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(nil, nil) //nolint:errcheck
+		}
+	})
+
+	b.Run("EmptyToPopulated", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(nil, baseConfigBytes) //nolint:errcheck
+		}
+	})
+
+	b.Run("PopulatedToEmpty", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(baseConfigBytes, nil) //nolint:errcheck
+		}
+	})
+
+	b.Run("Identical", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(baseConfigBytes, baseConfigBytes) //nolint:errcheck
+		}
+	})
+
+	b.Run("RealDiff", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(baseConfigBytes, modifiedConfigBytes) //nolint:errcheck
+		}
+	})
+
+	b.Run("InstallSectionIgnored", func(b *testing.B) {
+		for range b.N {
+			diff.Compute(baseConfigBytes, installChangeConfigBytes) //nolint:errcheck
+		}
+	})
+
+	largeYAML := generateLargeYAML(10000)
+
+	b.Run("EmptyToLargeYAML", func(b *testing.B) {
+		b.ReportAllocs()
+
+		for range b.N {
+			diff.Compute(nil, largeYAML) //nolint:errcheck
+		}
+	})
+
+	b.Run("LargeYAMLToEmpty", func(b *testing.B) {
+		b.ReportAllocs()
+
+		for range b.N {
+			diff.Compute(largeYAML, nil) //nolint:errcheck
+		}
+	})
+
+	largeYAMLModified := generateLargeYAML(10001)
+
+	b.Run("LargeYAMLToDifferentLargeYAML", func(b *testing.B) {
+		b.ReportAllocs()
+
+		for range b.N {
+			diff.Compute(largeYAML, largeYAMLModified) //nolint:errcheck
+		}
+	})
+}
+
+func modifyConfig(t testing.TB, data []byte, update func(*v1alpha1.Config)) []byte {
+	cfg, err := configloader.NewFromBytes(data)
+	require.NoError(t, err)
+
+	c, err := container.New(cfg.Documents()...)
+	require.NoError(t, err)
+
+	v1Cfg := c.RawV1Alpha1()
+	require.NotNil(t, v1Cfg)
+
+	update(v1Cfg)
+
+	newData, err := c.EncodeBytes(encoder.WithComments(encoder.CommentsDisabled))
+	require.NoError(t, err)
+
+	return newData
+}
+
+//go:embed testdata/base-config.yaml
+var baseConfigBytes []byte
+
+//go:embed testdata/empty-to-populated.diff
+var emptyToPopulatedDiff string
+
+//go:embed testdata/populated-to-empty.diff
+var populatedToEmptyDiff string
+
+// TestComputeDiff tests the ComputeDiff function with various state transitions.
+func TestComputeDiff(t *testing.T) {
+	modifiedConfigBytes := modifyConfig(t, baseConfigBytes, func(c *v1alpha1.Config) {
+		c.MachineConfig.MachineFiles = append(c.MachineConfig.MachineFiles,
+			&v1alpha1.MachineFile{
+				FileContent:     "aaa",
+				FilePermissions: 0o777,
+				FilePath:        "/var/f",
+				FileOp:          "create",
+			},
+		)
+	})
+
+	tests := []struct {
+		name         string
+		wantDiff     string
+		previousData []byte
+		newData      []byte
+		wantErr      bool
+	}{
+		{
+			name:         "empty to empty",
+			previousData: nil,
+			newData:      nil,
+		},
+		{
+			name:         "empty to populated",
+			previousData: nil,
+			newData:      baseConfigBytes,
+			wantDiff:     emptyToPopulatedDiff,
+		},
+		{
+			name:         "populated to empty",
+			previousData: baseConfigBytes,
+			newData:      nil,
+			wantDiff:     populatedToEmptyDiff,
+		},
+		{
+			name:         "identical",
+			previousData: baseConfigBytes,
+			newData:      baseConfigBytes,
+			wantDiff:     "",
+		},
+		{
+			name:         "real diff",
+			previousData: baseConfigBytes,
+			newData:      modifiedConfigBytes,
+			wantDiff: `@@ -15,6 +15,11 @@
+     install:
+         wipe: false
+         grubUseUKICmdline: true
++    files:
++        - content: aaa
++          permissions: 0o777
++          path: /var/f
++          op: create
+     features:
+         diskQuotaSupport: true
+         kubePrism:
+`,
+		},
+	}
+
+	for _, tt := range tests {
+		t.Run(tt.name, func(t *testing.T) {
+			diff, err := diff.Compute(tt.previousData, tt.newData)
+
+			if tt.wantErr {
+				require.Error(t, err)
+
+				return
+			}
+
+			require.NoError(t, err)
+			require.Equal(t, tt.wantDiff, diff)
+		})
+	}
+}
+
+func TestComputeDiff_LargeInput(t *testing.T) {
+	t.Run("structural diff for inputs under threshold", func(t *testing.T) {
+		small := generateLargeYAML(1000) // ~8000 lines, well under 50k
+
+		diff, err := diff.Compute(nil, small)
+		require.NoError(t, err)
+		assert.NotEmpty(t, diff)
+		assert.True(t, strings.HasPrefix(diff, "@@ -0,0 +1,"))
+	})
+
+	t.Run("bulk diff for inputs over threshold", func(t *testing.T) {
+		largeYAML := generateLargeYAML(10000) // ~80k lines, over 50k threshold
+
+		diff, err := diff.Compute(nil, largeYAML)
+		require.NoError(t, err)
+		assert.Contains(t, diff, "diff too large to display")
+	})
+
+	t.Run("bulk diff large to empty", func(t *testing.T) {
+		largeYAML := generateLargeYAML(10000)
+
+		diff, err := diff.Compute(largeYAML, nil)
+		require.NoError(t, err)
+		assert.Contains(t, diff, "diff too large to display")
+	})
+
+	t.Run("bulk diff large to different large", func(t *testing.T) {
+		largeYAML := generateLargeYAML(10000)
+		largeYAMLModified := generateLargeYAML(10001)
+
+		diff, err := diff.Compute(largeYAML, largeYAMLModified)
+		require.NoError(t, err)
+		assert.Contains(t, diff, "diff too large to display")
+	})
+}
+
+// TestComputeDiff_MemoryBudget asserts that diff.Compute stays within a memory
+// budget across a range of input sizes and patterns.
+func TestComputeDiff_MemoryBudget(t *testing.T) {
+	const memoryBudget = 50 * 1024 * 1024 // 50 MB hard ceiling
+
+	// generateLines builds a YAML-like blob with exactly n newline-terminated lines.
+	// When variant > 0 every variant-th line is changed so the diff is non-trivial.
+	generateLines := func(n, variant int) []byte {
+		var sb strings.Builder
+
+		for i := range n {
+			if variant > 0 && i%variant == 0 {
+				fmt.Fprintf(&sb, "line-%d-variant-%d\n", i, variant)
+			} else {
+				fmt.Fprintf(&sb, "line-%d\n", i)
+			}
+		}
+
+		return []byte(sb.String())
+	}
+
+	tests := []struct {
+		old         func() []byte
+		new         func() []byte
+		name        string
+		maxMemBytes uint64
+	}{
+		{
+			name:        "small similar configs (100 lines, few changes)",
+			old:         func() []byte { return generateLines(100, 0) },
+			new:         func() []byte { return generateLines(100, 10) },
+			maxMemBytes: 1 * 1024 * 1024, // 1 MB
+		},
+		{
+			name:        "small completely different (100 lines)",
+			old:         func() []byte { return generateLines(100, 0) },
+			new:         func() []byte { return generateLines(100, 1) },
+			maxMemBytes: 1 * 1024 * 1024,
+		},
+		{
+			name:        "medium similar (5K lines, few changes)",
+			old:         func() []byte { return generateLines(5000, 0) },
+			new:         func() []byte { return generateLines(5000, 50) },
+			maxMemBytes: 10 * 1024 * 1024, // 10 MB
+		},
+		{
+			name:        "medium completely different (5K lines)",
+			old:         func() []byte { return generateLines(5000, 0) },
+			new:         func() []byte { return generateLines(5000, 1) },
+			maxMemBytes: 10 * 1024 * 1024,
+		},
+		{
+			name:        "large similar (30K lines, few changes)",
+			old:         func() []byte { return generateLines(30000, 0) },
+			new:         func() []byte { return generateLines(30000, 100) },
+			maxMemBytes: 50 * 1024 * 1024, // 50 MB
+		},
+		{
+			name:        "large completely different (30K lines)",
+			old:         func() []byte { return generateLines(30000, 0) },
+			new:         func() []byte { return generateLines(30000, 1) },
+			maxMemBytes: 100 * 1024 * 1024, // 100 MB
+		},
+		{
+			name:        "asymmetric: empty to 30K lines",
+			old:         func() []byte { return nil },
+			new:         func() []byte { return generateLines(30000, 0) },
+			maxMemBytes: 50 * 1024 * 1024,
+		},
+		{
+			name:        "asymmetric: 50 lines to 30K lines",
+			old:         func() []byte { return generateLines(50, 0) },
+			new:         func() []byte { return generateLines(30000, 0) },
+			maxMemBytes: 50 * 1024 * 1024,
+		},
+		{
+			name:        "near threshold (total ~74K lines)",
+			old:         func() []byte { return generateLines(37000, 0) },
+			new:         func() []byte { return generateLines(37000, 1) },
+			maxMemBytes: memoryBudget,
+		},
+		{
+			name:        "over threshold (total ~76K lines, returns summary)",
+			old:         func() []byte { return generateLines(38000, 0) },
+			new:         func() []byte { return generateLines(38000, 1) },
+			maxMemBytes: 1 * 1024 * 1024, // summary path allocates almost nothing
+		},
+	}
+
+	for _, tt := range tests {
+		t.Run(tt.name, func(t *testing.T) {
+			oldData := tt.old()
+			newData := tt.new()
+
+			oldLines := bytes.Count(oldData, []byte("\n"))
+			newLines := bytes.Count(newData, []byte("\n"))
+
+			// Measure allocations.
+			runtime.GC()
+
+			var before, after runtime.MemStats
+
+			runtime.ReadMemStats(&before)
+
+			result, err := diff.Compute(oldData, newData)
+			require.NoError(t, err)
+
+			runtime.ReadMemStats(&after)
+
+			allocated := after.TotalAlloc - before.TotalAlloc
+
+			t.Logf("oldData=%d lines, newData=%d lines, allocated=%s, result=%d bytes",
+				oldLines, newLines, formatBytes(allocated), len(result))
+
+			assert.Less(t, allocated, tt.maxMemBytes,
+				"memory budget exceeded: allocated %s, limit %s",
+				formatBytes(allocated), formatBytes(tt.maxMemBytes))
+		})
+	}
+}
+
+func formatBytes(b uint64) string {
+	switch {
+	case b >= 1024*1024*1024:
+		return fmt.Sprintf("%.1f GB", float64(b)/(1024*1024*1024))
+	case b >= 1024*1024:
+		return fmt.Sprintf("%.1f MB", float64(b)/(1024*1024))
+	case b >= 1024:
+		return fmt.Sprintf("%.1f KB", float64(b)/1024)
+	default:
+		return fmt.Sprintf("%d B", b)
+	}
+}
+
+// generateLargeYAML generates a YAML document with the given number of
+// K8s-manifest-like entries to simulate large inline manifests configs.
+func generateLargeYAML(n int) []byte {
+	var sb strings.Builder
+
+	for i := range n {
+		if i > 0 {
+			sb.WriteString("---\n")
+		}
+
+		fmt.Fprintf(&sb, "apiVersion: v1\n")
+		fmt.Fprintf(&sb, "kind: ConfigMap\n")
+		fmt.Fprintf(&sb, "metadata:\n")
+		fmt.Fprintf(&sb, "  name: manifest-%d\n", i)
+		fmt.Fprintf(&sb, "  namespace: default\n")
+		fmt.Fprintf(&sb, "data:\n")
+		fmt.Fprintf(&sb, "  key: value-%d\n", i)
+	}
+
+	return []byte(sb.String())
+}
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/base-config.yaml b/client/pkg/diff/testdata/base-config.yaml
similarity index 100%
rename from internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/base-config.yaml
rename to client/pkg/diff/testdata/base-config.yaml
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/empty-to-populated.diff b/client/pkg/diff/testdata/empty-to-populated.diff
similarity index 99%
rename from internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/empty-to-populated.diff
rename to client/pkg/diff/testdata/empty-to-populated.diff
index b3df2bdf..123a2c00 100644
--- a/internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/empty-to-populated.diff
+++ b/client/pkg/diff/testdata/empty-to-populated.diff
@@ -1,4 +1,4 @@
-@@ -1 +1,93 @@
+@@ -0,0 +1,93 @@
 +version: v1alpha1
 +debug: false
 +persist: true
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/populated-to-empty.diff b/client/pkg/diff/testdata/populated-to-empty.diff
similarity index 99%
rename from internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/populated-to-empty.diff
rename to client/pkg/diff/testdata/populated-to-empty.diff
index 47589fbc..95fc9bbb 100644
--- a/internal/backend/runtime/omni/controllers/omni/machineconfig/testdata/populated-to-empty.diff
+++ b/client/pkg/diff/testdata/populated-to-empty.diff
@@ -1,4 +1,4 @@
-@@ -1,93 +1 @@
+@@ -1,93 +0,0 @@
 -version: v1alpha1
 -debug: false
 -persist: true
diff --git a/client/pkg/infra/provision/context.go b/client/pkg/infra/provision/context.go
index f3ef1d00..ffff2792 100644
--- a/client/pkg/infra/provision/context.go
+++ b/client/pkg/infra/provision/context.go
@@ -126,6 +126,11 @@ func (context *Context[T]) GetTalosVersion() string {
 	return context.machineRequest.TypedSpec().Value.TalosVersion
 }
 
+// GetMachineRequestSetID returns the machine request set ID.
+func (context *Context[T]) GetMachineRequestSetID() (string, bool) {
+	return context.machineRequest.Metadata().Labels().Get(omni.LabelMachineRequestSet)
+}
+
 // SetMachineUUID in the machine request status.
 func (context *Context[T]) SetMachineUUID(value string) {
 	context.MachineRequestStatus.TypedSpec().Value.Id = value
diff --git a/client/pkg/omnictl/config.go b/client/pkg/omnictl/config.go
index 08397f6f..e6ccaa93 100644
--- a/client/pkg/omnictl/config.go
+++ b/client/pkg/omnictl/config.go
@@ -266,6 +266,7 @@ var configInfoCmd = &cobra.Command{
 		}
 
 		var buf bytes.Buffer
+
 		err = configInfoCmdTemplate.Execute(&buf, map[string]string{
 			"Context":  conf.Context,
 			"APIURL":   context.URL,
diff --git a/client/pkg/omnictl/configure/machine.go b/client/pkg/omnictl/configure/machine.go
index c738845e..2cc5266b 100644
--- a/client/pkg/omnictl/configure/machine.go
+++ b/client/pkg/omnictl/configure/machine.go
@@ -40,7 +40,6 @@ var machineCmd = &cobra.Command{
 	RunE: func(cmd *cobra.Command, args []string) error {
 		return access.WithClient(func(ctx context.Context, client *client.Client) error {
 			for _, id := range args {
-
 				if machineCmdFlags.siderolinkConnection == "" {
 					fmt.Println("nothing to do: no flags specified")
 
diff --git a/client/pkg/omnictl/docs.go b/client/pkg/omnictl/docs.go
index 2ccaab0a..5cefb6b6 100644
--- a/client/pkg/omnictl/docs.go
+++ b/client/pkg/omnictl/docs.go
@@ -46,6 +46,7 @@ var docsCmd = &cobra.Command{
 		dir := args[0]
 
 		filename := filepath.Join(dir, "cli.md")
+
 		f, err := os.Create(filename)
 		if err != nil {
 			return err
diff --git a/client/pkg/template/operations/export.go b/client/pkg/template/operations/export.go
index 6dcd80b8..b061bd8b 100644
--- a/client/pkg/template/operations/export.go
+++ b/client/pkg/template/operations/export.go
@@ -18,7 +18,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
 	"github.com/siderolabs/gen/xslices"
-	"github.com/siderolabs/go-pointer"
 	"go.yaml.in/yaml/v4"
 
 	"github.com/siderolabs/omni/client/api/omni/specs"
@@ -279,7 +278,7 @@ func transformMachineSetToModel(machineSet *omni.MachineSet, nodes []*omni.Machi
 		updateStrategyConfig = &models.UpdateStrategyConfig{}
 
 		if spec.GetUpdateStrategy() != specs.MachineSetSpec_Rolling { // Rolling is the default for update, so set the strategy type only when it is not Rolling.
-			updateStrategyConfig.Type = pointer.To(models.UpdateStrategyType(spec.GetUpdateStrategy()))
+			updateStrategyConfig.Type = new(models.UpdateStrategyType(spec.GetUpdateStrategy()))
 		}
 
 		if spec.GetUpdateStrategyConfig().GetRolling() != nil {
@@ -295,7 +294,7 @@ func transformMachineSetToModel(machineSet *omni.MachineSet, nodes []*omni.Machi
 		deleteStrategyConfig = &models.UpdateStrategyConfig{}
 
 		if spec.GetDeleteStrategy() != specs.MachineSetSpec_Unset { // Unset is the default for delete, so set the strategy type only when it is not Unset.
-			deleteStrategyConfig.Type = pointer.To(models.UpdateStrategyType(spec.GetDeleteStrategy()))
+			deleteStrategyConfig.Type = new(models.UpdateStrategyType(spec.GetDeleteStrategy()))
 		}
 
 		if spec.GetDeleteStrategyConfig().GetRolling() != nil {
diff --git a/client/pkg/template/operations/internal/utils/utils.go b/client/pkg/template/operations/internal/utils/utils.go
index 1cb99a61..f6e23f39 100644
--- a/client/pkg/template/operations/internal/utils/utils.go
+++ b/client/pkg/template/operations/internal/utils/utils.go
@@ -13,10 +13,9 @@ import (
 
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/fatih/color"
-	"github.com/hexops/gotextdiff"
-	"github.com/hexops/gotextdiff/myers"
-	"github.com/hexops/gotextdiff/span"
 	"go.yaml.in/yaml/v4"
+
+	"github.com/siderolabs/omni/client/pkg/diff"
 )
 
 // MarshalResource to YAML format (bytes).
@@ -70,71 +69,44 @@ func RenderDiff(w io.Writer, oldR, newR resource.Resource) error {
 		newPath = "/dev/null"
 	}
 
-	edits := myers.ComputeEdits(span.URIFromPath(oldPath), string(oldYaml), string(newYaml))
-	diff := gotextdiff.ToUnified(oldPath, newPath, string(oldYaml), edits)
+	diffStr, err := diff.Compute(oldYaml, newYaml)
+	if err != nil {
+		return err
+	}
 
-	outputDiff(w, diff)
+	outputDiff(w, diffStr, oldPath, newPath)
 
 	return nil
 }
 
-func outputDiff(w io.Writer, u gotextdiff.Unified) {
-	if len(u.Hunks) == 0 {
+func outputDiff(w io.Writer, diffStr, fromPath, toPath string) {
+	// Strip the library's generic header; we print our own with resource paths.
+	diffStr, _ = strings.CutPrefix(diffStr, "--- a\n+++ b\n")
+
+	if diffStr == "" {
 		return
 	}
 
 	bold := color.New(color.Bold)
-	bold.Fprintf(w, "--- %s\n", u.From) //nolint:errcheck
-	bold.Fprintf(w, "+++ %s\n", u.To)   //nolint:errcheck
+	bold.Fprintf(w, "--- %s\n", fromPath) //nolint:errcheck
+	bold.Fprintf(w, "+++ %s\n", toPath)   //nolint:errcheck
 
 	cyan := color.New(color.FgCyan)
 	red := color.New(color.FgRed)
 	green := color.New(color.FgGreen)
 
-	for _, hunk := range u.Hunks {
-		fromCount, toCount := 0, 0
-
-		for _, l := range hunk.Lines {
-			switch l.Kind { //nolint:exhaustive
-			case gotextdiff.Delete:
-				fromCount++
-			case gotextdiff.Insert:
-				toCount++
-			default:
-				fromCount++
-				toCount++
-			}
-		}
-
-		cyan.Fprintf(w, "@@") //nolint:errcheck
-
-		if fromCount > 1 {
-			cyan.Fprintf(w, " -%d,%d", hunk.FromLine, fromCount) //nolint:errcheck
-		} else {
-			cyan.Fprintf(w, " -%d", hunk.FromLine) //nolint:errcheck
-		}
-
-		if toCount > 1 {
-			cyan.Fprintf(w, " +%d,%d", hunk.ToLine, toCount) //nolint:errcheck
-		} else {
-			cyan.Fprintf(w, " +%d", hunk.ToLine) //nolint:errcheck
-		}
-
-		cyan.Printf(" @@\n") //nolint:errcheck
-
-		for _, l := range hunk.Lines {
-			switch l.Kind { //nolint:exhaustive
-			case gotextdiff.Delete:
-				red.Fprintf(w, "-%s", l.Content) //nolint:errcheck
-			case gotextdiff.Insert:
-				green.Fprintf(w, "+%s", l.Content) //nolint:errcheck
-			default:
-				fmt.Fprintf(w, " %s", l.Content) //nolint:errcheck
-			}
-
-			if !strings.HasSuffix(l.Content, "\n") {
-				red.Fprintf(w, "\n\\ No newline at end of file\n") //nolint:errcheck
-			}
+	for line := range strings.SplitSeq(diffStr, "\n") {
+		switch {
+		case strings.HasPrefix(line, "@@"):
+			cyan.Fprintln(w, line) //nolint:errcheck
+		case strings.HasPrefix(line, "-"):
+			red.Fprintln(w, line) //nolint:errcheck
+		case strings.HasPrefix(line, "+"):
+			green.Fprintln(w, line) //nolint:errcheck
+		case line == "":
+			// skip trailing empty line
+		default:
+			fmt.Fprintln(w, line) //nolint:errcheck
 		}
 	}
 }
diff --git a/client/pkg/template/template.go b/client/pkg/template/template.go
index 07071f43..be532f99 100644
--- a/client/pkg/template/template.go
+++ b/client/pkg/template/template.go
@@ -46,7 +46,7 @@ func Load(input io.Reader) (*Template, error) {
 		}
 
 		if docNode.Kind != yaml.DocumentNode {
-			return nil, fmt.Errorf("unexpected node kind %q", docNode.Kind)
+			return nil, fmt.Errorf("unexpected node kind %v", docNode.Kind)
 		}
 
 		if len(docNode.Content) != 1 {
@@ -83,7 +83,7 @@ func Load(input io.Reader) (*Template, error) {
 
 func findKind(node *yaml.Node) (string, error) {
 	if node.Kind != yaml.MappingNode {
-		return "", fmt.Errorf("unexpected node kind %q, expecting mapping", node.Kind)
+		return "", fmt.Errorf("unexpected node kind %v, expecting mapping", node.Kind)
 	}
 
 	for i := 0; i < len(node.Content); i += 2 {
@@ -91,7 +91,7 @@ func findKind(node *yaml.Node) (string, error) {
 		value := node.Content[i+1]
 
 		if key.Kind != yaml.ScalarNode {
-			return "", fmt.Errorf("unexpected node kind %q", key.Kind)
+			return "", fmt.Errorf("unexpected node kind %v", key.Kind)
 		}
 
 		if key.Value != "kind" {
@@ -99,7 +99,7 @@ func findKind(node *yaml.Node) (string, error) {
 		}
 
 		if value.Kind != yaml.ScalarNode {
-			return "", fmt.Errorf("unexpected value type for kind field %q", value.Kind)
+			return "", fmt.Errorf("unexpected value type for kind field %v", value.Kind)
 		}
 
 		return value.Value, nil
diff --git a/client/pkg/template/template_test.go b/client/pkg/template/template_test.go
index 6afb8b9a..5622438c 100644
--- a/client/pkg/template/template_test.go
+++ b/client/pkg/template/template_test.go
@@ -101,7 +101,7 @@ func TestLoad(t *testing.T) {
 		{
 			name:          "clusterBadYAML1",
 			data:          clusterBadYAML1,
-			expectedError: "error decoding document at line 1:1: yaml: unmarshal errors:\n  line 7: field containerd not found in type models.Cluster",
+			expectedError: "error decoding document at line 1:1: yaml: construct errors:\n  line 7: field containerd not found in type models.Cluster",
 		},
 		{
 			name:          "clusterBadYAML2",
diff --git a/cmd/make-cookies/main.go b/cmd/make-cookies/main.go
index 866dcfee..389214f6 100644
--- a/cmd/make-cookies/main.go
+++ b/cmd/make-cookies/main.go
@@ -7,49 +7,43 @@
 package main
 
 import (
-	"context"
+	"encoding/base64"
 	"fmt"
+	"log"
 	"net/http"
-	"os"
+
+	"github.com/siderolabs/go-api-signature/pkg/serviceaccount"
 
 	"github.com/siderolabs/omni/internal/backend/services/workloadproxy"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
 )
 
 func main() {
 	if err := app(); err != nil {
-		fmt.Fprintln(os.Stderr, err)
-		os.Exit(1)
+		log.Fatalf("failed to create cookies: %v", err)
 	}
 }
 
 func app() error {
-	ctx, cancel := context.WithCancel(context.Background())
-	defer cancel()
-
-	// don't forget to build this with the -tags=sidero.debug
-	if len(os.Args) != 2 {
-		return fmt.Errorf("usage: %s <endpoint>", os.Args[0])
+	_, saKey := serviceaccount.GetFromEnv()
+	if saKey == "" {
+		return fmt.Errorf("no service account key found in environment variables")
 	}
 
-	cfg := clientconfig.New(os.Args[1], os.Getenv("OMNI_SERVICE_ACCOUNT_KEY"))
-	defer cfg.Close() //nolint:errcheck
-
-	client, err := cfg.GetClient(ctx)
+	sa, err := serviceaccount.Decode(saKey)
 	if err != nil {
-		return fmt.Errorf("error getting client: %w", err)
+		return fmt.Errorf("error decoding service account key: %w", err)
 	}
 
-	defer client.Close() //nolint:errcheck
+	keyID := sa.Key.Fingerprint()
 
-	keyID, keyIDSignatureBase64, err := clientconfig.RegisterKeyGetIDSignatureBase64(ctx, client)
+	signedIDBytes, err := sa.Key.Sign([]byte(keyID))
 	if err != nil {
-		return fmt.Errorf("error registering key: %w", err)
+		return fmt.Errorf("error signing key ID: %w", err)
 	}
 
 	cookies := []*http.Cookie{
 		{Name: workloadproxy.PublicKeyIDCookie, Value: keyID},
-		{Name: workloadproxy.PublicKeyIDSignatureBase64Cookie, Value: keyIDSignatureBase64},
+		{Name: workloadproxy.PublicKeyIDSignatureBase64Cookie, Value: base64.StdEncoding.EncodeToString(signedIDBytes)},
 	}
 
 	for _, cookie := range cookies {
diff --git a/cmd/omni/cmd/cmd.go b/cmd/omni/cmd/cmd.go
index 838e77c6..f2ac9b89 100644
--- a/cmd/omni/cmd/cmd.go
+++ b/cmd/omni/cmd/cmd.go
@@ -425,6 +425,7 @@ func defineStorageFlags(rootCmd *cobra.Command, rootCmdFlagBinder *FlagBinder, f
 
 	rootCmdFlagBinder.StringVar(config.SQLiteStoragePathFlag,
 		flagDescription("storage.sqlite.path", schema), &flagConfig.Storage.Sqlite.Path)
+
 	rootCmdFlagBinder.StringVar("sqlite-storage-experimental-base-params",
 		flagDescription("storage.sqlite.experimentalBaseParams", schema), &flagConfig.Storage.Sqlite.ExperimentalBaseParams)
 
@@ -432,6 +433,9 @@ func defineStorageFlags(rootCmd *cobra.Command, rootCmdFlagBinder *FlagBinder, f
 		flagDescription("storage.sqlite.extraParams", schema),
 		&flagConfig.Storage.Sqlite.ExtraParams)
 
+	rootCmdFlagBinder.StringVar("vault-k8s-auth-mount-path",
+		flagDescription("storage.vault.k8sAuthMountPath", schema), &flagConfig.Storage.Vault.K8SAuthMountPath)
+
 	return nil
 }
 
diff --git a/cmd/omni/pkg/app/app.go b/cmd/omni/pkg/app/app.go
index cc8c3bfd..e2a59f92 100644
--- a/cmd/omni/pkg/app/app.go
+++ b/cmd/omni/pkg/app/app.go
@@ -29,6 +29,7 @@ import (
 	"github.com/siderolabs/omni/internal/backend/runtime"
 	"github.com/siderolabs/omni/internal/backend/runtime/kubernetes"
 	"github.com/siderolabs/omni/internal/backend/runtime/omni"
+	"github.com/siderolabs/omni/internal/backend/runtime/omni/sqlite"
 	"github.com/siderolabs/omni/internal/backend/runtime/talos"
 	"github.com/siderolabs/omni/internal/backend/services/workloadproxy"
 	"github.com/siderolabs/omni/internal/pkg/auth"
@@ -120,6 +121,7 @@ func Run(ctx context.Context, state *omni.State, cfg *config.Params, logger *zap
 		state.Default(),
 		&cfg.Logs.Machine,
 		logger.With(logging.Component("siderolink_log_handler")),
+		siderolink.WithLogHandlerCleanupCallback(state.SQLiteMetrics().CleanupCallback(sqlite.SubsystemMachineLogs)),
 	)
 	if err != nil {
 		return fmt.Errorf("failed to set up log handler: %w", err)
diff --git a/deploy/helm/v2/omni/values.yaml b/deploy/helm/v2/omni/values.yaml
index a195221e..58079414 100644
--- a/deploy/helm/v2/omni/values.yaml
+++ b/deploy/helm/v2/omni/values.yaml
@@ -421,6 +421,10 @@ config:
       # Tip: Use additionalConfigSources to load this from an existing Secret,
       # or set the VAULT_TOKEN environment variable via env/envFrom.
       token: ""
+      # K8sAuthMountPath is the mount path of the Kubernetes auth method in Vault.
+      # When not set, it defaults to "kubernetes".
+      # This is useful when Vault is running on a different cluster and has multiple Kubernetes auth mounts.
+      #k8sAuthMountPath: ""
 
 # -- Environment variables to pass to Omni.
 env: []
diff --git a/frontend/.vscode/settings.json b/frontend/.vscode/settings.json
index 2fe05e42..762e03bd 100644
--- a/frontend/.vscode/settings.json
+++ b/frontend/.vscode/settings.json
@@ -8,7 +8,7 @@
     "*.css": "tailwindcss"
   },
   "javascript.preferences.importModuleSpecifier": "non-relative",
-  "tailwindCSS.classAttributes": ["class", "toast-options"],
+  "tailwindCSS.classAttributes": ["class", "toast-options", ".*-class"],
   "typescript.preferences.preferTypeOnlyAutoImports": true,
   "typescript.tsdk": "node_modules/typescript/lib"
 }
diff --git a/frontend/e2e/auth_fixtures.ts b/frontend/e2e/auth_fixtures.ts
index 61c9c8b7..748e2b4d 100644
--- a/frontend/e2e/auth_fixtures.ts
+++ b/frontend/e2e/auth_fixtures.ts
@@ -26,7 +26,6 @@ const test = base.extend<AuthFixtures>({
       await page.getByRole('textbox', { name: 'Password' }).fill(process.env.AUTH_PASSWORD)
       await page.getByRole('button', { name: 'Continue', exact: true }).click()
 
-      await page.getByRole('button', { name: 'Log In' }).click()
       await page.getByRole('heading', { name: 'Home' }).waitFor()
 
       if (await page.getByText('Cookies for a Better Experience').isVisible()) {
diff --git a/frontend/e2e/talemu/cluster_fixtures.ts b/frontend/e2e/talemu/cluster_fixtures.ts
index d4d03b17..19901249 100644
--- a/frontend/e2e/talemu/cluster_fixtures.ts
+++ b/frontend/e2e/talemu/cluster_fixtures.ts
@@ -28,7 +28,7 @@ const test = base.extend<ClusterFixtures>({
           kind: 'Cluster',
           name: clusterName,
           kubernetes: { version: 'v1.35.0' },
-          talos: { version: 'v1.12.1' },
+          talos: { version: 'v1.12.3' },
         },
         {
           kind: 'ControlPlane',
diff --git a/frontend/package-lock.json b/frontend/package-lock.json
index 5a60784b..67a9f986 100644
--- a/frontend/package-lock.json
+++ b/frontend/package-lock.json
@@ -13,6 +13,7 @@
         "@heroicons/vue": "^2.2.0",
         "@jsonforms/vue": "^3.7.0",
         "@jsonforms/vue-vanilla": "^3.7.0",
+        "@tanstack/vue-virtual": "^3.13.18",
         "@vueuse/components": "^14.2.0",
         "@vueuse/core": "^14.2.0",
         "@vueuse/integrations": "^14.2.0",
@@ -2977,9 +2978,9 @@
       }
     },
     "node_modules/@tanstack/virtual-core": {
-      "version": "3.13.16",
-      "resolved": "https://registry.npmjs.org/@tanstack/virtual-core/-/virtual-core-3.13.16.tgz",
-      "integrity": "sha512-njazUC8mDkrxWmyZmn/3eXrDcP8Msb3chSr4q6a65RmwdSbMlMCdnOphv6/8mLO7O3Fuza5s4M4DclmvAO5w0w==",
+      "version": "3.13.18",
+      "resolved": "https://registry.npmjs.org/@tanstack/virtual-core/-/virtual-core-3.13.18.tgz",
+      "integrity": "sha512-Mx86Hqu1k39icq2Zusq+Ey2J6dDWTjDvEv43PJtRCoEYTLyfaPnxIQ6iy7YAOK0NV/qOEmZQ/uCufrppZxTgcg==",
       "license": "MIT",
       "funding": {
         "type": "github",
@@ -2987,12 +2988,12 @@
       }
     },
     "node_modules/@tanstack/vue-virtual": {
-      "version": "3.13.16",
-      "resolved": "https://registry.npmjs.org/@tanstack/vue-virtual/-/vue-virtual-3.13.16.tgz",
-      "integrity": "sha512-0k6qO5eAwDIfHL3oWtV0RdY7b32kCFETyYUBYmQnU/ka0HHUngAN7ZyW+Urrkj1le2goELkRcrlC0FWEkMcLPQ==",
+      "version": "3.13.18",
+      "resolved": "https://registry.npmjs.org/@tanstack/vue-virtual/-/vue-virtual-3.13.18.tgz",
+      "integrity": "sha512-6pT8HdHtTU5Z+t906cGdCroUNA5wHjFXsNss9gwk7QAr1VNZtz9IQCs2Nhx0gABK48c+OocHl2As+TMg8+Hy4A==",
       "license": "MIT",
       "dependencies": {
-        "@tanstack/virtual-core": "3.13.16"
+        "@tanstack/virtual-core": "3.13.18"
       },
       "funding": {
         "type": "github",
diff --git a/frontend/package.json b/frontend/package.json
index 652e3aa1..fb4dd8bd 100644
--- a/frontend/package.json
+++ b/frontend/package.json
@@ -30,6 +30,7 @@
     "@heroicons/vue": "^2.2.0",
     "@jsonforms/vue": "^3.7.0",
     "@jsonforms/vue-vanilla": "^3.7.0",
+    "@tanstack/vue-virtual": "^3.13.18",
     "@vueuse/components": "^14.2.0",
     "@vueuse/core": "^14.2.0",
     "@vueuse/integrations": "^14.2.0",
diff --git a/frontend/prettier.config.ts b/frontend/prettier.config.ts
index e4824df0..abb99d35 100644
--- a/frontend/prettier.config.ts
+++ b/frontend/prettier.config.ts
@@ -11,7 +11,7 @@ const config: Config & PluginOptions = {
   printWidth: 100,
   plugins: ['prettier-plugin-tailwindcss'],
   htmlWhitespaceSensitivity: 'ignore',
-  tailwindAttributes: ['toast-options'],
+  tailwindAttributes: ['toast-options', '/.*-class/'],
   tailwindStylesheet: './src/index.css',
 }
 
diff --git a/frontend/src/api/common/common.pb.ts b/frontend/src/api/common/common.pb.ts
index 3d3e5236..7e16b49c 100644
--- a/frontend/src/api/common/common.pb.ts
+++ b/frontend/src/api/common/common.pb.ts
@@ -53,6 +53,11 @@ export type EmptyResponse = {
   messages?: Empty[]
 }
 
+export type ContainerdInstance = {
+  driver?: ContainerDriver
+  namespace?: ContainerdNamespace
+}
+
 export type URL = {
   full_path?: string
 }
diff --git a/frontend/src/api/common/common.proto b/frontend/src/api/common/common.proto
index 30a6b23e..1b155bd8 100644
--- a/frontend/src/api/common/common.proto
+++ b/frontend/src/api/common/common.proto
@@ -95,6 +95,13 @@ enum ContainerdNamespace {
   NS_CRI = 2;
 }
 
+message ContainerdInstance {
+  // Containerd instance to use.
+  ContainerDriver driver = 1;
+  // Containerd namespace to use.
+  ContainerdNamespace namespace = 2;
+}
+
 message URL {
   string full_path = 1;
 }
diff --git a/frontend/src/api/google/protobuf/any.proto b/frontend/src/api/google/protobuf/any.proto
index eff44e50..e95b5b49 100644
--- a/frontend/src/api/google/protobuf/any.proto
+++ b/frontend/src/api/google/protobuf/any.proto
@@ -42,121 +42,65 @@ option csharp_namespace = "Google.Protobuf.WellKnownTypes";
 // `Any` contains an arbitrary serialized protocol buffer message along with a
 // URL that describes the type of the serialized message.
 //
-// Protobuf library provides support to pack/unpack Any values in the form
-// of utility functions or additional generated methods of the Any type.
-//
-// Example 1: Pack and unpack a message in C++.
-//
-//     Foo foo = ...;
-//     Any any;
-//     any.PackFrom(foo);
-//     ...
-//     if (any.UnpackTo(&foo)) {
-//       ...
-//     }
-//
-// Example 2: Pack and unpack a message in Java.
-//
-//     Foo foo = ...;
-//     Any any = Any.pack(foo);
-//     ...
-//     if (any.is(Foo.class)) {
-//       foo = any.unpack(Foo.class);
-//     }
-//     // or ...
-//     if (any.isSameTypeAs(Foo.getDefaultInstance())) {
-//       foo = any.unpack(Foo.getDefaultInstance());
-//     }
-//
-//  Example 3: Pack and unpack a message in Python.
-//
-//     foo = Foo(...)
-//     any = Any()
-//     any.Pack(foo)
-//     ...
-//     if any.Is(Foo.DESCRIPTOR):
-//       any.Unpack(foo)
-//       ...
-//
-//  Example 4: Pack and unpack a message in Go
-//
-//      foo := &pb.Foo{...}
-//      any, err := anypb.New(foo)
-//      if err != nil {
-//        ...
-//      }
-//      ...
-//      foo := &pb.Foo{}
-//      if err := any.UnmarshalTo(foo); err != nil {
-//        ...
-//      }
-//
-// The pack methods provided by protobuf library will by default use
-// 'type.googleapis.com/full.type.name' as the type URL and the unpack
-// methods only use the fully qualified type name after the last '/'
-// in the type URL, for example "foo.bar.com/x/y.z" will yield type
-// name "y.z".
-//
-// JSON
-// ====
-// The JSON representation of an `Any` value uses the regular
-// representation of the deserialized, embedded message, with an
-// additional field `@type` which contains the type URL. Example:
-//
-//     package google.profile;
-//     message Person {
-//       string first_name = 1;
-//       string last_name = 2;
-//     }
-//
-//     {
-//       "@type": "type.googleapis.com/google.profile.Person",
-//       "firstName": <string>,
-//       "lastName": <string>
-//     }
-//
-// If the embedded message type is well-known and has a custom JSON
-// representation, that representation will be embedded adding a field
-// `value` which holds the custom JSON in addition to the `@type`
-// field. Example (for message [google.protobuf.Duration][]):
-//
-//     {
-//       "@type": "type.googleapis.com/google.protobuf.Duration",
-//       "value": "1.212s"
-//     }
-//
+// In its binary encoding, an `Any` is an ordinary message; but in other wire
+// forms like JSON, it has a special encoding. The format of the type URL is
+// described on the `type_url` field.
+//
+// Protobuf APIs provide utilities to interact with `Any` values:
+//
+// - A 'pack' operation accepts a message and constructs a generic `Any` wrapper
+//   around it.
+// - An 'unpack' operation reads the content of an `Any` message, either into an
+//   existing message or a new one. Unpack operations must check the type of the
+//   value they unpack against the declared `type_url`.
+// - An 'is' operation decides whether an `Any` contains a message of the given
+//   type, i.e. whether it can 'unpack' that type.
+//
+// The JSON format representation of an `Any` follows one of these cases:
+//
+// - For types without special-cased JSON encodings, the JSON format
+//   representation of the `Any` is the same as that of the message, with an
+//   additional `@type` field which contains the type URL.
+// - For types with special-cased JSON encodings (typically called 'well-known'
+//   types, listed in https://protobuf.dev/programming-guides/json/#any), the
+//   JSON format representation has a key `@type` which contains the type URL
+//   and a key `value` which contains the JSON-serialized value.
+//
+// The text format representation of an `Any` is like a message with one field
+// whose name is the type URL in brackets. For example, an `Any` containing a
+// `foo.Bar` message may be written `[type.googleapis.com/foo.Bar] { a: 2 }`.
 message Any {
-  // A URL/resource name that uniquely identifies the type of the serialized
-  // protocol buffer message. This string must contain at least
-  // one "/" character. The last segment of the URL's path must represent
-  // the fully qualified name of the type (as in
-  // `path/google.protobuf.Duration`). The name should be in a canonical form
-  // (e.g., leading "." is not accepted).
+  // Identifies the type of the serialized Protobuf message with a URI reference
+  // consisting of a prefix ending in a slash and the fully-qualified type name.
   //
-  // In practice, teams usually precompile into the binary all types that they
-  // expect it to use in the context of Any. However, for URLs which use the
-  // scheme `http`, `https`, or no scheme, one can optionally set up a type
-  // server that maps type URLs to message definitions as follows:
+  // Example: type.googleapis.com/google.protobuf.StringValue
   //
-  // * If no scheme is provided, `https` is assumed.
-  // * An HTTP GET on the URL must yield a [google.protobuf.Type][]
-  //   value in binary format, or produce an error.
-  // * Applications are allowed to cache lookup results based on the
-  //   URL, or have them precompiled into a binary to avoid any
-  //   lookup. Therefore, binary compatibility needs to be preserved
-  //   on changes to types. (Use versioned type names to manage
-  //   breaking changes.)
+  // This string must contain at least one `/` character, and the content after
+  // the last `/` must be the fully-qualified name of the type in canonical
+  // form, without a leading dot. Do not write a scheme on these URI references
+  // so that clients do not attempt to contact them.
   //
-  // Note: this functionality is not currently available in the official
-  // protobuf release, and it is not used for type URLs beginning with
-  // type.googleapis.com. As of May 2023, there are no widely used type server
-  // implementations and no plans to implement one.
+  // The prefix is arbitrary and Protobuf implementations are expected to
+  // simply strip off everything up to and including the last `/` to identify
+  // the type. `type.googleapis.com/` is a common default prefix that some
+  // legacy implementations require. This prefix does not indicate the origin of
+  // the type, and URIs containing it are not expected to respond to any
+  // requests.
   //
-  // Schemes other than `http`, `https` (or the empty scheme) might be
-  // used with implementation specific semantics.
+  // All type URL strings must be legal URI references with the additional
+  // restriction (for the text format) that the content of the reference
+  // must consist only of alphanumeric characters, percent-encoded escapes, and
+  // characters in the following set (not including the outer backticks):
+  // `/-.~_!$&()*+,;=`. Despite our allowing percent encodings, implementations
+  // should not unescape them to prevent confusion with existing parsers. For
+  // example, `type.googleapis.com%2FFoo` should be rejected.
   //
+  // In the original design of `Any`, the possibility of launching a type
+  // resolution service at these type URLs was considered but Protobuf never
+  // implemented one and considers contacting these URLs to be problematic and
+  // a potential security issue. Do not attempt to contact type URLs.
   string type_url = 1;
 
-  // Must be a valid serialized protocol buffer of the above specified type.
+  // Holds a Protobuf serialization of the type described by type_url.
   bytes value = 2;
 }
diff --git a/frontend/src/api/resources.ts b/frontend/src/api/resources.ts
index 7be98161..c7353572 100644
--- a/frontend/src/api/resources.ts
+++ b/frontend/src/api/resources.ts
@@ -25,12 +25,12 @@ export const samlSessionHeader = "saml-session";
 export const SignedRedirect = "v1:";
 export const workloadProxyPublicKeyIdCookie = "publicKeyId";
 export const workloadProxyPublicKeyIdSignatureBase64Cookie = "publicKeyIdSignatureBase64";
-export const DefaultKubernetesVersion = "1.35.0";
+export const DefaultKubernetesVersion = "1.35.1";
 export const installDiskMinSize = 5e+09;
 export const MaxJoinTokenNameLength = 16;
 export const authPublicKeyIDQueryParam = "public-key-id";
 export const SecureBoot = "secureboot";
-export const DefaultTalosVersion = "1.12.1";
+export const DefaultTalosVersion = "1.12.3";
 export const MinTalosVersion = "1.8.0";
 export const PatchWeightInstallDisk = 0;
 export const PatchBaseWeightCluster = 200;
diff --git a/frontend/src/api/talos/machine/machine.proto b/frontend/src/api/talos/machine/machine.proto
index d8abddbf..10d92e82 100644
--- a/frontend/src/api/talos/machine/machine.proto
+++ b/frontend/src/api/talos/machine/machine.proto
@@ -100,9 +100,19 @@ service MachineService {
   // MetaDelete deletes a META key.
   rpc MetaDelete(MetaDeleteRequest) returns (MetaDeleteResponse);
   // ImageList lists images in the CRI.
-  rpc ImageList(ImageListRequest) returns (stream ImageListResponse);
+  //
+  // Use ImageService List RPC instead.
+  rpc ImageList(ImageListRequest) returns (stream ImageListResponse) {
+    option (common.remove_deprecated_method) = "v1.18";
+    option deprecated = true;
+  }
   // ImagePull pulls an image into the CRI.
-  rpc ImagePull(ImagePullRequest) returns (ImagePullResponse);
+  //
+  // Use ImageService Pull RPC instead.
+  rpc ImagePull(ImagePullRequest) returns (ImagePullResponse) {
+    option (common.remove_deprecated_method) = "v1.18";
+    option deprecated = true;
+  }
 }
 
 // rpc applyConfiguration
diff --git a/frontend/src/components/common/DiffRenderer/DiffRenderer.stories.ts b/frontend/src/components/common/DiffRenderer/DiffRenderer.stories.ts
new file mode 100644
index 00000000..0d78802b
--- /dev/null
+++ b/frontend/src/components/common/DiffRenderer/DiffRenderer.stories.ts
@@ -0,0 +1,19 @@
+// Copyright (c) 2026 Sidero Labs, Inc.
+//
+// Use of this software is governed by the Business Source License
+// included in the LICENSE file.
+import type { Meta, StoryObj } from '@storybook/vue3-vite'
+
+import DiffRenderer from './DiffRenderer.vue'
+
+const meta: Meta<typeof DiffRenderer> = {
+  component: DiffRenderer,
+  args: {
+    withSearch: true,
+  },
+}
+
+export default meta
+type Story = StoryObj<typeof meta>
+
+export const Default: Story = {}
diff --git a/frontend/src/components/common/DiffRenderer/DiffRenderer.vue b/frontend/src/components/common/DiffRenderer/DiffRenderer.vue
new file mode 100644
index 00000000..1a61b85d
--- /dev/null
+++ b/frontend/src/components/common/DiffRenderer/DiffRenderer.vue
@@ -0,0 +1,150 @@
+<!--
+Copyright (c) 2026 Sidero Labs, Inc.
+
+Use of this software is governed by the Business Source License
+included in the LICENSE file.
+-->
+<script setup lang="ts">
+import { useVirtualizer, type VirtualItem } from '@tanstack/vue-virtual'
+import { refDebounced } from '@vueuse/core'
+import { type ComponentPublicInstance, computed, markRaw, ref, useTemplateRef, watch } from 'vue'
+import WordHighlighter from 'vue-word-highlighter'
+
+import IconButton from '@/components/common/Button/IconButton.vue'
+import TInput from '@/components/common/TInput/TInput.vue'
+
+const { diff, withSearch } = defineProps<{
+  diff: string
+  withSearch?: boolean
+}>()
+
+const scrollContainer = useTemplateRef('scrollContainerRef')
+
+const parsedLines = computed(() =>
+  markRaw(
+    diff.split('\n').map((line) => ({
+      line,
+      type: line.startsWith('#')
+        ? 'comment'
+        : line.startsWith('+')
+          ? 'add'
+          : line.startsWith('-')
+            ? 'remove'
+            : line.startsWith('@@')
+              ? 'chunk'
+              : 'neutral',
+    })),
+  ),
+)
+
+const rowVirtualizer = useVirtualizer(
+  computed(() => ({
+    count: parsedLines.value.length,
+    getScrollElement: () => scrollContainer.value,
+    estimateSize: () => 26,
+    overscan: 10,
+  })),
+)
+
+const virtualRows = computed(() => rowVirtualizer.value.getVirtualItems())
+const totalHeight = computed(() => rowVirtualizer.value.getTotalSize())
+
+const search = ref('')
+const searchDebounced = refDebounced(search, 300)
+const currentMatchIndex = ref(0)
+
+watch(searchDebounced, () => {
+  currentMatchIndex.value = 0
+  scrollToMatch()
+})
+
+const matchedLines = computed(() => {
+  if (!withSearch || !searchDebounced.value) return []
+
+  const lowered = searchDebounced.value.toLowerCase()
+
+  return parsedLines.value.reduce<number[]>((prev, curr, i) => {
+    if (curr.line.toLowerCase().includes(lowered)) {
+      prev.push(i)
+    }
+
+    return prev
+  }, [])
+})
+
+function scrollToMatch() {
+  if (!matchedLines.value.length) return
+  const targetLineIndex = matchedLines.value[currentMatchIndex.value]
+
+  rowVirtualizer.value.scrollToIndex(targetLineIndex, { align: 'center' })
+}
+
+function nextMatch() {
+  if (!matchedLines.value.length) return
+
+  currentMatchIndex.value = (currentMatchIndex.value + 1) % matchedLines.value.length
+
+  scrollToMatch()
+}
+
+function prevMatch() {
+  if (!matchedLines.value.length) return
+
+  currentMatchIndex.value =
+    (currentMatchIndex.value - 1 + matchedLines.value.length) % matchedLines.value.length
+
+  scrollToMatch()
+}
+
+function getRowKey(row: VirtualItem) {
+  return row.key as number | string
+}
+
+function measureElement(el?: Element | ComponentPublicInstance | null) {
+  if (el) rowVirtualizer.value.measureElement(el as Element)
+}
+</script>
+
+<template>
+  <div class="flex flex-col gap-4">
+    <div v-if="withSearch" class="flex items-center gap-2">
+      <TInput v-model.trim="search" title="Search" class="grow" @keydown.enter="nextMatch" />
+
+      <div class="flex gap-1">
+        <IconButton :disabled="!matchedLines.length" icon="arrow-up" @click="prevMatch" />
+        <IconButton :disabled="!matchedLines.length" icon="arrow-down" @click="nextMatch" />
+      </div>
+    </div>
+
+    <div ref="scrollContainerRef" class="h-full overflow-y-auto font-mono text-sm/relaxed">
+      <div class="relative text-naturals-n14" :style="{ height: `${totalHeight}px` }">
+        <div
+          class="absolute top-0 left-0"
+          :style="{ transform: `translateY(${virtualRows[0]?.start ?? 0}px)` }"
+        >
+          <div
+            v-for="virtualRow in virtualRows"
+            :key="getRowKey(virtualRow)"
+            :ref="measureElement"
+            :data-index="virtualRow.index"
+            class="px-2 py-0.5 break-all whitespace-pre-wrap"
+            :class="{
+              'text-naturals-n10': parsedLines[virtualRow.index].type === 'comment',
+              'text-green-g1': parsedLines[virtualRow.index].type === 'add',
+              'text-red-r1': parsedLines[virtualRow.index].type === 'remove',
+              'text-blue-b1': parsedLines[virtualRow.index].type === 'chunk',
+            }"
+          >
+            <WordHighlighter
+              v-if="withSearch"
+              :query="searchDebounced"
+              :text-to-highlight="parsedLines[virtualRow.index].line"
+              highlight-class="bg-naturals-n14"
+            />
+            <template v-else>{{ parsedLines[virtualRow.index].line }}</template>
+          </div>
+        </div>
+      </div>
+    </div>
+  </div>
+</template>
diff --git a/frontend/src/components/common/SelectList/TSelectList.vue b/frontend/src/components/common/SelectList/TSelectList.vue
index e7022452..1e6f9faa 100644
--- a/frontend/src/components/common/SelectList/TSelectList.vue
+++ b/frontend/src/components/common/SelectList/TSelectList.vue
@@ -195,7 +195,7 @@ function labelFromValue(value?: T) {
                 <WordHighligher
                   :query="searchTerm"
                   :text-to-highlight="itemLabel(item)"
-                  highlight-class="text-naturals-n14 font-medium bg-transparent truncate"
+                  highlight-class="truncate bg-transparent font-medium text-naturals-n14"
                 />
               </SelectItemText>
 
diff --git a/frontend/src/components/common/Tabs/Tabs.vue b/frontend/src/components/common/Tabs/Tabs.vue
index 13366d1d..8c3c8164 100644
--- a/frontend/src/components/common/Tabs/Tabs.vue
+++ b/frontend/src/components/common/Tabs/Tabs.vue
@@ -5,6 +5,8 @@ Use of this software is governed by the Business Source License
 included in the LICENSE file.
 -->
 <script setup lang="ts">
+import { reactiveOmit } from '@vueuse/core'
+import type { ClassValue } from 'clsx'
 import {
   TabsIndicator,
   TabsList,
@@ -14,9 +16,17 @@ import {
   useForwardPropsEmits,
 } from 'reka-ui'
 
-const props = defineProps<TabsRootProps>()
+import { cn } from '@/methods/utils'
+
+interface Props extends TabsRootProps {
+  tabsListClass?: ClassValue
+}
+
+const props = defineProps<Props>()
 const emits = defineEmits<TabsRootEmits>()
-const forwarded = useForwardPropsEmits(props, emits)
+
+const tabsRootProps = reactiveOmit(props, 'tabsListClass')
+const forwarded = useForwardPropsEmits(tabsRootProps, emits)
 
 defineSlots<{
   triggers(): unknown
@@ -26,7 +36,14 @@ defineSlots<{
 
 <template>
   <TabsRoot class="flex flex-col" v-bind="forwarded">
-    <TabsList class="relative flex shrink-0 gap-6 border-b border-naturals-n4 pb-3.5">
+    <TabsList
+      :class="
+        cn(
+          'relative flex shrink-0 gap-6 overflow-x-auto overflow-y-hidden border-b border-naturals-n4 pb-3.5 whitespace-nowrap',
+          tabsListClass,
+        )
+      "
+    >
       <TabsIndicator
         class="absolute bottom-0 left-0 h-0.5 w-(--reka-tabs-indicator-size) translate-x-(--reka-tabs-indicator-position) translate-y-px transition-[width,translate] duration-300"
       >
diff --git a/frontend/src/methods/index.spec.ts b/frontend/src/methods/index.spec.ts
index 0fe94e1b..5d707d28 100644
--- a/frontend/src/methods/index.spec.ts
+++ b/frontend/src/methods/index.spec.ts
@@ -48,10 +48,10 @@ test.each`
 test.each`
   version                    | expected
   ${'1.13.0'}                | ${'1.13'}
-  ${'1.12.1'}                | ${'1.12'}
+  ${'1.12.3'}                | ${'1.12'}
   ${'1.11'}                  | ${'1.11'}
   ${'v1.13.0'}               | ${'1.13'}
-  ${'v1.12.1'}               | ${'1.12'}
+  ${'v1.12.3'}               | ${'1.12'}
   ${'v1.11'}                 | ${'1.11'}
   ${'v2'}                    | ${'2.0'}
   ${'this is not a version'} | ${'0.0'}
diff --git a/frontend/src/router/index.ts b/frontend/src/router/index.ts
index 47e41681..dc7c96ee 100644
--- a/frontend/src/router/index.ts
+++ b/frontend/src/router/index.ts
@@ -151,6 +151,7 @@ export const routes: RouteRecordRaw[] = [
                   {
                     path: '',
                     name: 'NodeDetails',
+                    meta: { disablePadding: true },
                     component: () => import('@/views/cluster/Nodes/NodeDetails.vue'),
                     children: [
                       {
@@ -173,6 +174,16 @@ export const routes: RouteRecordRaw[] = [
                         name: 'NodeConfig',
                         component: () => import('@/views/cluster/Nodes/NodeConfig.vue'),
                       },
+                      {
+                        path: 'pending-updates',
+                        name: 'NodePendingUpdates',
+                        component: () => import('@/views/cluster/Nodes/NodePendingUpdates.vue'),
+                      },
+                      {
+                        path: 'config-diffs',
+                        name: 'NodeConfigDiffs',
+                        component: () => import('@/views/cluster/Nodes/NodeConfigDiffs.vue'),
+                      },
                       {
                         path: 'patches',
                         name: 'NodePatches',
diff --git a/frontend/src/views/cluster/ClusterMachines/ClusterMachine.vue b/frontend/src/views/cluster/ClusterMachines/ClusterMachine.vue
index 9645277c..983969e6 100644
--- a/frontend/src/views/cluster/ClusterMachines/ClusterMachine.vue
+++ b/frontend/src/views/cluster/ClusterMachines/ClusterMachine.vue
@@ -5,7 +5,7 @@ Use of this software is governed by the Business Source License
 included in the LICENSE file.
 -->
 <script setup lang="ts">
-import { computed, toRefs } from 'vue'
+import { computed } from 'vue'
 import { useRouter } from 'vue-router'
 
 import type { Resource } from '@/api/grpc'
@@ -28,62 +28,57 @@ import NodeContextMenu from '@/views/common/NodeContextMenu.vue'
 
 import ClusterMachinePhase from './ClusterMachinePhase.vue'
 
-const props = defineProps<{
+const { machine } = defineProps<{
   machine: Resource<ClusterMachineStatusSpec>
   deleteDisabled?: boolean
   hasDiagnosticInfo?: boolean
 }>()
 
-const { machine } = toRefs(props)
-
 const icon = computed(() => {
-  if (machine.value.metadata.labels?.[LabelIsManagedByStaticInfraProvider] !== undefined) {
+  if (machine.metadata.labels?.[LabelIsManagedByStaticInfraProvider] !== undefined) {
     return 'server-network'
   }
 
-  return Object.keys(machine.value.spec.provision_status ?? {}).length
-    ? 'cloud-connection'
-    : 'server'
+  return Object.keys(machine.spec.provision_status ?? {}).length ? 'cloud-connection' : 'server'
 })
 
 const locked = computed(() => {
-  return machine.value?.metadata?.annotations?.[MachineLocked] !== undefined
+  return machine.metadata.annotations?.[MachineLocked] !== undefined
 })
 
 const lockable = computed(() => {
-  return machine?.value.metadata?.labels?.[LabelWorkerRole] !== undefined
+  return machine.metadata.labels?.[LabelWorkerRole] !== undefined
 })
 
 const router = useRouter()
 
 const hostname = computed(() => {
-  const labelHostname = props.machine?.metadata?.labels?.[LabelHostname]
-  return labelHostname && labelHostname !== '' ? labelHostname : props.machine?.metadata.id
+  const labelHostname = machine.metadata.labels?.[LabelHostname]
+  return labelHostname && labelHostname !== '' ? labelHostname : machine.metadata.id
 })
 const nodeName = computed(
-  () =>
-    (props.machine?.metadata?.labels || {})[ClusterMachineStatusLabelNodeName] || hostname.value,
+  () => machine.metadata.labels?.[ClusterMachineStatusLabelNodeName] || hostname.value,
 )
-const clusterName = computed(() => (props.machine?.metadata?.labels || {})[LabelCluster])
+const clusterName = computed(() => (machine.metadata?.labels || {})[LabelCluster])
 
 const openNodeInfo = async () => {
   router.push({
     name: 'NodeOverview',
-    params: { cluster: clusterName.value, machine: props.machine.metadata.id },
+    params: { cluster: clusterName.value, machine: machine.metadata.id },
   })
 }
 
 const lockedUpdate = computed(() => {
-  return machine.value.metadata.labels?.[UpdateLocked] !== undefined
+  return machine.metadata.labels?.[UpdateLocked] !== undefined
 })
 
 const updateLock = async () => {
-  if (!props.machine.metadata.id) {
+  if (!machine.metadata.id) {
     return
   }
 
   try {
-    await updateMachineLock(props.machine.metadata.id, !locked.value)
+    await updateMachineLock(machine.metadata.id, !locked.value)
   } catch (e) {
     showError('Failed To Update Machine Lock', e.message)
   }
@@ -110,10 +105,18 @@ const updateLock = async () => {
 
     <div class="col-span-2 flex items-center gap-2">
       <ClusterMachinePhase :machine="machine" />
-      <div v-if="lockedUpdate" class="flex items-center gap-1 truncate text-sky-400">
+      <RouterLink
+        v-if="lockedUpdate"
+        :to="{
+          name: 'NodePendingUpdates',
+          params: { cluster: clusterName, machine: machine.metadata.id },
+        }"
+        class="flex items-center gap-1 truncate text-sky-400"
+        @click.stop
+      >
         <TIcon icon="time" class="h-4 w-4 min-w-max" />
         <div class="flex-1 truncate">Pending Config Update</div>
-      </div>
+      </RouterLink>
     </div>
 
     <div class="flex items-center justify-end">
diff --git a/frontend/src/views/cluster/Nodes/NodeConfigDiffs.vue b/frontend/src/views/cluster/Nodes/NodeConfigDiffs.vue
new file mode 100644
index 00000000..2dd359ed
--- /dev/null
+++ b/frontend/src/views/cluster/Nodes/NodeConfigDiffs.vue
@@ -0,0 +1,54 @@
+<!--
+Copyright (c) 2026 Sidero Labs, Inc.
+
+Use of this software is governed by the Business Source License
+included in the LICENSE file.
+-->
+<script setup lang="ts">
+import { computed } from 'vue'
+import { useRoute } from 'vue-router'
+
+import { Runtime } from '@/api/common/omni.pb'
+import type { MachineConfigDiffSpec } from '@/api/omni/specs/omni.pb'
+import { DefaultNamespace, LabelMachine, MachineConfigDiffType } from '@/api/resources'
+import DiffRenderer from '@/components/common/DiffRenderer/DiffRenderer.vue'
+import TSpinner from '@/components/common/Spinner/TSpinner.vue'
+import TAlert from '@/components/TAlert.vue'
+import { formatISO } from '@/methods/time'
+import { useResourceWatch } from '@/methods/useResourceWatch'
+
+const route = useRoute()
+
+const machineId = computed(() => route.params.machine.toString())
+
+const { data: configDiffs, loading: diffsLoading } = useResourceWatch<MachineConfigDiffSpec>(
+  () => ({
+    runtime: Runtime.Omni,
+    resource: {
+      namespace: DefaultNamespace,
+      type: MachineConfigDiffType,
+    },
+    selectors: [`${LabelMachine}=${machineId.value}`],
+  }),
+)
+
+const combinedDiff = computed(() =>
+  configDiffs.value
+    .map((d) => `# Created on ${formatISO(d.metadata.created!)}\n${d.spec.diff}`)
+    .join('\n'),
+)
+</script>
+
+<template>
+  <div>
+    <template v-if="!diffsLoading">
+      <TAlert v-if="!combinedDiff" type="info" title="No Records">
+        No previously applied config diffs found for this machine
+      </TAlert>
+
+      <DiffRenderer class="h-full" :diff="combinedDiff" with-search />
+    </template>
+
+    <TSpinner v-else class="mx-auto my-8 size-6" />
+  </div>
+</template>
diff --git a/frontend/src/views/cluster/Nodes/NodeDetails.vue b/frontend/src/views/cluster/Nodes/NodeDetails.vue
index 66145b06..860ad5d4 100644
--- a/frontend/src/views/cluster/Nodes/NodeDetails.vue
+++ b/frontend/src/views/cluster/Nodes/NodeDetails.vue
@@ -34,6 +34,14 @@ const routes = computed(() => {
       name: 'Config',
       to: { name: 'NodeConfig', params: { machine: machine.value } },
     },
+    {
+      name: 'Pending Updates',
+      to: { name: 'NodePendingUpdates', params: { machine: machine.value } },
+    },
+    {
+      name: 'Config History',
+      to: { name: 'NodeConfigDiffs', params: { machine: machine.value } },
+    },
     {
       name: 'Patches',
       to: { name: 'NodePatches', params: { machine: machine.value } },
@@ -51,10 +59,14 @@ const routes = computed(() => {
 </script>
 
 <template>
-  <div class="flex h-full flex-col">
-    <NodesHeader />
+  <div class="flex h-full flex-col pt-6">
+    <NodesHeader class="px-4 md:px-6" />
 
-    <Tabs :model-value="$route.name?.toString()" class="grow">
+    <Tabs
+      :model-value="$route.name?.toString()"
+      class="grow overflow-y-hidden"
+      tabs-list-class="px-4 md:px-6"
+    >
       <template #triggers>
         <TabButton v-for="{ name, to } in routes" :key="name" :as="RouterLink" :value="to.name" :to>
           {{ name }}
@@ -62,7 +74,13 @@ const routes = computed(() => {
       </template>
 
       <template #contents>
-        <TabContent v-for="{ name, to } in routes" :key="name" class="mt-4 grow" :value="to.name">
+        <TabContent
+          v-for="{ name, to } in routes"
+          :key="name"
+          class="mt-4 grow overflow-y-auto"
+          :class="{ 'px-4 md:px-6': to.name !== 'NodeExtensions' }"
+          :value="to.name"
+        >
           <RouterView class="h-full" />
         </TabContent>
       </template>
diff --git a/frontend/src/views/cluster/Nodes/NodeExtensions.vue b/frontend/src/views/cluster/Nodes/NodeExtensions.vue
index 41814047..c09460bc 100644
--- a/frontend/src/views/cluster/Nodes/NodeExtensions.vue
+++ b/frontend/src/views/cluster/Nodes/NodeExtensions.vue
@@ -168,19 +168,21 @@ const openExtensionsUpdate = () => {
 </script>
 
 <template>
-  <div class="flex flex-1 flex-col">
-    <div class="flex flex-1 flex-col gap-4 pb-10">
+  <div class="flex flex-col">
+    <div class="flex grow flex-col gap-4 px-4 md:px-6">
       <TInput v-model="searchString" icon="search" />
       <div class="flex flex-1 flex-col">
         <template v-if="ready && extensionsState.length > 0">
-          <div class="header list-grid">
+          <div
+            class="mb-1 grid grid-cols-3 items-center justify-center bg-naturals-n2 px-6 py-2 text-xs"
+          >
             <div>Name</div>
             <div>State</div>
             <div>Level</div>
           </div>
           <TListItem v-for="item in extensionsState" :key="item.name">
             <div class="flex gap-2 px-3">
-              <div class="list-grid flex-1 text-naturals-n12">
+              <div class="grid flex-1 grid-cols-3 items-center justify-center text-naturals-n12">
                 <WordHighlighter
                   :query="searchString"
                   :text-to-highlight="item.name"
@@ -225,8 +227,9 @@ const openExtensionsUpdate = () => {
         </div>
       </div>
     </div>
+
     <div
-      class="sticky -bottom-6 -mx-6 -my-6 flex h-16 items-center justify-end gap-2 border-t border-naturals-n5 bg-naturals-n1 px-12 py-6 text-xs"
+      class="flex h-16 items-center justify-end border-t border-naturals-n5 bg-naturals-n1 px-12"
     >
       <TButton variant="highlighted" :disabled="!canUpdateTalos" @click="openExtensionsUpdate">
         Update Extensions
@@ -234,15 +237,3 @@ const openExtensionsUpdate = () => {
     </div>
   </div>
 </template>
-
-<style scoped>
-@reference "../../../index.css";
-
-.list-grid {
-  @apply grid grid-cols-3 items-center justify-center;
-}
-
-.header {
-  @apply mb-1 bg-naturals-n2 px-6 py-2 text-xs;
-}
-</style>
diff --git a/frontend/src/views/cluster/Nodes/NodePendingUpdates.vue b/frontend/src/views/cluster/Nodes/NodePendingUpdates.vue
new file mode 100644
index 00000000..55219f7a
--- /dev/null
+++ b/frontend/src/views/cluster/Nodes/NodePendingUpdates.vue
@@ -0,0 +1,45 @@
+<!--
+Copyright (c) 2026 Sidero Labs, Inc.
+
+Use of this software is governed by the Business Source License
+included in the LICENSE file.
+-->
+<script setup lang="ts">
+import { computed } from 'vue'
+import { useRoute } from 'vue-router'
+
+import { Runtime } from '@/api/common/omni.pb'
+import type { MachinePendingUpdatesSpec } from '@/api/omni/specs/omni.pb'
+import { DefaultNamespace, MachinePendingUpdatesType } from '@/api/resources'
+import DiffRenderer from '@/components/common/DiffRenderer/DiffRenderer.vue'
+import TSpinner from '@/components/common/Spinner/TSpinner.vue'
+import TAlert from '@/components/TAlert.vue'
+import { useResourceWatch } from '@/methods/useResourceWatch'
+
+const route = useRoute()
+
+const machineId = computed(() => route.params.machine.toString())
+
+const { data, loading } = useResourceWatch<MachinePendingUpdatesSpec>(() => ({
+  runtime: Runtime.Omni,
+  resource: {
+    namespace: DefaultNamespace,
+    type: MachinePendingUpdatesType,
+    id: machineId.value,
+  },
+}))
+</script>
+
+<template>
+  <div class="flex flex-col gap-4">
+    <template v-if="!loading">
+      <TAlert v-if="!data?.spec.config_diff" type="info" title="No Records">
+        No pending config updates found for this machine
+      </TAlert>
+
+      <DiffRenderer v-else :diff="data.spec.config_diff" with-search />
+    </template>
+
+    <TSpinner v-else class="mx-auto my-8 size-6" />
+  </div>
+</template>
diff --git a/frontend/src/views/omni/Auth/Authenticate.vue b/frontend/src/views/omni/Auth/Authenticate.vue
index 50c1628b..558256b7 100644
--- a/frontend/src/views/omni/Auth/Authenticate.vue
+++ b/frontend/src/views/omni/Auth/Authenticate.vue
@@ -9,7 +9,7 @@ import type { User } from '@auth0/auth0-spa-js'
 import type { Auth0VueClient } from '@auth0/auth0-vue'
 import { useAuth0 } from '@auth0/auth0-vue'
 import { jwtDecode } from 'jwt-decode'
-import { computed, onMounted, ref } from 'vue'
+import { computed, onMounted, ref, watch } from 'vue'
 import { useRoute, useRouter } from 'vue-router'
 
 import { b64Encode, type fetchOption } from '@/api/fetch.pb'
@@ -31,6 +31,7 @@ import {
 } from '@/api/resources'
 import TButton from '@/components/common/Button/TButton.vue'
 import TIcon from '@/components/common/Icon/TIcon.vue'
+import TSpinner from '@/components/common/Spinner/TSpinner.vue'
 import UserInfo from '@/components/common/UserInfo/UserInfo.vue'
 import { AuthType, authType } from '@/methods'
 import { useLogout } from '@/methods/auth'
@@ -78,10 +79,6 @@ onMounted(() => {
   }
 })
 
-const authenticated = computed(() => {
-  return identity.value
-})
-
 const identity = computed(() => {
   switch (authType.value) {
     case AuthType.Auth0:
@@ -129,39 +126,49 @@ const picture = computed(() => {
 
 const router = useRouter()
 
-let publicKeyId = route.query[authPublicKeyIDQueryParam] as string
+const publicKeyId = computed(() => route.query[authPublicKeyIDQueryParam]?.toString())
 
 const confirmed = ref(false)
 
-let redirect: string = route.query[RedirectQueryParam] as string
-
 const logout = useLogout()
 const keys = useKeys()
 const identityStorage = useIdentity()
+const keysGenerating = ref(false)
+const keysAutoGenerated = ref(false)
 
-const generatePublicKey = async () => {
-  if (!identity.value) {
-    return
-  }
+const generatePublicKey = async (identity: string) => {
+  if (keysGenerating.value) return
 
-  const res = await createKeys(identity.value)
+  keysAutoGenerated.value = true
+  keysGenerating.value = true
 
-  publicKeyId = res.publicKeyId
+  let res: Awaited<ReturnType<typeof createKeys>>
 
   try {
-    await confirmPublicKey(res.keyPair)
+    res = await createKeys(identity)
+  } catch (e) {
+    showError('Failed to generate keys', e instanceof Error ? e.message : String(e))
+    keysGenerating.value = false
+    return
+  }
+
+  try {
+    await confirmPublicKey(res.publicKeyId, res.keyPair)
   } catch {
+    keysGenerating.value = false
     return
   }
 
   keys.keyPair.value = res.keyPair
   keys.keyExpirationTime.value = res.keyExpirationTime
-  keys.publicKeyID.value = publicKeyId
+  keys.publicKeyID.value = res.publicKeyId
 
-  identityStorage.identity.value = identity.value.toLowerCase()
+  identityStorage.identity.value = identity.toLowerCase()
   identityStorage.fullname.value = name.value ?? ''
   identityStorage.avatar.value = picture.value ?? ''
 
+  const redirect = route.query[RedirectQueryParam]?.toString()
+
   if (!redirect) {
     return
   }
@@ -172,17 +179,15 @@ const generatePublicKey = async () => {
     return
   }
 
-  if (redirect.indexOf('/') !== 0) {
-    redirect = '/'
-  }
-
-  await router.replace({ path: redirect })
+  await router.replace({ path: !redirect.startsWith('/') ? '/' : redirect })
 }
 
 let renewIdToken = false
 
-const confirmPublicKey = async (keyPair?: CryptoKeyPair) => {
+const confirmPublicKey = async (publicKeyId: string, keyPair?: CryptoKeyPair) => {
   try {
+    // If the JWT validation has failed on the backend at the moment of clicking "Login", get a new ID token from Auth0 on the next click.
+    // This way, the user will not have to reload the page after validating their email - they can simply click "Login" again to get in.
     if (renewIdToken && auth0) {
       renewIdToken = false
 
@@ -242,7 +247,28 @@ const Auth = {
   CLI: CLIAuthFlow,
   Frontend: FrontendAuthFlow,
   WorkloadProxy: WorkloadProxyAuthFlow,
-}
+} as const
+
+const authFlow = computed(
+  () => route.query[AuthFlowQueryParam] as (typeof Auth)[keyof typeof Auth] | undefined,
+)
+
+// For the frontend flow, we automatically generate keys for the user
+// Will only attempt this once, however, then fallback to the form
+watch(
+  [authFlow, identity],
+  () => {
+    if (
+      authFlow.value === Auth.Frontend &&
+      identity.value &&
+      !keysAutoGenerated.value &&
+      !keysGenerating.value
+    ) {
+      generatePublicKey(identity.value)
+    }
+  },
+  { immediate: true },
+)
 </script>
 
 <template>
@@ -251,61 +277,52 @@ const Auth = {
       <div class="flex items-center gap-4">
         <TIcon icon="key" class="fill-color h-6 w-6" />
         <div class="text-xl font-bold text-naturals-n13">
-          <div v-if="$route.query[AuthFlowQueryParam] === Auth.CLI">Authenticate CLI Access</div>
-          <div v-else-if="$route.query[AuthFlowQueryParam] === Auth.Frontend">
-            Authenticate UI Access
-          </div>
-          <div v-else-if="$route.query[AuthFlowQueryParam] === Auth.WorkloadProxy">
-            Authenticate Workload Proxy Access
-          </div>
+          <div v-if="authFlow === Auth.CLI">Authenticate CLI Access</div>
+          <div v-else-if="authFlow === Auth.Frontend">Authenticate UI Access</div>
+          <div v-else-if="authFlow === Auth.WorkloadProxy">Authenticate Workload Proxy Access</div>
         </div>
       </div>
 
-      <div v-if="!publicKeyId && $route.query[AuthFlowQueryParam] === Auth.CLI" class="mx-12">
+      <div v-if="!publicKeyId && authFlow === Auth.CLI" class="mx-12">
         Public key ID parameter is missing...
       </div>
-      <template v-else>
-        <div v-if="!authenticated">Redirecting to the authentication provider...</div>
-        <div v-else-if="!identity">
-          Could not get user's email address from the authentication provider...
+      <div v-else-if="!identity">Redirecting to the authentication provider...</div>
+      <div v-else-if="confirmed" id="confirmed">
+        Successfully logged in as {{ identity }}, you can return to the application...
+      </div>
+      <div v-else class="flex w-full flex-col gap-4">
+        <div>The keys are going to be issued for the user:</div>
+        <UserInfo
+          user="user"
+          class="rounded-md bg-naturals-n6 px-6 py-2"
+          :email="identity"
+          :avatar="picture"
+          :fullname="name"
+        />
+        <div class="flex w-full flex-col gap-3">
+          <TButton variant="secondary" class="w-full" @click="logout">Switch User</TButton>
+          <TButton
+            v-if="authFlow === Auth.CLI"
+            id="confirm"
+            class="w-full"
+            variant="highlighted"
+            @click="confirmPublicKey(publicKeyId!)"
+          >
+            Grant Access
+          </TButton>
+          <TButton
+            v-else
+            id="login"
+            class="w-full"
+            variant="highlighted"
+            :disabled="keysGenerating"
+            @click="generatePublicKey(identity)"
+          >
+            <TSpinner v-if="keysGenerating" class="size-4" />
+            <template v-else>Log In</template>
+          </TButton>
         </div>
-        <template v-else>
-          <div v-if="confirmed" id="confirmed">
-            Successfully logged in as {{ identity }}, you can return to the application...
-          </div>
-          <div v-else class="flex w-full flex-col gap-4">
-            <div>The keys are going to be issued for the user:</div>
-            <UserInfo
-              user="user"
-              class="rounded-md bg-naturals-n6 px-6 py-2"
-              :email="identity"
-              :avatar="picture"
-              :fullname="name"
-            />
-            <div class="flex w-full flex-col gap-3">
-              <TButton variant="secondary" class="w-full" @click="logout">Switch User</TButton>
-              <TButton
-                v-if="$route.query[AuthFlowQueryParam] === Auth.CLI"
-                id="confirm"
-                class="w-full"
-                variant="highlighted"
-                @click="() => confirmPublicKey()"
-              >
-                Grant Access
-              </TButton>
-              <TButton
-                v-else
-                id="login"
-                class="w-full"
-                variant="highlighted"
-                @click="generatePublicKey"
-              >
-                Log In
-              </TButton>
-            </div>
-          </div>
-        </template>
-      </template>
+      </div>
     </div>
   </div>
 </template>
diff --git a/go.mod b/go.mod
index c908710b..5f901163 100644
--- a/go.mod
+++ b/go.mod
@@ -1,6 +1,6 @@
 module github.com/siderolabs/omni
 
-go 1.25.6
+go 1.26.0
 
 replace (
 	// adds the extraTags field to the JSONSchema, switch to upstream if/when https://github.com/omissis/go-jsonschema/pull/504 gets merged
@@ -22,7 +22,7 @@ require (
 	github.com/aws/aws-sdk-go-v2 v1.41.1
 	github.com/aws/aws-sdk-go-v2/config v1.32.7
 	github.com/aws/aws-sdk-go-v2/credentials v1.19.7
-	github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.21.1
+	github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.22.0
 	github.com/aws/aws-sdk-go-v2/service/s3 v1.96.0
 	github.com/aws/smithy-go v1.24.0
 	github.com/benbjohnson/clock v1.3.5
@@ -30,12 +30,12 @@ require (
 	github.com/cenkalti/backoff/v5 v5.0.3
 	github.com/containers/image/v5 v5.36.2 // indirect
 	github.com/coreos/go-oidc/v3 v3.17.0
-	github.com/cosi-project/runtime v1.13.1-0.20251208192740-2b3357ea6788
+	github.com/cosi-project/runtime v1.14.0
 	github.com/cosi-project/state-etcd v0.5.3
-	github.com/cosi-project/state-sqlite v0.2.0
+	github.com/cosi-project/state-sqlite v0.3.0
 	github.com/crewjam/saml v0.5.1
 	github.com/dustin/go-humanize v1.0.1
-	github.com/emicklei/dot v1.10.0
+	github.com/emicklei/dot v1.11.0
 	github.com/felixge/httpsnoop v1.0.4
 	github.com/fsnotify/fsnotify v1.9.0
 	github.com/gertd/go-pluralize v0.2.1
@@ -48,30 +48,31 @@ require (
 	github.com/google/uuid v1.6.0
 	github.com/grpc-ecosystem/go-grpc-middleware v1.4.0
 	github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0
-	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7
+	github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8
 	github.com/hashicorp/go-cleanhttp v0.5.2
 	github.com/hashicorp/go-multierror v1.1.1
 	github.com/hashicorp/golang-lru/v2 v2.0.7
 	github.com/hashicorp/vault/api v1.22.0
 	github.com/hashicorp/vault/api/auth/kubernetes v0.10.0
-	github.com/hexops/gotextdiff v1.0.3
-	github.com/johannesboyne/gofakes3 v0.0.0-20250916175020-ebf3e50324d3
+	github.com/hexops/gotextdiff v1.0.3 // indirect
+	github.com/johannesboyne/gofakes3 v0.0.0-20260208201424-4c385a1f6a73
 	github.com/jonboulle/clockwork v0.5.0
 	github.com/julienschmidt/httprouter v1.3.0
 	github.com/jxskiss/base62 v1.1.0
-	github.com/klauspost/compress v1.18.3 // indirect
+	github.com/klauspost/compress v1.18.4 // indirect
 	github.com/mattn/go-shellwords v1.0.12
+	github.com/neticdk/go-stdlib v1.0.0 // indirect
 	github.com/prometheus/client_golang v1.23.2
 	github.com/prometheus/common v0.67.5
 	github.com/santhosh-tekuri/jsonschema/v6 v6.0.2
 	github.com/siderolabs/crypto v0.6.4
-	github.com/siderolabs/discovery-api v0.1.6
-	github.com/siderolabs/discovery-client v0.1.13
+	github.com/siderolabs/discovery-api v0.1.8
+	github.com/siderolabs/discovery-client v0.1.15
 	github.com/siderolabs/discovery-service v1.0.13
 	github.com/siderolabs/gen v0.8.6
 	github.com/siderolabs/go-api-signature v0.3.12
 	github.com/siderolabs/go-circular v0.2.3
-	github.com/siderolabs/go-debug v0.6.1
+	github.com/siderolabs/go-debug v0.6.2
 	github.com/siderolabs/go-kubernetes v0.2.31
 	github.com/siderolabs/go-loadbalancer v0.5.0
 	github.com/siderolabs/go-pointer v1.0.1
@@ -79,41 +80,41 @@ require (
 	github.com/siderolabs/go-tail v0.1.1
 	github.com/siderolabs/go-talos-support v0.1.4
 	github.com/siderolabs/grpc-proxy v0.5.1
-	github.com/siderolabs/image-factory v1.0.0
-	github.com/siderolabs/kms-client v0.1.0
-	github.com/siderolabs/omni/client v1.4.7
+	github.com/siderolabs/image-factory v1.0.3
+	github.com/siderolabs/kms-client v0.2.0
+	github.com/siderolabs/omni/client v1.5.2
 	github.com/siderolabs/proto-codec v0.1.3
 	github.com/siderolabs/siderolink v0.3.15
 	github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3
-	github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3
+	github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48
 	github.com/siderolabs/tcpproxy v0.1.0 // indirect
 	github.com/sirupsen/logrus v1.9.4
 	github.com/spf13/cobra v1.10.2
 	github.com/stretchr/testify v1.11.1
 	github.com/stripe/stripe-go/v76 v76.25.0
 	github.com/zitadel/logging v0.7.0
-	github.com/zitadel/oidc/v3 v3.45.3
+	github.com/zitadel/oidc/v3 v3.45.4
 	go.etcd.io/bbolt v1.4.3
 	go.etcd.io/etcd/client/pkg/v3 v3.6.7
 	go.etcd.io/etcd/client/v3 v3.6.7
 	go.etcd.io/etcd/server/v3 v3.6.7
 	go.uber.org/goleak v1.3.0
 	go.uber.org/zap v1.27.1
-	go.yaml.in/yaml/v4 v4.0.0-rc.3
-	golang.org/x/crypto v0.47.0
-	golang.org/x/net v0.49.0
-	golang.org/x/oauth2 v0.34.0
+	go.yaml.in/yaml/v4 v4.0.0-rc.4
+	golang.org/x/crypto v0.48.0
+	golang.org/x/net v0.50.0
+	golang.org/x/oauth2 v0.35.0
 	golang.org/x/sync v0.19.0
-	golang.org/x/text v0.33.0
+	golang.org/x/text v0.34.0
 	golang.org/x/time v0.14.0
-	golang.org/x/tools v0.41.0
+	golang.org/x/tools v0.42.0
 	golang.zx2c4.com/wireguard v0.0.0-20250521234502-f333402bd9cb
 	golang.zx2c4.com/wireguard/wgctrl v0.0.0-20241231184526-a9ab2273dd10
-	google.golang.org/grpc v1.78.0
+	google.golang.org/grpc v1.79.0
 	google.golang.org/protobuf v1.36.11
-	k8s.io/api v0.35.0
-	k8s.io/apimachinery v0.35.0
-	k8s.io/client-go v0.35.0
+	k8s.io/api v0.35.1
+	k8s.io/apimachinery v0.35.1
+	k8s.io/client-go v0.35.1
 	k8s.io/klog/v2 v2.130.1
 	sigs.k8s.io/controller-runtime v0.23.1
 	zombiezen.com/go/sqlite v1.4.2
@@ -129,7 +130,7 @@ require (
 	github.com/ProtonMail/go-mime v0.0.0-20230322103455-7d82a3887f2f // indirect
 	github.com/adrg/xdg v0.5.3 // indirect
 	github.com/antlr4-go/antlr/v4 v4.13.1 // indirect
-	github.com/atombender/go-jsonschema v0.21.0 // indirect
+	github.com/atombender/go-jsonschema v0.22.0 // indirect
 	github.com/aws/aws-sdk-go-v2/aws/protocol/eventstream v1.7.4 // indirect
 	github.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.18.17 // indirect
 	github.com/aws/aws-sdk-go-v2/internal/configsources v1.4.17 // indirect
@@ -150,7 +151,6 @@ require (
 	github.com/cenkalti/backoff/v4 v4.3.0 // indirect
 	github.com/cespare/xxhash/v2 v2.3.0 // indirect
 	github.com/chai2010/gettext-go v1.0.3 // indirect
-	github.com/cilium/ebpf v0.20.0 // indirect
 	github.com/cloudflare/circl v1.6.3 // indirect
 	github.com/containerd/go-cni v1.1.13 // indirect
 	github.com/containerd/stargz-snapshotter/estargz v0.18.2 // indirect
@@ -171,10 +171,10 @@ require (
 	github.com/fatih/camelcase v1.0.0 // indirect
 	github.com/fatih/color v1.18.0 // indirect
 	github.com/fluxcd/cli-utils v0.37.1-flux.1 // indirect
-	github.com/fluxcd/pkg/ssa v0.65.0 // indirect
+	github.com/fluxcd/pkg/ssa v0.67.0 // indirect
 	github.com/fxamacker/cbor/v2 v2.9.0 // indirect
 	github.com/ghodss/yaml v1.0.0 // indirect
-	github.com/go-chi/chi/v5 v5.2.4 // indirect
+	github.com/go-chi/chi/v5 v5.2.5 // indirect
 	github.com/go-errors/errors v1.5.1 // indirect
 	github.com/go-logr/stdr v1.2.2 // indirect
 	github.com/go-openapi/jsonpointer v0.22.4 // indirect
@@ -213,8 +213,9 @@ require (
 	github.com/hashicorp/go-sockaddr v1.0.7 // indirect
 	github.com/hashicorp/hcl v1.0.1-vault-7 // indirect
 	github.com/inconshreveable/mousetrap v1.1.0 // indirect
-	github.com/jsimonetti/rtnetlink/v2 v2.1.0 // indirect
+	github.com/jsimonetti/rtnetlink/v2 v2.2.0 // indirect
 	github.com/json-iterator/go v1.1.12 // indirect
+	github.com/kylelemons/godebug v1.1.0 // indirect
 	github.com/liggitt/tabwriter v0.0.0-20181228230101-89fcab3d43de // indirect
 	github.com/mattermost/xml-roundtrip-validator v0.1.0 // indirect
 	github.com/mattn/go-colorable v0.1.14 // indirect
@@ -284,34 +285,34 @@ require (
 	go.yaml.in/yaml/v2 v2.4.3 // indirect
 	go.yaml.in/yaml/v3 v3.0.4 // indirect
 	go4.org/netipx v0.0.0-20231129151722-fdeea329fbba // indirect
-	golang.org/x/exp v0.0.0-20260112195511-716be5621a96 // indirect
-	golang.org/x/mod v0.32.0 // indirect
-	golang.org/x/sys v0.40.0 // indirect
-	golang.org/x/term v0.39.0 // indirect
+	golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a // indirect
+	golang.org/x/mod v0.33.0 // indirect
+	golang.org/x/sys v0.41.0 // indirect
+	golang.org/x/term v0.40.0 // indirect
 	golang.zx2c4.com/wintun v0.0.0-20230126152724-0fa3db229ce2 // indirect
-	google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b // indirect
-	google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b // indirect
+	google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57 // indirect
+	google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57 // indirect
 	gopkg.in/evanphx/json-patch.v4 v4.13.0 // indirect
 	gopkg.in/go-jose/go-jose.v2 v2.6.3 // indirect
 	gopkg.in/inf.v0 v0.9.1 // indirect
 	gopkg.in/natefinch/lumberjack.v2 v2.2.1 // indirect
 	gopkg.in/yaml.v2 v2.4.0 // indirect
 	gopkg.in/yaml.v3 v3.0.1 // indirect
-	k8s.io/cli-runtime v0.35.0 // indirect
-	k8s.io/component-base v0.35.0 // indirect
-	k8s.io/component-helpers v0.35.0 // indirect
+	k8s.io/cli-runtime v0.35.1 // indirect
+	k8s.io/component-base v0.35.1 // indirect
+	k8s.io/component-helpers v0.35.1 // indirect
 	k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4 // indirect
-	k8s.io/kubectl v0.35.0 // indirect
-	k8s.io/utils v0.0.0-20260108192941-914a6e750570 // indirect
+	k8s.io/kubectl v0.35.1 // indirect
+	k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2 // indirect
 	modernc.org/libc v1.67.7 // indirect
 	modernc.org/mathutil v1.7.1 // indirect
 	modernc.org/memory v1.11.0 // indirect
-	modernc.org/sqlite v1.44.3 // indirect
+	modernc.org/sqlite v1.45.0 // indirect
 	sigs.k8s.io/cli-utils v0.37.3-0.20250918194211-77c836a69463 // indirect
 	sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730 // indirect
-	sigs.k8s.io/kustomize/api v0.21.0 // indirect
-	sigs.k8s.io/kustomize/kyaml v0.21.0 // indirect
+	sigs.k8s.io/kustomize/api v0.21.1 // indirect
+	sigs.k8s.io/kustomize/kyaml v0.21.1 // indirect
 	sigs.k8s.io/randfill v1.0.0 // indirect
-	sigs.k8s.io/structured-merge-diff/v6 v6.3.2-0.20260122202528-d9cc6641c482 // indirect
+	sigs.k8s.io/structured-merge-diff/v6 v6.3.2 // indirect
 	sigs.k8s.io/yaml v1.6.0 // indirect
 )
diff --git a/go.sum b/go.sum
index ec1dc7d6..7ccef288 100644
--- a/go.sum
+++ b/go.sum
@@ -41,8 +41,8 @@ github.com/aws/aws-sdk-go-v2/credentials v1.19.7 h1:tHK47VqqtJxOymRrNtUXN5SP/zUT
 github.com/aws/aws-sdk-go-v2/credentials v1.19.7/go.mod h1:qOZk8sPDrxhf+4Wf4oT2urYJrYt3RejHSzgAquYeppw=
 github.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.18.17 h1:I0GyV8wiYrP8XpA70g1HBcQO1JlQxCMTW9npl5UbDHY=
 github.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.18.17/go.mod h1:tyw7BOl5bBe/oqvoIeECFJjMdzXoa/dfVz3QQ5lgHGA=
-github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.21.1 h1:1hWFp+52Vq8Fevy/KUhbW/1MEApMz7uitCF/PQXRJpk=
-github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.21.1/go.mod h1:sIec8j802/rCkCKgZV678HFR0s7lhQUYXT77tIvlaa4=
+github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.22.0 h1:MpkX8EjkwuvyuX9B7+Zgk5M4URb2WQ84Y6jM81n5imw=
+github.com/aws/aws-sdk-go-v2/feature/s3/manager v1.22.0/go.mod h1:4V9Pv5sFfMPWQF0Q0zYN6BlV/504dFGaTeogallRqQw=
 github.com/aws/aws-sdk-go-v2/internal/configsources v1.4.17 h1:xOLELNKGp2vsiteLsvLPwxC+mYmO6OZ8PYgiuPJzF8U=
 github.com/aws/aws-sdk-go-v2/internal/configsources v1.4.17/go.mod h1:5M5CI3D12dNOtH3/mk6minaRwI2/37ifCURZISxA/IQ=
 github.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.7.17 h1:WWLqlh79iO48yLkj1v3ISRNiv+3KdQoZ6JWyfcsyQik=
@@ -78,12 +78,14 @@ github.com/benbjohnson/clock v1.3.5 h1:VvXlSJBzZpA/zum6Sj74hxwYI2DIxRWuNIoXAzHZz
 github.com/benbjohnson/clock v1.3.5/go.mod h1:J11/hYXuz8f4ySSvYwY0FKfm+ezbsZBKZxNJlLklBHA=
 github.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=
 github.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=
+github.com/blang/semver v3.5.1+incompatible h1:cQNTCjp13qL8KC3Nbxr/y2Bqb63oX6wdnnjpJbkM4JQ=
 github.com/blang/semver/v4 v4.0.0 h1:1PFHFE6yCCTv8C1TeyNNarDzntLi7wMI5i/pzqYIsAM=
 github.com/blang/semver/v4 v4.0.0/go.mod h1:IbckMUScFkM3pff0VJDNKRiT6TG/YpiHIM2yvyW5YoQ=
 github.com/bmatcuk/doublestar/v4 v4.10.0 h1:zU9WiOla1YA122oLM6i4EXvGW62DvKZVxIe6TYWexEs=
 github.com/bmatcuk/doublestar/v4 v4.10.0/go.mod h1:xBQ8jztBU6kakFMg+8WGxn0c6z1fTSPVIjEY1Wr7jzc=
 github.com/brianvoe/gofakeit/v7 v7.7.3 h1:RWOATEGpJ5EVg2nN8nlaEyaV/aB4d6c3GqYrbqQekss=
 github.com/brianvoe/gofakeit/v7 v7.7.3/go.mod h1:QXuPeBw164PJCzCUZVmgpgHJ3Llj49jSLVkKPMtxtxA=
+github.com/cenkalti/backoff v2.2.1+incompatible h1:tNowT99t7UNflLxfYYSlKYsBpXdEet03Pg2g16Swow4=
 github.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=
 github.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=
 github.com/cenkalti/backoff/v5 v5.0.3 h1:ZN+IMa753KfX5hd8vVaMixjnqRZ3y8CuJKRKj1xcsSM=
@@ -119,12 +121,12 @@ github.com/coreos/go-semver v0.3.1 h1:yi21YpKnrx1gt5R+la8n5WgS0kCrsPp33dmEyHReZr
 github.com/coreos/go-semver v0.3.1/go.mod h1:irMmmIw/7yzSRPWryHsK7EYSg09caPQL03VsM8rvUec=
 github.com/coreos/go-systemd/v22 v22.7.0 h1:LAEzFkke61DFROc7zNLX/WA2i5J8gYqe0rSj9KI28KA=
 github.com/coreos/go-systemd/v22 v22.7.0/go.mod h1:xNUYtjHu2EDXbsxz1i41wouACIwT7Ybq9o0BQhMwD0w=
-github.com/cosi-project/runtime v1.13.1-0.20251208192740-2b3357ea6788 h1:h39IpNUp4Uek2NkoSuKWUnpbGtSIamqZzZwLZT70nSI=
-github.com/cosi-project/runtime v1.13.1-0.20251208192740-2b3357ea6788/go.mod h1:/9fspODJfZrO5dQatMRgN440K8DjWP1jFSgiLX+FmQc=
+github.com/cosi-project/runtime v1.14.0 h1:puGI7sssk1h2KScC4ETjC+M7nyN+0ur44bAuSLdY91A=
+github.com/cosi-project/runtime v1.14.0/go.mod h1:sd2+E6DjC/QjrnlEEglINDZ4FUW7cVDMB5aG98Dl3LA=
 github.com/cosi-project/state-etcd v0.5.3 h1:jkXX1zFDMH6qsRjt4Ku9EqDtluhI3ghx1GuQpIwg88Q=
 github.com/cosi-project/state-etcd v0.5.3/go.mod h1:htNLQUC/dIx0twbudZ/wIr7aKLV0El7xHoGKvnuKzfk=
-github.com/cosi-project/state-sqlite v0.2.0 h1:MTgqB/ig5NNK/4VoRyrAsJVIaQhxf1veNxhOkTehYCI=
-github.com/cosi-project/state-sqlite v0.2.0/go.mod h1:V20oy2Sfxla0zZ+SJSgjV20feg2xGARlvVPL4Z4KfRo=
+github.com/cosi-project/state-sqlite v0.3.0 h1:6Qa66WaNOgRKwL/fSyn13krMGb1rXr1MGmhkFPkibt4=
+github.com/cosi-project/state-sqlite v0.3.0/go.mod h1:V20oy2Sfxla0zZ+SJSgjV20feg2xGARlvVPL4Z4KfRo=
 github.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
 github.com/cpuguy83/go-md2man/v2 v2.0.7 h1:zbFlGlXEAKlwXpmvle3d8Oe3YnkKIK4xSRTd3sHPnBo=
 github.com/cpuguy83/go-md2man/v2 v2.0.7/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=
@@ -145,8 +147,8 @@ github.com/docker/docker-credential-helpers v0.9.5 h1:EFNN8DHvaiK8zVqFA2DT6BjXE0
 github.com/docker/docker-credential-helpers v0.9.5/go.mod h1:v1S+hepowrQXITkEfw6o4+BMbGot02wiKpzWhGUZK6c=
 github.com/dustin/go-humanize v1.0.1 h1:GzkhY7T5VNhEkwH0PVJgjz+fX1rhBrR7pRT3mDkpeCY=
 github.com/dustin/go-humanize v1.0.1/go.mod h1:Mu1zIs6XwVuF/gI1OepvI0qD18qycQx+mFykh5fBlto=
-github.com/emicklei/dot v1.10.0 h1:z17n0ce/FBMz3QbShSzVGhiW447Qhu7fljzvp3Gs6ig=
-github.com/emicklei/dot v1.10.0/go.mod h1:DeV7GvQtIw4h2u73RKBkkFdvVAz0D9fzeJrgPW6gy/s=
+github.com/emicklei/dot v1.11.0 h1:zsrhCuFHAJge/aZIC4N4LdHy5tqYu4tWEaUzIwdYj4Y=
+github.com/emicklei/dot v1.11.0/go.mod h1:DeV7GvQtIw4h2u73RKBkkFdvVAz0D9fzeJrgPW6gy/s=
 github.com/emicklei/go-restful/v3 v3.13.0 h1:C4Bl2xDndpU6nJ4bc1jXd+uTmYPVUwkD6bFY/oTyCes=
 github.com/emicklei/go-restful/v3 v3.13.0/go.mod h1:6n3XBCmQQb25CM2LCACGz8ukIrRry+4bhvbpWn3mrbc=
 github.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=
@@ -167,8 +169,8 @@ github.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2
 github.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=
 github.com/fluxcd/cli-utils v0.37.1-flux.1 h1:WnG2mHxCPZMj/soIq/S/1zvbrGCJN3GJGbNfG06X55M=
 github.com/fluxcd/cli-utils v0.37.1-flux.1/go.mod h1:aND5wX3LuTFtB7eUT7vsWr8mmxRVSPR2Wkvbn0SqPfw=
-github.com/fluxcd/pkg/ssa v0.65.0 h1:pvPYmBmfqS0sRNoi4/IUoocBbglYuD/OJLgOuxMJ9+o=
-github.com/fluxcd/pkg/ssa v0.65.0/go.mod h1:RjvVjJIoRo1ecsv91yMuiqzO6cpNag80M6MOB/vrJdc=
+github.com/fluxcd/pkg/ssa v0.67.0 h1:1u7rG1JuAzaAssV/heYJy/oyDwyipRYwNfB3nOLpoRg=
+github.com/fluxcd/pkg/ssa v0.67.0/go.mod h1:PFXVjChubQOiWDxalpwh6PzRsEswGqnKwZB4ScoxDx4=
 github.com/fsnotify/fsnotify v1.9.0 h1:2Ml+OJNzbYCTzsxtv8vKSFD9PbJjmhYF14k/jKC7S9k=
 github.com/fsnotify/fsnotify v1.9.0/go.mod h1:8jBTzvmWwFyi3Pb8djgCCO5IBqzKJ/Jwo8TRcHyHii0=
 github.com/fxamacker/cbor/v2 v2.9.0 h1:NpKPmjDBgUfBms6tr6JZkTHtfFGcMKsw3eGcmD/sapM=
@@ -177,8 +179,8 @@ github.com/gertd/go-pluralize v0.2.1 h1:M3uASbVjMnTsPb0PNqg+E/24Vwigyo/tvyMTtAlL
 github.com/gertd/go-pluralize v0.2.1/go.mod h1:rbYaKDbsXxmRfr8uygAEKhOWsjyrrqrkHVpZvoOp8zk=
 github.com/ghodss/yaml v1.0.0 h1:wQHKEahhL6wmXdzwWG11gIVCkOv05bNOh+Rxn0yngAk=
 github.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=
-github.com/go-chi/chi/v5 v5.2.4 h1:WtFKPHwlywe8Srng8j2BhOD9312j9cGUxG1SP4V2cR4=
-github.com/go-chi/chi/v5 v5.2.4/go.mod h1:X7Gx4mteadT3eDOMTsXzmI4/rwUpOwBHLpAfupzFJP0=
+github.com/go-chi/chi/v5 v5.2.5 h1:Eg4myHZBjyvJmAFjFvWgrqDTXFyOzjj7YIm3L3mu6Ug=
+github.com/go-chi/chi/v5 v5.2.5/go.mod h1:X7Gx4mteadT3eDOMTsXzmI4/rwUpOwBHLpAfupzFJP0=
 github.com/go-errors/errors v1.5.1 h1:ZwEMSLRCapFLflTpT7NKaAc7ukJ8ZPEjzlxt8rPN8bk=
 github.com/go-errors/errors v1.5.1/go.mod h1:sIVyrIiJhuEF+Pj9Ebtd6P/rEYROXFi3BopGUQ5a5Og=
 github.com/go-jose/go-jose/v4 v4.1.3 h1:CVLmWDhDVRa6Mi/IgCgaopNosCaHz7zrMeF9MlZRkrs=
@@ -285,8 +287,8 @@ github.com/grpc-ecosystem/go-grpc-middleware/v2 v2.3.3 h1:B+8ClL/kCQkRiU82d9xajR
 github.com/grpc-ecosystem/go-grpc-middleware/v2 v2.3.3/go.mod h1:NbCUVmiS4foBGBHOYlCT25+YmGpJ32dZPi75pGEUpj4=
 github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0 h1:Ovs26xHkKqVztRpIrF/92BcuyuQ/YW4NSIpoGtfXNho=
 github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0/go.mod h1:8NvIoxWQoOIhqOTXgfV/d3M/q6VIi02HzZEHgUlZvzk=
-github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7 h1:X+2YciYSxvMQK0UZ7sg45ZVabVZBeBuvMkmuI2V3Fak=
-github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.7/go.mod h1:lW34nIZuQ8UDPdkon5fmfp2l3+ZkQ2me/+oecHYLOII=
+github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8 h1:NpbJl/eVbvrGE0MJ6X16X9SAifesl6Fwxg/YmCvubRI=
+github.com/grpc-ecosystem/grpc-gateway/v2 v2.27.8/go.mod h1:mi7YA+gCzVem12exXy46ZespvGtX/lZmD/RLnQhVW7U=
 github.com/hashicorp/errwrap v1.0.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
 github.com/hashicorp/errwrap v1.1.0 h1:OxrOeh75EUXMY8TBjag2fzXGZ40LB6IKw45YeGUDY2I=
 github.com/hashicorp/errwrap v1.1.0/go.mod h1:YH+1FKiLXxHSkmPseP+kNlulaMuP3n2brvKWEqk/Jc4=
@@ -318,14 +320,14 @@ github.com/hexops/gotextdiff v1.0.3 h1:gitA9+qJrrTCsiCl7+kh75nPqQt1cx4ZkudSTLoUq
 github.com/hexops/gotextdiff v1.0.3/go.mod h1:pSWU5MAI3yDq+fZBTazCSJysOMbxWL1BSow5/V2vxeg=
 github.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=
 github.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=
-github.com/johannesboyne/gofakes3 v0.0.0-20250916175020-ebf3e50324d3 h1:2713fQZ560HxoNVgfJH41GKzjMjIG+DW4hH6nYXfXW8=
-github.com/johannesboyne/gofakes3 v0.0.0-20250916175020-ebf3e50324d3/go.mod h1:S4S9jGBVlLri0OeqrSSbCGG5vsI6he06UJyuz1WT1EE=
+github.com/johannesboyne/gofakes3 v0.0.0-20260208201424-4c385a1f6a73 h1:0xkWp+RMC2ImuKacheMHEAtrbOTMOa0kYkxyzM1Z/II=
+github.com/johannesboyne/gofakes3 v0.0.0-20260208201424-4c385a1f6a73/go.mod h1:S4S9jGBVlLri0OeqrSSbCGG5vsI6he06UJyuz1WT1EE=
 github.com/jonboulle/clockwork v0.5.0 h1:Hyh9A8u51kptdkR+cqRpT1EebBwTn1oK9YfGYbdFz6I=
 github.com/jonboulle/clockwork v0.5.0/go.mod h1:3mZlmanh0g2NDKO5TWZVJAfofYk64M7XN3SzBPjZF60=
 github.com/jpillora/backoff v1.0.0 h1:uvFg412JmmHBHw7iwprIxkPMI+sGQ4kzOWsMeHnm2EA=
 github.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=
-github.com/jsimonetti/rtnetlink/v2 v2.1.0 h1:3sSPD0k+Qvia3wbv6kZXCN0Dlz6Swv7RHjvvonuOcKE=
-github.com/jsimonetti/rtnetlink/v2 v2.1.0/go.mod h1:hPPUTE+ekH3HD+zCEGAGLxzFY9HrJCyD1aN7JJ3SHIY=
+github.com/jsimonetti/rtnetlink/v2 v2.2.0 h1:/KfZ310gOAFrXXol5VwnFEt+ucldD/0dsSRZwpHCP9w=
+github.com/jsimonetti/rtnetlink/v2 v2.2.0/go.mod h1:lbjDHxC+5RJ08lzPeA90Ls2pEoId3F08MoEMlhfHxeI=
 github.com/json-iterator/go v1.1.12 h1:PV8peI4a0ysnczrg+LtxykD8LfKY9ML6u2jnxaEnrnM=
 github.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=
 github.com/julienschmidt/httprouter v1.3.0 h1:U0609e9tgbseu3rBINet9P48AI/D3oJs4dN7jwJOQ1U=
@@ -334,8 +336,8 @@ github.com/jxskiss/base62 v1.1.0 h1:A5zbF8v8WXx2xixnAKD2w+abC+sIzYJX+nxmhA6HWFw=
 github.com/jxskiss/base62 v1.1.0/go.mod h1:HhWAlUXvxKThfOlZbcuFzsqwtF5TcqS9ru3y5GfjWAc=
 github.com/kisielk/errcheck v1.5.0/go.mod h1:pFxgyoBC7bSaBwPgfKdkLd5X25qrDl4LWUI2bnpBCr8=
 github.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=
-github.com/klauspost/compress v1.18.3 h1:9PJRvfbmTabkOX8moIpXPbMMbYN60bWImDDU7L+/6zw=
-github.com/klauspost/compress v1.18.3/go.mod h1:R0h/fSBs8DE4ENlcrlib3PsXS61voFxhIs2DeRhCvJ4=
+github.com/klauspost/compress v1.18.4 h1:RPhnKRAQ4Fh8zU2FY/6ZFDwTVTxgJ/EMydqSTzE9a2c=
+github.com/klauspost/compress v1.18.4/go.mod h1:R0h/fSBs8DE4ENlcrlib3PsXS61voFxhIs2DeRhCvJ4=
 github.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=
 github.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=
 github.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=
@@ -394,6 +396,8 @@ github.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f h1:KUppIJq7/+
 github.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=
 github.com/ncruces/go-strftime v1.0.0 h1:HMFp8mLCTPp341M/ZnA4qaf7ZlsbTc+miZjCLOFAw7w=
 github.com/ncruces/go-strftime v1.0.0/go.mod h1:Fwc5htZGVVkseilnfgOVb9mKy6w1naJmn9CehxcKcls=
+github.com/neticdk/go-stdlib v1.0.0 h1:9QCpoMpO5dBJGHJhumZrHzfJyvpVBd2Gc7ODJujfpXY=
+github.com/neticdk/go-stdlib v1.0.0/go.mod h1:rch+DEB6VtR972ZPTY6A5OyLmCrp2YlXP0WGjuDDdcw=
 github.com/onsi/ginkgo/v2 v2.27.2 h1:LzwLj0b89qtIy6SSASkzlNvX6WktqurSHwkk2ipF/Ns=
 github.com/onsi/ginkgo/v2 v2.27.2/go.mod h1:ArE1D/XhNXBXCBkKOLkbsb2c81dQHCRcF5zwn/ykDRo=
 github.com/onsi/gomega v1.39.0 h1:y2ROC3hKFmQZJNFeGAMeHZKkjBL65mIZcvrLQBF9k6Q=
@@ -438,6 +442,8 @@ github.com/rs/cors v1.11.1 h1:eU3gRzXLRK57F5rKMGMZURNdIG4EoAmX8k94r9wXWHA=
 github.com/rs/cors v1.11.1/go.mod h1:XyqrcTp5zjWr1wsJ8PIRZssZ8b/WMcMf71DJnit4EMU=
 github.com/russellhaering/goxmldsig v1.5.0 h1:AU2UkkYIUOTyZRbe08XMThaOCelArgvNfYapcmSjBNw=
 github.com/russellhaering/goxmldsig v1.5.0/go.mod h1:x98CjQNFJcWfMxeOrMnMKg70lvDP6tE0nTaeUnjXDmk=
+github.com/russross/blackfriday v1.6.0 h1:KqfZb0pUVN2lYqZUYRddxF4OR8ZMURnJIG5Y3VRLtww=
+github.com/russross/blackfriday v1.6.0/go.mod h1:ti0ldHuxg49ri4ksnFxlkCfN+hvslNlmVHqNRXXJNAY=
 github.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=
 github.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=
 github.com/ryanuber/go-glob v1.0.0 h1:iQh3xXAumdQ+4Ufa5b25cRpC5TYKlno6hsv6Cb3pkBk=
@@ -456,10 +462,10 @@ github.com/sergi/go-diff v1.4.0 h1:n/SP9D5ad1fORl+llWyN+D6qoUETXNZARKjyY2/KVCw=
 github.com/sergi/go-diff v1.4.0/go.mod h1:A0bzQcvG0E7Rwjx0REVgAGH58e96+X0MeOfepqsbeW4=
 github.com/siderolabs/crypto v0.6.4 h1:uMoe/X/mABOv6yOgvKcjmjIMdv6U8JegBXlPKtyjn3g=
 github.com/siderolabs/crypto v0.6.4/go.mod h1:39B7Mdrd8qTfEYOjsWPQOk7gLTWrEI30isAW+YYj9nk=
-github.com/siderolabs/discovery-api v0.1.6 h1:/LhsF1ytqFEfWwV0UKfUgn90k9fk5+rhYMJ9yeUB2yc=
-github.com/siderolabs/discovery-api v0.1.6/go.mod h1:s5CnTyRMGid/vJNSJs8Jw9I4tnKHu/2SGqP2ytTaePQ=
-github.com/siderolabs/discovery-client v0.1.13 h1:s0iK2ixopCFFgQ5zZmzsQ8xf8Hd+SygrUdlhE+um6iQ=
-github.com/siderolabs/discovery-client v0.1.13/go.mod h1:kojlX4Kk0o9wsbJU1XOy4BH0W6RMg2I2d8WJ4ciK3qU=
+github.com/siderolabs/discovery-api v0.1.8 h1:Hq/Si0fFQICvdT+P/I81fRf9t5I+J6vaJNBvgehv8GE=
+github.com/siderolabs/discovery-api v0.1.8/go.mod h1:JN8aBpnsArIeLNLbqt3HIYHyFR14Qfwr4etAB2ZfygA=
+github.com/siderolabs/discovery-client v0.1.15 h1:XN2nm2U/RUtevZtKZnwYAOE+Z68VpW32Me1K19zXtHU=
+github.com/siderolabs/discovery-client v0.1.15/go.mod h1:iUpFYp40CNTnqshG7d2r9zjMruLEaT0sb49rZzVSXVA=
 github.com/siderolabs/discovery-service v1.0.13 h1:vSgO2OLvDiTAvKWp9L6z3stgv9IKr5EHGDI8TKh68eQ=
 github.com/siderolabs/discovery-service v1.0.13/go.mod h1:57g7vyTRiosUBXWdDo6mmldctxABD6G86yYVLXTwZ+c=
 github.com/siderolabs/gen v0.8.6 h1:pE6shuqov3L+5rEcAUJ/kY6iJofimljQw5G95P8a5c4=
@@ -470,6 +476,8 @@ github.com/siderolabs/go-circular v0.2.3 h1:GKkA1Tw79kEFGtWdl7WTxEUTbwtklITeiRT0
 github.com/siderolabs/go-circular v0.2.3/go.mod h1:YBN/q9YpQphUYnBtBgPsngauSHj1TEZfgQZWZVjk1WE=
 github.com/siderolabs/go-debug v0.6.1 h1:LAkM2ADz+naL3PA6Mv0SzyXYx7aCxYlKdO2dSiZmhRc=
 github.com/siderolabs/go-debug v0.6.1/go.mod h1:qKGKnrkHXdgj+gPaGujFs3L/hc87FXYTp1/l6kN/1s0=
+github.com/siderolabs/go-debug v0.6.2 h1:zWWMTcrYDVyiNTotSxEVg++hj9mb2ctuTNVnOeCWtO8=
+github.com/siderolabs/go-debug v0.6.2/go.mod h1:tcHnBjzOfEC/Stfc+cpP8J9Y6y5Pp89XNBN0n3dsWD4=
 github.com/siderolabs/go-kubeconfig v0.1.1 h1:tZlgpelj/OqrcHVUwISPN0NRgObcflpH9WtE41mtQZ0=
 github.com/siderolabs/go-kubeconfig v0.1.1/go.mod h1:QaGp4i9L95oDbcU7jDn30aw4gnREkb3O5otgxw8imOk=
 github.com/siderolabs/go-kubernetes v0.2.31 h1:pAYVti2SUnUzXlGAMmZZPqhq2+V8ifg7zhFku4iqeTQ=
@@ -486,10 +494,10 @@ github.com/siderolabs/go-talos-support v0.1.4 h1:vFYI7tcuyH4PoSkSOZtFMX8OKjvrkkt
 github.com/siderolabs/go-talos-support v0.1.4/go.mod h1:1DX20fTINVjMaW2zBmmqDBmQ4Be/6a6HwyqI1DR1ijM=
 github.com/siderolabs/grpc-proxy v0.5.1 h1:WTZYLMPTZPt43BzEJ02LT9kYA9qAfquWwCezc6NPPYE=
 github.com/siderolabs/grpc-proxy v0.5.1/go.mod h1:EQwE87LiWxhiIUPBeWmpjJb9DIWxWID8R6ARtdTC+8A=
-github.com/siderolabs/image-factory v1.0.0 h1:35d9XPQrphgKcKolqaRZft7mhVx9dkpdaMPbPvsQrBE=
-github.com/siderolabs/image-factory v1.0.0/go.mod h1:rRMN+e4W4RjZRf+bRdyyscp7VLbkhyPmo9WFXLGfKEo=
-github.com/siderolabs/kms-client v0.1.0 h1:rCDWzcDDsNlp6zdyLngOuuhchVILn+vwUQy3tk6rQps=
-github.com/siderolabs/kms-client v0.1.0/go.mod h1:4UQkRhuEh3kaK7VhJxez4YyJLv6lPEff7g3Pa6Y9okg=
+github.com/siderolabs/image-factory v1.0.3 h1:qcivcfaTNSnLMKMWH82r8oEmxymz3fzqxefZbk5lKx8=
+github.com/siderolabs/image-factory v1.0.3/go.mod h1:7ydfVZ4cfMgTAdaPdeqCADKc280GRyUHSygKQAxSfgQ=
+github.com/siderolabs/kms-client v0.2.0 h1:8RniCStUI75RTZO8qkhHOSVOnEU1AvvsKqJ7FqW/8NA=
+github.com/siderolabs/kms-client v0.2.0/go.mod h1:qq6dwcLPO0gaUyfkrhWi/37g/ZyZJzOHzvHrilLz48E=
 github.com/siderolabs/net v0.4.0 h1:1bOgVay/ijPkJz4qct98nHsiB/ysLQU0KLoBC4qLm7I=
 github.com/siderolabs/net v0.4.0/go.mod h1:/ibG+Hm9HU27agp5r9Q3eZicEfjquzNzQNux5uEk0kM=
 github.com/siderolabs/proto-codec v0.1.3 h1:tRzt2Rlc84Uv+Lx6vV2VmFpgHSV1fUNq/7nTXU892dM=
@@ -500,8 +508,8 @@ github.com/siderolabs/siderolink v0.3.15 h1:WSsgKQGJY/ObIKjTcYYGEaGfRMyox+r/Ft+9
 github.com/siderolabs/siderolink v0.3.15/go.mod h1:iWdlsHji90zotgDg4+a2zJL2ZMNJckQ8/VwqR39ThBM=
 github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3 h1:SXKyyQ76pUSHDNfZkwfXFJjVEjxIgrLSHzoovZHq2lc=
 github.com/siderolabs/talos v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3/go.mod h1:qOz9COzDsTohBYUAS3GWJttiUe6qhABYvw4g7TvUxjU=
-github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3 h1:ejFpLb7XgRordk94Zn3KxC9dq1cj9oqxjceCU810xPQ=
-github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210134859-406b8c83c9b3/go.mod h1:QKitWcS6eF4RnOUK7mJZEUwUTVi34hNKw4t4BFNpCoM=
+github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48 h1:b7/G7JMBMoElNg4CZraLihAHa7WtiI1ZsUzvU446l9Y=
+github.com/siderolabs/talos/pkg/machinery v1.13.0-alpha.1.0.20260210235840-a16392559a48/go.mod h1:hUAVw/bOMv0jyyGpgxu6AcvSBUzGGylGF7baIwwR2uI=
 github.com/siderolabs/tcpproxy v0.1.0 h1:IbkS9vRhjMOscc1US3M5P1RnsGKFgB6U5IzUk+4WkKA=
 github.com/siderolabs/tcpproxy v0.1.0/go.mod h1:onn6CPPj/w1UNqQ0U97oRPF0CqbrgEApYCw4P9IiCW8=
 github.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=
@@ -556,8 +564,8 @@ github.com/yuin/goldmark v1.2.1/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9dec
 github.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=
 github.com/zitadel/logging v0.7.0 h1:eugftwMM95Wgqwftsvj81isL0JK/hoScVqp/7iA2adQ=
 github.com/zitadel/logging v0.7.0/go.mod h1:9A6h9feBF/3u0IhA4uffdzSDY7mBaf7RE78H5sFMINQ=
-github.com/zitadel/oidc/v3 v3.45.3 h1:iaicqH5M7L5a973DTaG9UVSE14Z6Nj6hN41pp7kYBIw=
-github.com/zitadel/oidc/v3 v3.45.3/go.mod h1:yerW4/1YA5rUgjSjHsJ4HRnMbaKsyeIJkzyQrwDQ4t8=
+github.com/zitadel/oidc/v3 v3.45.4 h1:GKyWaPRVQ8sCu9XgJ3NgNGtG52FzwVJpzXjIUG2+YrI=
+github.com/zitadel/oidc/v3 v3.45.4/go.mod h1:XALmFXS9/kSom9B6uWin1yJ2WTI/E4Ti5aXJdewAVEs=
 github.com/zitadel/schema v1.3.2 h1:gfJvt7dOMfTmxzhscZ9KkapKo3Nei3B6cAxjav+lyjI=
 github.com/zitadel/schema v1.3.2/go.mod h1:IZmdfF9Wu62Zu6tJJTH3UsArevs3Y4smfJIj3L8fzxw=
 go.etcd.io/bbolt v1.4.3 h1:dEadXpI6G79deX5prL3QRNP6JB8UxVkqo4UPnHaNXJo=
@@ -610,19 +618,21 @@ go.yaml.in/yaml/v2 v2.4.3 h1:6gvOSjQoTB3vt1l+CU+tSyi/HOjfOjRLJ4YwYZGwRO0=
 go.yaml.in/yaml/v2 v2.4.3/go.mod h1:zSxWcmIDjOzPXpjlTTbAsKokqkDNAVtZO0WOMiT90s8=
 go.yaml.in/yaml/v3 v3.0.4 h1:tfq32ie2Jv2UxXFdLJdh3jXuOzWiL1fo0bu/FbuKpbc=
 go.yaml.in/yaml/v3 v3.0.4/go.mod h1:DhzuOOF2ATzADvBadXxruRBLzYTpT36CKvDb3+aBEFg=
-go.yaml.in/yaml/v4 v4.0.0-rc.3 h1:3h1fjsh1CTAPjW7q/EMe+C8shx5d8ctzZTrLcs/j8Go=
-go.yaml.in/yaml/v4 v4.0.0-rc.3/go.mod h1:aZqd9kCMsGL7AuUv/m/PvWLdg5sjJsZ4oHDEnfPPfY0=
+go.yaml.in/yaml/v4 v4.0.0-rc.4 h1:UP4+v6fFrBIb1l934bDl//mmnoIZEDK0idg1+AIvX5U=
+go.yaml.in/yaml/v4 v4.0.0-rc.4/go.mod h1:aZqd9kCMsGL7AuUv/m/PvWLdg5sjJsZ4oHDEnfPPfY0=
 go4.org/netipx v0.0.0-20231129151722-fdeea329fbba h1:0b9z3AuHCjxk0x/opv64kcgZLBseWJUpBw5I82+2U4M=
 go4.org/netipx v0.0.0-20231129151722-fdeea329fbba/go.mod h1:PLyyIXexvUFg3Owu6p/WfdlivPbZJsZdgWZlrGope/Y=
 golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=
 golang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=
 golang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=
 golang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=
-golang.org/x/crypto v0.47.0 h1:V6e3FRj+n4dbpw86FJ8Fv7XVOql7TEwpHapKoMJ/GO8=
-golang.org/x/crypto v0.47.0/go.mod h1:ff3Y9VzzKbwSSEzWqJsJVBnWmRwRSHt/6Op5n9bQc4A=
+golang.org/x/crypto v0.48.0 h1:/VRzVqiRSggnhY7gNRxPauEQ5Drw9haKdM0jqfcCFts=
+golang.org/x/crypto v0.48.0/go.mod h1:r0kV5h3qnFPlQnBSrULhlsRfryS2pmewsg+XfMgkVos=
 golang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=
-golang.org/x/exp v0.0.0-20260112195511-716be5621a96 h1:Z/6YuSHTLOHfNFdb8zVZomZr7cqNgTJvA8+Qz75D8gU=
-golang.org/x/exp v0.0.0-20260112195511-716be5621a96/go.mod h1:nzimsREAkjBCIEFtHiYkrJyT+2uy9YZJB7H1k68CXZU=
+golang.org/x/exp v0.0.0-20260211191109-2735e65f0518 h1:2E1CW7v5QB+Wi3N+MXllOtVR6SFmI8iJM8EdzgxrgrU=
+golang.org/x/exp v0.0.0-20260211191109-2735e65f0518/go.mod h1:K79w1Vqn7PoiZn+TkNpx3BUWUQksGO3JcVX6qIjytmA=
+golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a h1:ovFr6Z0MNmU7nH8VaX5xqw+05ST2uO1exVfZPVqRC5o=
+golang.org/x/exp v0.0.0-20260212183809-81e46e3db34a/go.mod h1:K79w1Vqn7PoiZn+TkNpx3BUWUQksGO3JcVX6qIjytmA=
 golang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=
 golang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=
 golang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=
@@ -631,8 +641,8 @@ golang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=
 golang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=
 golang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=
 golang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=
-golang.org/x/mod v0.32.0 h1:9F4d3PHLljb6x//jOyokMv3eX+YDeepZSEo3mFJy93c=
-golang.org/x/mod v0.32.0/go.mod h1:SgipZ/3h2Ci89DlEtEXWUk/HteuRin+HHhN+WbNhguU=
+golang.org/x/mod v0.33.0 h1:tHFzIWbBifEmbwtGz65eaWyGiGZatSrT9prnU8DbVL8=
+golang.org/x/mod v0.33.0/go.mod h1:swjeQEj+6r7fODbD2cqrnje9PnziFuw4bmLbBZFrQ5w=
 golang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
 golang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=
@@ -647,11 +657,11 @@ golang.org/x/net v0.0.0-20210520170846-37e1c6afe023/go.mod h1:9nx3DQGgdP8bBQD5qx
 golang.org/x/net v0.0.0-20211123203042-d83791d6bcd9/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=
 golang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=
 golang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=
-golang.org/x/net v0.49.0 h1:eeHFmOGUTtaaPSGNmjBKpbng9MulQsJURQUAfUwY++o=
-golang.org/x/net v0.49.0/go.mod h1:/ysNB2EvaqvesRkuLAyjI1ycPZlQHM3q01F02UY/MV8=
+golang.org/x/net v0.50.0 h1:ucWh9eiCGyDR3vtzso0WMQinm2Dnt8cFMuQa9K33J60=
+golang.org/x/net v0.50.0/go.mod h1:UgoSli3F/pBgdJBHCTc+tp3gmrU4XswgGRgtnwWTfyM=
 golang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=
-golang.org/x/oauth2 v0.34.0 h1:hqK/t4AKgbqWkdkcAeI8XLmbK+4m4G5YeQRrmiotGlw=
-golang.org/x/oauth2 v0.34.0/go.mod h1:lzm5WQJQwKZ3nwavOZ3IS5Aulzxi68dUSgRHujetwEA=
+golang.org/x/oauth2 v0.35.0 h1:Mv2mzuHuZuY2+bkyWXIHMfhNdJAdwW3FuWeCPYN5GVQ=
+golang.org/x/oauth2 v0.35.0/go.mod h1:lzm5WQJQwKZ3nwavOZ3IS5Aulzxi68dUSgRHujetwEA=
 golang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
 golang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=
@@ -679,21 +689,21 @@ golang.org/x/sys v0.1.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
 golang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
 golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
 golang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
-golang.org/x/sys v0.40.0 h1:DBZZqJ2Rkml6QMQsZywtnjnnGvHza6BTfYFWY9kjEWQ=
-golang.org/x/sys v0.40.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
+golang.org/x/sys v0.41.0 h1:Ivj+2Cp/ylzLiEU89QhWblYnOE9zerudt9Ftecq2C6k=
+golang.org/x/sys v0.41.0/go.mod h1:OgkHotnGiDImocRcuBABYBEXf8A9a87e/uXjp9XT3ks=
 golang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=
 golang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=
 golang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=
-golang.org/x/term v0.39.0 h1:RclSuaJf32jOqZz74CkPA9qFuVTX7vhLlpfj/IGWlqY=
-golang.org/x/term v0.39.0/go.mod h1:yxzUCTP/U+FzoxfdKmLaA0RV1WgE0VY7hXBwKtY/4ww=
+golang.org/x/term v0.40.0 h1:36e4zGLqU4yhjlmxEaagx2KuYbJq3EwY8K943ZsHcvg=
+golang.org/x/term v0.40.0/go.mod h1:w2P8uVp06p2iyKKuvXIm7N/y0UCRt3UfJTfZ7oOpglM=
 golang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=
 golang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
 golang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=
 golang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=
 golang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=
 golang.org/x/text v0.8.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=
-golang.org/x/text v0.33.0 h1:B3njUFyqtHDUI5jMn1YIr5B0IE2U0qck04r6d4KPAxE=
-golang.org/x/text v0.33.0/go.mod h1:LuMebE6+rBincTi9+xWTY8TztLzKHc/9C1uBCG27+q8=
+golang.org/x/text v0.34.0 h1:oL/Qq0Kdaqxa1KbNeMKwQq0reLCCaFtqu2eNuSeNHbk=
+golang.org/x/text v0.34.0/go.mod h1:homfLqTYRFyVYemLBFl5GgL/DWEiH5wcsQ5gSh1yziA=
 golang.org/x/time v0.14.0 h1:MRx4UaLrDotUKUdCIqzPC48t1Y9hANFKIRpNx+Te8PI=
 golang.org/x/time v0.14.0/go.mod h1:eL/Oa2bBBK0TkX57Fyni+NgnyQQN4LitPmob2Hjnqw4=
 golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=
@@ -707,8 +717,8 @@ golang.org/x/tools v0.0.0-20200619180055-7c47624df98f/go.mod h1:EkVYQZoAsY45+roY
 golang.org/x/tools v0.0.0-20210106214847-113979e3529a/go.mod h1:emZCQorbCU4vsT4fOWvOPXz4eW1wZW4PmDk9uLelYpA=
 golang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=
 golang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=
-golang.org/x/tools v0.41.0 h1:a9b8iMweWG+S0OBnlU36rzLp20z1Rp10w+IY2czHTQc=
-golang.org/x/tools v0.41.0/go.mod h1:XSY6eDqxVNiYgezAVqqCeihT4j1U2CCsqvH3WhQpnlg=
+golang.org/x/tools v0.42.0 h1:uNgphsn75Tdz5Ji2q36v/nsFSfR/9BRFvqhGBaJGd5k=
+golang.org/x/tools v0.42.0/go.mod h1:Ma6lCIwGZvHK6XtgbswSoWroEkhugApmsXyrUmBhfr0=
 golang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
 golang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
 golang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=
@@ -726,10 +736,10 @@ google.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7
 google.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=
 google.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=
 google.golang.org/genproto v0.0.0-20200423170343-7949de9c1215/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=
-google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b h1:SGYyueaEovpqmWmtTvwtVgo638V/QFE2zlTCnRrR3jg=
-google.golang.org/genproto/googleapis/api v0.0.0-20260202165425-ce8ad4cf556b/go.mod h1:ZdbssH/1SOVnjnDlXzxDHK2MCidiqXtbYccJNzNYPEE=
-google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b h1:GZxXGdFaHX27ZSMHudWc4FokdD+xl8BC2UJm1OVIEzs=
-google.golang.org/genproto/googleapis/rpc v0.0.0-20260202165425-ce8ad4cf556b/go.mod h1:j9x/tPzZkyxcgEFkiKEEGxfvyumM01BEtsW8xzOahRQ=
+google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57 h1:JLQynH/LBHfCTSbDWl+py8C+Rg/k1OVH3xfcaiANuF0=
+google.golang.org/genproto/googleapis/api v0.0.0-20260209200024-4cfbd4190f57/go.mod h1:kSJwQxqmFXeo79zOmbrALdflXQeAYcUbgS7PbpMknCY=
+google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57 h1:mWPCjDEyshlQYzBpMNHaEof6UX1PmHcaUODUywQ0uac=
+google.golang.org/genproto/googleapis/rpc v0.0.0-20260209200024-4cfbd4190f57/go.mod h1:j9x/tPzZkyxcgEFkiKEEGxfvyumM01BEtsW8xzOahRQ=
 google.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=
 google.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=
 google.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=
@@ -737,6 +747,8 @@ google.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8
 google.golang.org/grpc v1.29.1/go.mod h1:itym6AZVZYACWQqET3MqgPpjcuV5QH3BxFS3IjizoKk=
 google.golang.org/grpc v1.78.0 h1:K1XZG/yGDJnzMdd/uZHAkVqJE+xIDOcmdSFZkBUicNc=
 google.golang.org/grpc v1.78.0/go.mod h1:I47qjTo4OKbMkjA/aOOwxDIiPSBofUtQUI5EfpWvW7U=
+google.golang.org/grpc v1.79.0 h1:6/+EFlxsMyoSbHbBoEDx94n/Ycx/bi0IhJ5Qh7b7LaA=
+google.golang.org/grpc v1.79.0/go.mod h1:KmT0Kjez+0dde/v2j9vzwoAScgEPx/Bw1CYChhHLrHQ=
 google.golang.org/protobuf v1.36.11 h1:fV6ZwhNocDyBLK0dj+fg8ektcVegBBuEolpbTQyBNVE=
 google.golang.org/protobuf v1.36.11/go.mod h1:HTf+CrKn2C3g5S8VImy6tdcUvCska2kB7j23XfzDpco=
 gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=
@@ -770,28 +782,28 @@ gvisor.dev/gvisor v0.0.0-20250503011706-39ed1f5ac29c h1:m/r7OM+Y2Ty1sgBQ7Qb27VgI
 gvisor.dev/gvisor v0.0.0-20250503011706-39ed1f5ac29c/go.mod h1:3r5CMtNQMKIvBlrmM9xWUNamjKBYPOWyXOjmg5Kts3g=
 honnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
 honnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=
-k8s.io/api v0.35.0 h1:iBAU5LTyBI9vw3L5glmat1njFK34srdLmktWwLTprlY=
-k8s.io/api v0.35.0/go.mod h1:AQ0SNTzm4ZAczM03QH42c7l3bih1TbAXYo0DkF8ktnA=
+k8s.io/api v0.35.1 h1:0PO/1FhlK/EQNVK5+txc4FuhQibV25VLSdLMmGpDE/Q=
+k8s.io/api v0.35.1/go.mod h1:28uR9xlXWml9eT0uaGo6y71xK86JBELShLy4wR1XtxM=
 k8s.io/apiextensions-apiserver v0.35.0 h1:3xHk2rTOdWXXJM+RDQZJvdx0yEOgC0FgQ1PlJatA5T4=
 k8s.io/apiextensions-apiserver v0.35.0/go.mod h1:E1Ahk9SADaLQ4qtzYFkwUqusXTcaV2uw3l14aqpL2LU=
-k8s.io/apimachinery v0.35.0 h1:Z2L3IHvPVv/MJ7xRxHEtk6GoJElaAqDCCU0S6ncYok8=
-k8s.io/apimachinery v0.35.0/go.mod h1:jQCgFZFR1F4Ik7hvr2g84RTJSZegBc8yHgFWKn//hns=
-k8s.io/cli-runtime v0.35.0 h1:PEJtYS/Zr4p20PfZSLCbY6YvaoLrfByd6THQzPworUE=
-k8s.io/cli-runtime v0.35.0/go.mod h1:VBRvHzosVAoVdP3XwUQn1Oqkvaa8facnokNkD7jOTMY=
-k8s.io/client-go v0.35.0 h1:IAW0ifFbfQQwQmga0UdoH0yvdqrbwMdq9vIFEhRpxBE=
-k8s.io/client-go v0.35.0/go.mod h1:q2E5AAyqcbeLGPdoRB+Nxe3KYTfPce1Dnu1myQdqz9o=
-k8s.io/component-base v0.35.0 h1:+yBrOhzri2S1BVqyVSvcM3PtPyx5GUxCK2tinZz1G94=
-k8s.io/component-base v0.35.0/go.mod h1:85SCX4UCa6SCFt6p3IKAPej7jSnF3L8EbfSyMZayJR0=
-k8s.io/component-helpers v0.35.0 h1:wcXv7HJRksgVjM4VlXJ1CNFBpyDHruRI99RrBtrJceA=
-k8s.io/component-helpers v0.35.0/go.mod h1:ahX0m/LTYmu7fL3W8zYiIwnQ/5gT28Ex4o2pymF63Co=
+k8s.io/apimachinery v0.35.1 h1:yxO6gV555P1YV0SANtnTjXYfiivaTPvCTKX6w6qdDsU=
+k8s.io/apimachinery v0.35.1/go.mod h1:jQCgFZFR1F4Ik7hvr2g84RTJSZegBc8yHgFWKn//hns=
+k8s.io/cli-runtime v0.35.1 h1:uKcXFe8J7AMAM4Gm2JDK4mp198dBEq2nyeYtO+JfGJE=
+k8s.io/cli-runtime v0.35.1/go.mod h1:55/hiXIq1C8qIJ3WBrWxEwDLdHQYhBNRdZOz9f7yvTw=
+k8s.io/client-go v0.35.1 h1:+eSfZHwuo/I19PaSxqumjqZ9l5XiTEKbIaJ+j1wLcLM=
+k8s.io/client-go v0.35.1/go.mod h1:1p1KxDt3a0ruRfc/pG4qT/3oHmUj1AhSHEcxNSGg+OA=
+k8s.io/component-base v0.35.1 h1:XgvpRf4srp037QWfGBLFsYMUQJkE5yMa94UsJU7pmcE=
+k8s.io/component-base v0.35.1/go.mod h1:HI/6jXlwkiOL5zL9bqA3en1Ygv60F03oEpnuU1G56Bs=
+k8s.io/component-helpers v0.35.1 h1:vwQ/cAfnVwaPeSXTu4DdK3d3n11Lugc5vMb6EV809ZY=
+k8s.io/component-helpers v0.35.1/go.mod h1:HQqMwUk68Yyxgj92dJ+J1w/qbx9M0QR0eZ680m/o+Rk=
 k8s.io/klog/v2 v2.130.1 h1:n9Xl7H1Xvksem4KFG4PYbdQCQxqc/tTUyrgXaOhHSzk=
 k8s.io/klog/v2 v2.130.1/go.mod h1:3Jpz1GvMt720eyJH1ckRHK1EDfpxISzJ7I9OYgaDtPE=
 k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4 h1:HhDfevmPS+OalTjQRKbTHppRIz01AWi8s45TMXStgYY=
 k8s.io/kube-openapi v0.0.0-20260127142750-a19766b6e2d4/go.mod h1:kdmbQkyfwUagLfXIad1y2TdrjPFWp2Q89B3qkRwf/pQ=
-k8s.io/kubectl v0.35.0 h1:cL/wJKHDe8E8+rP3G7avnymcMg6bH6JEcR5w5uo06wc=
-k8s.io/kubectl v0.35.0/go.mod h1:VR5/TSkYyxZwrRwY5I5dDq6l5KXmiCb+9w8IKplk3Qo=
-k8s.io/utils v0.0.0-20260108192941-914a6e750570 h1:JT4W8lsdrGENg9W+YwwdLJxklIuKWdRm+BC+xt33FOY=
-k8s.io/utils v0.0.0-20260108192941-914a6e750570/go.mod h1:xDxuJ0whA3d0I4mf/C4ppKHxXynQ+fxnkmQH0vTHnuk=
+k8s.io/kubectl v0.35.1 h1:zP3Er8C5i1dcAFUMh9Eva0kVvZHptXIn/+8NtRWMxwg=
+k8s.io/kubectl v0.35.1/go.mod h1:cQ2uAPs5IO/kx8R5s5J3Ihv3VCYwrx0obCXum0CvnXo=
+k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2 h1:AZYQSJemyQB5eRxqcPky+/7EdBj0xi3g0ZcxxJ7vbWU=
+k8s.io/utils v0.0.0-20260210185600-b8788abfbbc2/go.mod h1:xDxuJ0whA3d0I4mf/C4ppKHxXynQ+fxnkmQH0vTHnuk=
 modernc.org/cc/v4 v4.27.1 h1:9W30zRlYrefrDV2JE2O8VDtJ1yPGownxciz5rrbQZis=
 modernc.org/cc/v4 v4.27.1/go.mod h1:uVtb5OGqUKpoLWhqwNQo/8LwvoiEBLvZXIQ/SmO6mL0=
 modernc.org/ccgo/v4 v4.30.1 h1:4r4U1J6Fhj98NKfSjnPUN7Ze2c6MnAdL0hWw6+LrJpc=
@@ -814,8 +826,8 @@ modernc.org/opt v0.1.4 h1:2kNGMRiUjrp4LcaPuLY2PzUfqM/w9N23quVwhKt5Qm8=
 modernc.org/opt v0.1.4/go.mod h1:03fq9lsNfvkYSfxrfUhZCWPk1lm4cq4N+Bh//bEtgns=
 modernc.org/sortutil v1.2.1 h1:+xyoGf15mM3NMlPDnFqrteY07klSFxLElE2PVuWIJ7w=
 modernc.org/sortutil v1.2.1/go.mod h1:7ZI3a3REbai7gzCLcotuw9AC4VZVpYMjDzETGsSMqJE=
-modernc.org/sqlite v1.44.3 h1:+39JvV/HWMcYslAwRxHb8067w+2zowvFOUrOWIy9PjY=
-modernc.org/sqlite v1.44.3/go.mod h1:CzbrU2lSB1DKUusvwGz7rqEKIq+NUd8GWuBBZDs9/nA=
+modernc.org/sqlite v1.45.0 h1:r51cSGzKpbptxnby+EIIz5fop4VuE4qFoVEjNvWoObs=
+modernc.org/sqlite v1.45.0/go.mod h1:CzbrU2lSB1DKUusvwGz7rqEKIq+NUd8GWuBBZDs9/nA=
 modernc.org/strutil v1.2.1 h1:UneZBkQA+DX2Rp35KcM69cSsNES9ly8mQWD71HKlOA0=
 modernc.org/strutil v1.2.1/go.mod h1:EHkiggD70koQxjVdSBM3JKM7k6L0FbGE5eymy9i3B9A=
 modernc.org/token v1.1.0 h1:Xl7Ap9dKaEs5kLoOQeQmPWevfnk/DM5qcLcYlA8ys6Y=
@@ -826,14 +838,14 @@ sigs.k8s.io/controller-runtime v0.23.1 h1:TjJSM80Nf43Mg21+RCy3J70aj/W6KyvDtOlpKf
 sigs.k8s.io/controller-runtime v0.23.1/go.mod h1:B6COOxKptp+YaUT5q4l6LqUJTRpizbgf9KSRNdQGns0=
 sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730 h1:IpInykpT6ceI+QxKBbEflcR5EXP7sU1kvOlxwZh5txg=
 sigs.k8s.io/json v0.0.0-20250730193827-2d320260d730/go.mod h1:mdzfpAEoE6DHQEN0uh9ZbOCuHbLK5wOm7dK4ctXE9Tg=
-sigs.k8s.io/kustomize/api v0.21.0 h1:I7nry5p8iDJbuRdYS7ez8MUvw7XVNPcIP5GkzzuXIIQ=
-sigs.k8s.io/kustomize/api v0.21.0/go.mod h1:XGVQuR5n2pXKWbzXHweZU683pALGw/AMVO4zU4iS8SE=
-sigs.k8s.io/kustomize/kyaml v0.21.0 h1:7mQAf3dUwf0wBerWJd8rXhVcnkk5Tvn/q91cGkaP6HQ=
-sigs.k8s.io/kustomize/kyaml v0.21.0/go.mod h1:hmxADesM3yUN2vbA5z1/YTBnzLJ1dajdqpQonwBL1FQ=
+sigs.k8s.io/kustomize/api v0.21.1 h1:lzqbzvz2CSvsjIUZUBNFKtIMsEw7hVLJp0JeSIVmuJs=
+sigs.k8s.io/kustomize/api v0.21.1/go.mod h1:f3wkKByTrgpgltLgySCntrYoq5d3q7aaxveSagwTlwI=
+sigs.k8s.io/kustomize/kyaml v0.21.1 h1:IVlbmhC076nf6foyL6Taw4BkrLuEsXUXNpsE+ScX7fI=
+sigs.k8s.io/kustomize/kyaml v0.21.1/go.mod h1:hmxADesM3yUN2vbA5z1/YTBnzLJ1dajdqpQonwBL1FQ=
 sigs.k8s.io/randfill v1.0.0 h1:JfjMILfT8A6RbawdsK2JXGBR5AQVfd+9TbzrlneTyrU=
 sigs.k8s.io/randfill v1.0.0/go.mod h1:XeLlZ/jmk4i1HRopwe7/aU3H5n1zNUcX6TM94b3QxOY=
-sigs.k8s.io/structured-merge-diff/v6 v6.3.2-0.20260122202528-d9cc6641c482 h1:2WOzJpHUBVrrkDjU4KBT8n5LDcj824eX0I5UKcgeRUs=
-sigs.k8s.io/structured-merge-diff/v6 v6.3.2-0.20260122202528-d9cc6641c482/go.mod h1:M3W8sfWvn2HhQDIbGWj3S099YozAsymCo/wrT5ohRUE=
+sigs.k8s.io/structured-merge-diff/v6 v6.3.2 h1:kwVWMx5yS1CrnFWA/2QHyRVJ8jM6dBA80uLmm0wJkk8=
+sigs.k8s.io/structured-merge-diff/v6 v6.3.2/go.mod h1:M3W8sfWvn2HhQDIbGWj3S099YozAsymCo/wrT5ohRUE=
 sigs.k8s.io/yaml v1.6.0 h1:G8fkbMSAFqgEFgh4b1wmtzDnioxFCUgTZhlbj5P9QYs=
 sigs.k8s.io/yaml v1.6.0/go.mod h1:796bPqUfzR/0jLAl6XjHl3Ck7MiyVv8dbTdyT3/pMf4=
 zombiezen.com/go/sqlite v1.4.2 h1:KZXLrBuJ7tKNEm+VJcApLMeQbhmAUOKA5VWS93DfFRo=
diff --git a/go.work b/go.work
index c5b6766b..e05d4e0b 100644
--- a/go.work
+++ b/go.work
@@ -1,4 +1,4 @@
-go 1.25.6
+go 1.26.0
 
 use (
 	.
diff --git a/hack/test/common.sh b/hack/test/common.sh
index 9217ae97..762d8511 100755
--- a/hack/test/common.sh
+++ b/hack/test/common.sh
@@ -22,14 +22,14 @@ echo "127.0.0.1 omni.localhost" | tee -a /etc/hosts
 # Settings.
 LATEST_STABLE_OMNI=$(git tag -l --sort=-version:refname HEAD "v*" | grep -E '^v?[0-9]+\.[0-9]+\.[0-9]+$' | head -n 1)
 
-export TALOS_VERSION=1.12.1
-export KUBERNETES_VERSION=1.35.0
+export TALOS_VERSION=1.12.3
+export KUBERNETES_VERSION=1.35.1
 # To use in:
 # - Omni upgrade tests, to prevent Talos changes interfering with Omni changes
 # - Talos minor upgrade tests
 export STABLE_TALOS_VERSION=1.11.6
 export ANOTHER_OMNI_VERSION="${ANOTHER_OMNI_VERSION:-$LATEST_STABLE_OMNI}"
-export ANOTHER_KUBERNETES_VERSION=1.34.3
+export ANOTHER_KUBERNETES_VERSION=1.34.4
 
 export INTEGRATION_PREPARE_TEST_ARGS="${INTEGRATION_PREPARE_TEST_ARGS:-}"
 export ARTIFACTS=_out
diff --git a/hack/zstd-dict/.golangci.yml b/hack/zstd-dict/.golangci.yml
index 8f094df7..798a8403 100644
--- a/hack/zstd-dict/.golangci.yml
+++ b/hack/zstd-dict/.golangci.yml
@@ -152,8 +152,8 @@ issues:
   exclude-rules: [ ]
   exclude-use-default: false
   exclude-case-sensitive: false
-  max-issues-per-linter: 10
-  max-same-issues: 3
+  max-issues-per-linter: 100
+  max-same-issues: 100
   new: false
 
 severity:
diff --git a/hack/zstd-dict/go.mod b/hack/zstd-dict/go.mod
index 8da783d8..f6495300 100644
--- a/hack/zstd-dict/go.mod
+++ b/hack/zstd-dict/go.mod
@@ -1,6 +1,6 @@
 module github.com/siderolabs/omni-hack-zstd-dict
 
-go 1.25.6
+go 1.26.0
 
 require (
 	github.com/klauspost/compress v1.18.3
diff --git a/internal/backend/discovery/sqlitestore.go b/internal/backend/discovery/sqlitestore.go
index a51997c0..9cd58820 100644
--- a/internal/backend/discovery/sqlitestore.go
+++ b/internal/backend/discovery/sqlitestore.go
@@ -19,7 +19,8 @@ import (
 )
 
 const (
-	tableName  = "discovery_service_state"
+	// TableName is the SQLite table name used by the discovery state store.
+	TableName  = "discovery_service_state"
 	idColumn   = "id"
 	dataColumn = "data"
 
@@ -55,7 +56,7 @@ func NewSQLiteStore(ctx context.Context, db *sqlitex.Pool, timeout time.Duration
 	schema := fmt.Sprintf(`CREATE TABLE IF NOT EXISTS %s (
       %s TEXT PRIMARY KEY,
       %s BLOB
-    ) STRICT;`, tableName, idColumn, dataColumn)
+    ) STRICT;`, TableName, idColumn, dataColumn)
 
 	ctx, cancel := context.WithTimeout(ctx, timeout)
 	defer cancel()
@@ -98,7 +99,7 @@ func (w *writer) Close() error {
 		return nil
 	}
 
-	query := fmt.Sprintf("INSERT INTO %s (%s, %s) VALUES ($id, $data) ON CONFLICT(%s) DO UPDATE SET %s=excluded.%s", tableName, idColumn, dataColumn, idColumn, dataColumn, dataColumn)
+	query := fmt.Sprintf("INSERT INTO %s (%s, %s) VALUES ($id, $data) ON CONFLICT(%s) DO UPDATE SET %s=excluded.%s", TableName, idColumn, dataColumn, idColumn, dataColumn, dataColumn)
 
 	ctx, cancel := context.WithTimeout(w.ctx, w.timeout)
 	defer cancel()
@@ -144,7 +145,7 @@ func (r *reader) Read(p []byte) (n int, err error) {
 	}
 
 	if r.reader == nil {
-		query := fmt.Sprintf("SELECT %s FROM %s WHERE %s = $id", dataColumn, tableName, idColumn)
+		query := fmt.Sprintf("SELECT %s FROM %s WHERE %s = $id", dataColumn, TableName, idColumn)
 
 		ctx, cancel := context.WithTimeout(r.ctx, r.timeout)
 		defer cancel()
diff --git a/internal/backend/grpc/auth.go b/internal/backend/grpc/auth.go
index c9cf4883..21526a21 100644
--- a/internal/backend/grpc/auth.go
+++ b/internal/backend/grpc/auth.go
@@ -19,7 +19,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state"
 	gateway "github.com/grpc-ecosystem/grpc-gateway/v2/runtime"
 	authpb "github.com/siderolabs/go-api-signature/api/auth"
-	"github.com/siderolabs/go-pointer"
 	"go.uber.org/zap"
 	"google.golang.org/grpc"
 	"google.golang.org/grpc/codes"
@@ -176,7 +175,7 @@ func (s *authServer) RegisterPublicKey(ctx context.Context, request *authpb.Regi
 	if state.IsNotFoundError(err) {
 		setPubKeyAttributes(newPubKey)
 
-		err = s.state.Create(ctx, newPubKey, state.WithCreateOwner(pointer.To(omni.KeyPrunerController{}).Name()))
+		err = s.state.Create(ctx, newPubKey, state.WithCreateOwner(new(omni.KeyPrunerController{}).Name()))
 		if err != nil {
 			return nil, err
 		}
@@ -330,7 +329,7 @@ func (s *authServer) ConfirmPublicKey(ctx context.Context, request *authpb.Confi
 		pk.TypedSpec().Value.Confirmed = true
 
 		return nil
-	}, state.WithUpdateOwner(pointer.To(omni.KeyPrunerController{}).Name()))
+	}, state.WithUpdateOwner(new(omni.KeyPrunerController{}).Name()))
 	if err != nil {
 		return nil, err
 	}
diff --git a/internal/backend/grpc/auth_test.go b/internal/backend/grpc/auth_test.go
index 6e9a122c..aab4e80b 100644
--- a/internal/backend/grpc/auth_test.go
+++ b/internal/backend/grpc/auth_test.go
@@ -14,7 +14,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/inmem"
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	"github.com/siderolabs/go-api-signature/api/auth"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
 	"google.golang.org/grpc/codes"
@@ -30,7 +29,7 @@ func TestRegisterPublicKey(t *testing.T) {
 
 	authServer, err := grpc.NewAuthServer(st, config.Services{
 		Api: config.Service{
-			AdvertisedURL: pointer.To("http://localhost:8099"),
+			AdvertisedURL: new("http://localhost:8099"),
 		},
 	}, zaptest.NewLogger(t))
 
diff --git a/internal/backend/oidc/handlers.go b/internal/backend/oidc/handlers.go
index 406b8ed1..0c13184a 100644
--- a/internal/backend/oidc/handlers.go
+++ b/internal/backend/oidc/handlers.go
@@ -90,14 +90,14 @@ func newAuthState(query, token string) (authState, error) {
 }
 
 func parseAuthState(data string) (authState, error) {
-	rawJson, err := base64.RawURLEncoding.DecodeString(data)
+	rawJSON, err := base64.RawURLEncoding.DecodeString(data)
 	if err != nil {
 		return authState{}, err
 	}
 
 	var state authState
 
-	if err = json.Unmarshal(rawJson, &state); err != nil {
+	if err = json.Unmarshal(rawJSON, &state); err != nil {
 		return state, err
 	}
 
diff --git a/internal/backend/oidc/internal/client/client.go b/internal/backend/oidc/internal/client/client.go
index db3051d7..2e348277 100644
--- a/internal/backend/oidc/internal/client/client.go
+++ b/internal/backend/oidc/internal/client/client.go
@@ -87,6 +87,8 @@ func (Client) DevMode() bool {
 }
 
 // RestrictAdditionalIdTokenScopes allows specifying which custom scopes shall be asserted into the id_token.
+//
+//nolint:staticcheck // Id, not ID, because this is an implementation of an interface from a library.
 func (Client) RestrictAdditionalIdTokenScopes() func(scopes []string) []string { //nolint:revive
 	return func(scopes []string) []string {
 		return scopes
diff --git a/internal/backend/oidc/internal/models/auth_request.go b/internal/backend/oidc/internal/models/auth_request.go
index d70c8640..2fbc3281 100644
--- a/internal/backend/oidc/internal/models/auth_request.go
+++ b/internal/backend/oidc/internal/models/auth_request.go
@@ -8,7 +8,6 @@ package models
 import (
 	"time"
 
-	"github.com/siderolabs/go-pointer"
 	"github.com/zitadel/oidc/v3/pkg/oidc"
 )
 
@@ -138,7 +137,7 @@ func maxAgeToInternal(maxAge *uint) *time.Duration {
 		return nil
 	}
 
-	return pointer.To(time.Duration(*maxAge) * time.Second)
+	return new(time.Duration(*maxAge) * time.Second)
 }
 
 // AuthRequestToInternal converts an oidc.AuthRequest to an internal AuthRequest.
diff --git a/internal/backend/resourcelogger/resourcelogger.go b/internal/backend/resourcelogger/resourcelogger.go
index 1ea7dee5..a434d5a1 100644
--- a/internal/backend/resourcelogger/resourcelogger.go
+++ b/internal/backend/resourcelogger/resourcelogger.go
@@ -15,13 +15,12 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource/meta"
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/hexops/gotextdiff"
-	"github.com/hexops/gotextdiff/myers"
-	"github.com/hexops/gotextdiff/span"
 	"github.com/siderolabs/gen/maps"
 	"go.uber.org/zap"
 	"go.uber.org/zap/zapcore"
 	"go.yaml.in/yaml/v4"
+
+	"github.com/siderolabs/omni/client/pkg/diff"
 )
 
 type eventHandler func(event state.Event) error
@@ -82,11 +81,17 @@ func loggingEventHandler(logger *zap.Logger, lvl zapcore.Level, types map[resour
 				return fmt.Errorf("failed to convert new resource to YAML: %w", err)
 			}
 
-			resStr := resource.String(event.Old)
+			diffStr, err := diff.Compute([]byte(oldYAML), []byte(newYAML))
+			if err != nil {
+				return fmt.Errorf("failed to compute diff: %w", err)
+			}
+
+			if diffStr != "" {
+				resStr := resource.String(event.Old)
+				diffStr = fmt.Sprintf("--- %s\n+++ %s\n%s", resStr, resStr, diffStr)
+			}
 
-			edits := myers.ComputeEdits(span.URIFromPath(resStr), oldYAML, newYAML)
-			diff := gotextdiff.ToUnified(resStr, resStr, oldYAML, edits)
-			diffLines := strings.Split(fmt.Sprint(diff), "\n")
+			diffLines := strings.Split(diffStr, "\n")
 
 			fields = append(fields, zap.Strings("diff", diffLines))
 		}
diff --git a/internal/backend/resourcelogger/resourcelogger_test.go b/internal/backend/resourcelogger/resourcelogger_test.go
index 0fdd3323..576a0693 100644
--- a/internal/backend/resourcelogger/resourcelogger_test.go
+++ b/internal/backend/resourcelogger/resourcelogger_test.go
@@ -177,12 +177,12 @@ func TestResourceLogger(t *testing.T) {
      hardware: null
      network:
          hostname: aaa
--        domainname: bbb
 +        domainname: ccc
+-        domainname: bbb
          addresses:
              - 1.2.3.4
              - 5.6.7.8
-@@ -25,10 +17,10 @@
+@@ -25,10 +25,10 @@
                linkup: true
                description: hello
      lasterror: ""
diff --git a/internal/backend/runtime/omni/audit/audit.go b/internal/backend/runtime/omni/audit/audit.go
index 1bfc1fe8..993f95f5 100644
--- a/internal/backend/runtime/omni/audit/audit.go
+++ b/internal/backend/runtime/omni/audit/audit.go
@@ -33,9 +33,28 @@ type Logger interface {
 	Reader(ctx context.Context, start, end time.Time) (auditlog.Reader, error)
 }
 
+// LogOption configures optional Log behavior.
+type LogOption func(*logConfig)
+
+type logConfig struct {
+	onCleanup func(int)
+}
+
+// WithCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithCleanupCallback(cb func(int)) LogOption {
+	return func(c *logConfig) {
+		c.onCleanup = cb
+	}
+}
+
 // NewLog creates a new audit logger.
-func NewLog(ctx context.Context, config config.LogsAudit, db *sqlitex.Pool, logger *zap.Logger) (*Log, error) {
-	auditLogger, err := initLogger(ctx, config, db, logger)
+func NewLog(ctx context.Context, config config.LogsAudit, db *sqlitex.Pool, logger *zap.Logger, opts ...LogOption) (*Log, error) {
+	var cfg logConfig
+	for _, opt := range opts {
+		opt(&cfg)
+	}
+
+	auditLogger, err := initLogger(ctx, config, db, logger, cfg.onCleanup)
 	if err != nil {
 		return nil, err
 	}
diff --git a/internal/backend/runtime/omni/audit/audit_test.go b/internal/backend/runtime/omni/audit/audit_test.go
index 91a72dd2..b22fe1e6 100644
--- a/internal/backend/runtime/omni/audit/audit_test.go
+++ b/internal/backend/runtime/omni/audit/audit_test.go
@@ -19,7 +19,6 @@ import (
 	"github.com/google/go-cmp/cmp"
 	"github.com/google/go-cmp/cmp/cmpopts"
 	"github.com/siderolabs/gen/xtesting/must"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
 	"google.golang.org/protobuf/types/known/timestamppb"
@@ -40,7 +39,7 @@ var logData string
 
 func TestAudit(t *testing.T) {
 	config := config.LogsAudit{
-		Enabled: pointer.To(true),
+		Enabled: new(true),
 	}
 
 	db := testDB(t)
diff --git a/internal/backend/runtime/omni/audit/auditlog/auditlog.go b/internal/backend/runtime/omni/audit/auditlog/auditlog.go
index 231039f4..4543845a 100644
--- a/internal/backend/runtime/omni/audit/auditlog/auditlog.go
+++ b/internal/backend/runtime/omni/audit/auditlog/auditlog.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package auditlog provides an interface for writing audit logs and getting readers to read them.
 package auditlog
 
 import (
diff --git a/internal/backend/runtime/omni/audit/auditlog/auditlogfile/log_file.go b/internal/backend/runtime/omni/audit/auditlog/auditlogfile/log_file.go
index 85329725..4afe1a37 100644
--- a/internal/backend/runtime/omni/audit/auditlog/auditlogfile/log_file.go
+++ b/internal/backend/runtime/omni/audit/auditlog/auditlogfile/log_file.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package auditlogfile implements an audit log backend which stores logs in files.
 package auditlogfile
 
 import (
diff --git a/internal/backend/runtime/omni/audit/auditlog/auditlogsqlite/auditlogsqlite.go b/internal/backend/runtime/omni/audit/auditlog/auditlogsqlite/auditlogsqlite.go
index 1be4b479..1e11ca57 100644
--- a/internal/backend/runtime/omni/audit/auditlog/auditlogsqlite/auditlogsqlite.go
+++ b/internal/backend/runtime/omni/audit/auditlog/auditlogsqlite/auditlogsqlite.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package auditlogsqlite implements an SQLite-backed audit log store.
 package auditlogsqlite
 
 import (
@@ -19,7 +20,6 @@ import (
 
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/cosi-project/state-sqlite/pkg/sqlitexx"
-	"github.com/siderolabs/go-pointer"
 	"go.uber.org/zap"
 	zombiesqlite "zombiezen.com/go/sqlite"
 	"zombiezen.com/go/sqlite/sqlitex"
@@ -32,7 +32,8 @@ const (
 	// The probabilistic trigger ensures convergence over multiple writes.
 	removeBySizeBatchCap = 1000
 
-	tableName           = "audit_logs"
+	// TableName is the SQLite table name used by the audit log store.
+	TableName           = "audit_logs"
 	idColumn            = "id"
 	eventTypeColumn     = "event_type"
 	resourceTypeColumn  = "resource_type"
@@ -75,15 +76,28 @@ type schemaParams struct {
 	ClusterIDColumn     string
 }
 
+// Option configures optional Store behavior.
+type Option func(*Store)
+
+// WithCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithCleanupCallback(cb func(int)) Option {
+	return func(s *Store) {
+		s.onCleanup = cb
+	}
+}
+
+// Store is the SQLite-backed audit log store.
 type Store struct {
 	db                 *sqlitex.Pool
 	logger             *zap.Logger
+	onCleanup          func(int)
 	timeout            time.Duration
 	maxSize            uint64
 	cleanupProbability float64
 }
 
-func NewStore(ctx context.Context, db *sqlitex.Pool, timeout time.Duration, maxSize uint64, cleanupProbability float64, logger *zap.Logger) (*Store, error) {
+// NewStore creates a new audit log SQLite store.
+func NewStore(ctx context.Context, db *sqlitex.Pool, timeout time.Duration, maxSize uint64, cleanupProbability float64, logger *zap.Logger, opts ...Option) (*Store, error) {
 	if timeout <= 0 {
 		timeout = 30 * time.Second
 	}
@@ -93,7 +107,7 @@ func NewStore(ctx context.Context, db *sqlitex.Pool, timeout time.Duration, maxS
 	}
 
 	templateParams := schemaParams{
-		TableName:           tableName,
+		TableName:           TableName,
 		IDColumn:            idColumn,
 		EventTypeColumn:     eventTypeColumn,
 		ResourceTypeColumn:  resourceTypeColumn,
@@ -131,19 +145,25 @@ func NewStore(ctx context.Context, db *sqlitex.Pool, timeout time.Duration, maxS
 		return nil, fmt.Errorf("failed to create sqlite log table schema: %w", err)
 	}
 
-	return &Store{
+	store := &Store{
 		db:                 db,
 		logger:             logger,
 		timeout:            timeout,
 		maxSize:            maxSize,
 		cleanupProbability: cleanupProbability,
-	}, nil
+	}
+
+	for _, opt := range opts {
+		opt(store)
+	}
+
+	return store, nil
 }
 
 func (s *Store) Write(ctx context.Context, event auditlog.Event) error {
 	query := fmt.Sprintf(`INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES 
 	($event_type, $resource_type, $event_ts_ms, $event_data, $actor_email, $resource_id, $cluster_id)`,
-		tableName, eventTypeColumn, resourceTypeColumn, eventTSMillisColumn, eventDataColumn,
+		TableName, eventTypeColumn, resourceTypeColumn, eventTSMillisColumn, eventDataColumn,
 		actorEmailColumn, resourceIDColumn, clusterIDColumn)
 
 	ctx, cancel := context.WithTimeout(ctx, s.timeout)
@@ -203,7 +223,7 @@ func (s *Store) Write(ctx context.Context, event auditlog.Event) error {
 }
 
 func (s *Store) Remove(ctx context.Context, start, end time.Time) error {
-	query := fmt.Sprintf(`DELETE FROM %s WHERE %s >= $start AND %s <= $end`, tableName, eventTSMillisColumn, eventTSMillisColumn)
+	query := fmt.Sprintf(`DELETE FROM %s WHERE %s >= $start AND %s <= $end`, TableName, eventTSMillisColumn, eventTSMillisColumn)
 
 	ctx, cancel := context.WithTimeout(ctx, s.timeout)
 	defer cancel()
@@ -228,11 +248,15 @@ func (s *Store) Remove(ctx context.Context, start, end time.Time) error {
 		return fmt.Errorf("failed to remove audit log events: %w", err)
 	}
 
+	if s.onCleanup != nil {
+		s.onCleanup(conn.Changes())
+	}
+
 	return nil
 }
 
 func (s *Store) removeBySize(conn *zombiesqlite.Conn) error {
-	sizeQuery := fmt.Sprintf(`SELECT SUM(pgsize) FROM dbstat WHERE name = '%s'`, tableName)
+	sizeQuery := fmt.Sprintf(`SELECT SUM(pgsize) FROM dbstat WHERE name = '%s'`, TableName)
 
 	q, err := sqlitexx.NewQuery(conn, sizeQuery)
 	if err != nil {
@@ -255,7 +279,7 @@ func (s *Store) removeBySize(conn *zombiesqlite.Conn) error {
 
 	// Use min/max ID to estimate row count and compute the cutoff ID for deletion. This is much faster than COUNT(*) on large tables, and good enough for our probabilistic cleanup.
 	rangeQuery := fmt.Sprintf(`SELECT COALESCE(MIN(%s), 0), COALESCE(MAX(%s), 0) FROM %s`,
-		idColumn, idColumn, tableName)
+		idColumn, idColumn, TableName)
 
 	q, err = sqlitexx.NewQuery(conn, rangeQuery)
 	if err != nil {
@@ -301,7 +325,7 @@ func (s *Store) removeBySize(conn *zombiesqlite.Conn) error {
 	// below it. This lets SQLite use the primary key index directly.
 	cutoffID := minID + rowsToDelete - 1
 
-	deleteQuery := fmt.Sprintf(`DELETE FROM %s WHERE %s <= $cutoff_id`, tableName, idColumn)
+	deleteQuery := fmt.Sprintf(`DELETE FROM %s WHERE %s <= $cutoff_id`, TableName, idColumn)
 
 	q, err = sqlitexx.NewQuery(conn, deleteQuery)
 	if err != nil {
@@ -312,6 +336,10 @@ func (s *Store) removeBySize(conn *zombiesqlite.Conn) error {
 		return fmt.Errorf("failed to delete oldest audit log events by size: %w", err)
 	}
 
+	if s.onCleanup != nil {
+		s.onCleanup(conn.Changes())
+	}
+
 	return nil
 }
 
@@ -323,7 +351,7 @@ func (s *Store) Reader(ctx context.Context, start, end time.Time) (auditlog.Read
 	}
 
 	query := fmt.Sprintf(`SELECT %s, %s, %s, %s, %s FROM %s WHERE %s >= $start AND %s <= $end ORDER BY %s ASC, %s ASC`, eventTypeColumn,
-		resourceTypeColumn, resourceIDColumn, eventTSMillisColumn, eventDataColumn, tableName, eventTSMillisColumn, eventTSMillisColumn, eventTSMillisColumn, idColumn)
+		resourceTypeColumn, resourceIDColumn, eventTSMillisColumn, eventDataColumn, TableName, eventTSMillisColumn, eventTSMillisColumn, eventTSMillisColumn, idColumn)
 
 	q, err := sqlitexx.NewQuery(conn, query)
 	if err != nil {
@@ -348,7 +376,7 @@ func (s *Store) Reader(ctx context.Context, start, end time.Time) (auditlog.Read
 }
 
 func (s *Store) HasData(ctx context.Context) (bool, error) {
-	query := fmt.Sprintf("SELECT 1 FROM %s LIMIT 1", tableName)
+	query := fmt.Sprintf("SELECT 1 FROM %s LIMIT 1", TableName)
 
 	ctx, cancel := context.WithTimeout(ctx, s.timeout)
 	defer cancel()
@@ -416,15 +444,15 @@ func (l *logReader) Read() ([]byte, error) {
 	var event rawEvent
 
 	if !result.IsNull(eventTypeColumn) {
-		event.Type = pointer.To(result.GetText(eventTypeColumn))
+		event.Type = new(result.GetText(eventTypeColumn))
 	}
 
 	if !result.IsNull(resourceTypeColumn) {
-		event.ResourceType = pointer.To(result.GetText(resourceTypeColumn))
+		event.ResourceType = new(result.GetText(resourceTypeColumn))
 	}
 
 	if !result.IsNull(resourceIDColumn) {
-		event.ResourceID = pointer.To(result.GetText(resourceIDColumn))
+		event.ResourceID = new(result.GetText(resourceIDColumn))
 	}
 
 	if !result.IsNull(eventDataColumn) {
diff --git a/internal/backend/runtime/omni/audit/logger.go b/internal/backend/runtime/omni/audit/logger.go
index c2a7d603..6e0f3a44 100644
--- a/internal/backend/runtime/omni/audit/logger.go
+++ b/internal/backend/runtime/omni/audit/logger.go
@@ -23,14 +23,19 @@ import (
 	"github.com/siderolabs/omni/internal/pkg/config"
 )
 
-func initLogger(ctx context.Context, config config.LogsAudit, db *sqlitex.Pool, logger *zap.Logger) (Logger, error) {
+func initLogger(ctx context.Context, config config.LogsAudit, db *sqlitex.Pool, logger *zap.Logger, onCleanup func(int)) (Logger, error) {
 	if !config.GetEnabled() {
 		logger.Info("audit logging is disabled")
 
 		return &nopLogger{}, nil
 	}
 
-	dbAuditLogger, err := auditlogsqlite.NewStore(ctx, db, config.GetSqliteTimeout(), config.GetMaxSize(), config.GetCleanupProbability(), logger)
+	var storeOpts []auditlogsqlite.Option
+	if onCleanup != nil {
+		storeOpts = append(storeOpts, auditlogsqlite.WithCleanupCallback(onCleanup))
+	}
+
+	dbAuditLogger, err := auditlogsqlite.NewStore(ctx, db, config.GetSqliteTimeout(), config.GetMaxSize(), config.GetCleanupProbability(), logger, storeOpts...)
 	if err != nil {
 		return nil, fmt.Errorf("failed to create sqlite audit logger: %w", err)
 	}
@@ -84,7 +89,7 @@ func migrateFromFileToSQLite(ctx context.Context, fileAuditLogger Logger, dbAudi
 	var (
 		readFailed            bool
 		migrated, writeFailed int
-		lastTs                int64 // track the last valid timestamp to keep ordering for corrupt events
+		lastTS                int64 // track the last valid timestamp to keep ordering for corrupt events
 	)
 
 	for {
@@ -110,7 +115,7 @@ func migrateFromFileToSQLite(ctx context.Context, fileAuditLogger Logger, dbAudi
 				Type: "migration_parse_error",
 				// Use the last seen timestamp. This ensures the corrupt line appears
 				// immediately after the previous valid line when sorted by (time, id).
-				TimeMillis: lastTs,
+				TimeMillis: lastTS,
 				Data: &auditlog.Data{
 					MigrationError: &auditlog.MigrationError{
 						RawData: string(eventData), // save the raw bytes
@@ -119,7 +124,7 @@ func migrateFromFileToSQLite(ctx context.Context, fileAuditLogger Logger, dbAudi
 				},
 			}
 		} else {
-			lastTs = event.TimeMillis
+			lastTS = event.TimeMillis
 		}
 
 		if err = dbAuditLogger.Write(ctx, event); err != nil {
diff --git a/internal/backend/runtime/omni/audit/logger_test.go b/internal/backend/runtime/omni/audit/logger_test.go
index 74ac5c77..00e0d288 100644
--- a/internal/backend/runtime/omni/audit/logger_test.go
+++ b/internal/backend/runtime/omni/audit/logger_test.go
@@ -16,7 +16,6 @@ import (
 	"testing"
 	"time"
 
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/goleak"
@@ -76,9 +75,9 @@ func TestMigrateFromFileToSQLite(t *testing.T) {
 	// 3. Trigger Migration via NewLog
 	// We provide both Path and SQLite enabled, which triggers initLogger -> migrateFromFileToSQLite
 	logConf := config.LogsAudit{
-		Enabled:       pointer.To(true),
-		Path:          pointer.To(dir),
-		SqliteTimeout: pointer.To(5 * time.Second),
+		Enabled:       new(true),
+		Path:          new(dir),
+		SqliteTimeout: new(5 * time.Second),
 	}
 
 	auditLogger, err := audit.NewLog(ctx, logConf, db, logger)
@@ -140,9 +139,9 @@ func TestMigrateSkipIfHasData(t *testing.T) {
 
 	// 3. Trigger NewLog
 	logConf := config.LogsAudit{
-		Enabled:       pointer.To(true),
-		Path:          pointer.To(dir),
-		SqliteTimeout: pointer.To(5 * time.Second),
+		Enabled:       new(true),
+		Path:          new(dir),
+		SqliteTimeout: new(5 * time.Second),
 	}
 
 	auditLogger, err := audit.NewLog(ctx, logConf, db, logger)
@@ -200,9 +199,9 @@ THIS_IS_BROKEN_JSON
 
 	// 4. Trigger Migration
 	logConf := config.LogsAudit{
-		Enabled:       pointer.To(true),
-		Path:          pointer.To(dir),
-		SqliteTimeout: pointer.To(5 * time.Second),
+		Enabled:       new(true),
+		Path:          new(dir),
+		SqliteTimeout: new(5 * time.Second),
 	}
 
 	auditLogger, err := audit.NewLog(ctx, logConf, db, logger)
@@ -299,9 +298,9 @@ func TestMigrateLineExceedingDefaultBuffer(t *testing.T) {
 
 	// Trigger Migration
 	logConf := config.LogsAudit{
-		Enabled:       pointer.To(true),
-		Path:          pointer.To(dir),
-		SqliteTimeout: pointer.To(5 * time.Second),
+		Enabled:       new(true),
+		Path:          new(dir),
+		SqliteTimeout: new(5 * time.Second),
 	}
 
 	auditLogger, err := audit.NewLog(ctx, logConf, db, logger)
@@ -371,9 +370,9 @@ func TestMigrateLineExceedingMaxBuffer(t *testing.T) {
 
 	// Trigger Migration
 	logConf := config.LogsAudit{
-		Enabled:       pointer.To(true),
-		Path:          pointer.To(dir),
-		SqliteTimeout: pointer.To(5 * time.Second),
+		Enabled:       new(true),
+		Path:          new(dir),
+		SqliteTimeout: new(5 * time.Second),
 	}
 
 	auditLogger, err := audit.NewLog(ctx, logConf, db, logger)
diff --git a/internal/backend/runtime/omni/controllers/omni/cluster_machine_config_test.go b/internal/backend/runtime/omni/controllers/omni/cluster_machine_config_test.go
index 84a74a06..9a1956f5 100644
--- a/internal/backend/runtime/omni/controllers/omni/cluster_machine_config_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/cluster_machine_config_test.go
@@ -15,7 +15,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/go-retry/retry"
 	"github.com/siderolabs/talos/pkg/machinery/config"
 	"github.com/siderolabs/talos/pkg/machinery/config/configloader"
@@ -36,8 +35,8 @@ import (
 )
 
 var testSiderolinkCfg = conf.SiderolinkService{
-	EventSinkPort: pointer.To(8091),
-	LogServerPort: pointer.To(8092),
+	EventSinkPort: new(8091),
+	LogServerPort: new(8092),
 }
 
 var testMachineAPIURL = "http://127.0.0.1:8090"
@@ -251,7 +250,7 @@ func (suite *ClusterMachineConfigSuite) TestGenerationError() {
 		&suite.OmniSuite,
 		*omni.NewClusterMachineConfig(machines[0].Metadata().ID()).Metadata(),
 		func(cfg *omni.ClusterMachineConfig, assert *assert.Assertions) {
-			expectedError := "yaml: unmarshal errors"
+			expectedError := "yaml: construct errors"
 
 			buffer, bufferErr := cfg.TypedSpec().Value.GetUncompressedData()
 			suite.Require().NoError(bufferErr)
diff --git a/internal/backend/runtime/omni/controllers/omni/cluster_metrics_test.go b/internal/backend/runtime/omni/controllers/omni/cluster_metrics_test.go
index e9a19ed7..6b63be9c 100644
--- a/internal/backend/runtime/omni/controllers/omni/cluster_metrics_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/cluster_metrics_test.go
@@ -36,8 +36,7 @@ func getFeatures() []string {
 
 	var names []string
 
-	for i := range t.NumField() {
-		field := t.Field(i)
+	for field := range t.Fields() {
 		if field.IsExported() {
 			names = append(names, field.Name)
 		}
diff --git a/internal/backend/runtime/omni/controllers/omni/etcdbackup/store/s3store.go b/internal/backend/runtime/omni/controllers/omni/etcdbackup/store/s3store.go
index 14b723ce..56340442 100644
--- a/internal/backend/runtime/omni/controllers/omni/etcdbackup/store/s3store.go
+++ b/internal/backend/runtime/omni/controllers/omni/etcdbackup/store/s3store.go
@@ -21,7 +21,6 @@ import (
 	"github.com/aws/aws-sdk-go-v2/service/s3"
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/siderolabs/go-pointer"
 	"go.uber.org/zap"
 
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
@@ -205,7 +204,7 @@ func S3ClientFromResource(ctx context.Context, s3Conf *omni.EtcdBackupS3Conf) (*
 		o.DisableLogOutputChecksumValidationSkipped = true
 	})
 
-	_, err = client.ListObjects(ctx, &s3.ListObjectsInput{Bucket: pointer.To(bucket)})
+	_, err = client.ListObjects(ctx, &s3.ListObjectsInput{Bucket: new(bucket)})
 	if err != nil {
 		return nil, "", fmt.Errorf("failed to list objects in bucket %q: %w", bucket, err)
 	}
diff --git a/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/crypt/encrypt.go b/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/crypt/encrypt.go
index 1f22ff93..835a3a6a 100644
--- a/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/crypt/encrypt.go
+++ b/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/crypt/encrypt.go
@@ -12,7 +12,6 @@ import (
 	"io"
 
 	"github.com/siderolabs/gen/ensure"
-	"github.com/siderolabs/go-pointer"
 
 	"github.com/siderolabs/omni/client/api/omni/specs"
 	"github.com/siderolabs/omni/internal/backend/runtime/omni/controllers/omni/etcdbackup"
@@ -29,7 +28,7 @@ func Encrypt(dst io.Writer, descr etcdbackup.EncryptionData, r io.Reader) error
 	defer wrt.Close() //nolint:errcheck
 
 	for _, data := range [...][]byte{
-		ensure.Value(pointer.To(specs.EtcdBackupHeader{Version: 1}).MarshalVT()),
+		ensure.Value(new(specs.EtcdBackupHeader{Version: 1}).MarshalVT()),
 		[]byte(descr.AESCBCEncryptionSecret),
 		[]byte(descr.SecretboxEncryptionSecret),
 	} {
diff --git a/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/s3store/s3store.go b/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/s3store/s3store.go
index 5dd9b7d6..18529659 100644
--- a/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/s3store/s3store.go
+++ b/internal/backend/runtime/omni/controllers/omni/internal/etcdbackup/s3store/s3store.go
@@ -53,14 +53,16 @@ func NewStore(client *s3.Client, bucket string, upRate, downRate uint64) *Store
 }
 
 // Upload stores the data from [io.Reader] in a file. Implements [Store].
+//
+//nolint:staticcheck
 func (s *Store) Upload(ctx context.Context, descr etcdbackup.Description, r io.Reader) error {
 	uploader := manager.NewUploader(s.client, func(u *manager.Uploader) {
 		u.RequestChecksumCalculation = aws.RequestChecksumCalculationWhenRequired
 	})
 
 	_, err := uploader.Upload(ctx, &s3.PutObjectInput{
-		Bucket: pointer.To(s.bucket),
-		Key:    pointer.To(path.Join(descr.ClusterUUID, etcdbackup.CreateSnapshotName(descr.Timestamp))),
+		Bucket: new(s.bucket),
+		Key:    new(path.Join(descr.ClusterUUID, etcdbackup.CreateSnapshotName(descr.Timestamp))),
 		Body:   newReaderLimiter(io.NopCloser(r), s.uploadRate),
 	})
 	if err != nil {
@@ -73,8 +75,8 @@ func (s *Store) Upload(ctx context.Context, descr etcdbackup.Description, r io.R
 // Download downloads the backup with the specified name. Implements [Store].
 func (s *Store) Download(ctx context.Context, _ []byte, clusterUUID, snapshotName string) (etcdbackup.BackupData, io.ReadCloser, error) {
 	result, err := s.client.GetObject(ctx, &s3.GetObjectInput{
-		Bucket: pointer.To(s.bucket),
-		Key:    pointer.To(path.Join(clusterUUID, snapshotName)),
+		Bucket: new(s.bucket),
+		Key:    new(path.Join(clusterUUID, snapshotName)),
 	})
 	if err != nil {
 		return etcdbackup.BackupData{}, nil, fmt.Errorf("failed to get object: %w", err)
@@ -86,8 +88,8 @@ func (s *Store) Download(ctx context.Context, _ []byte, clusterUUID, snapshotNam
 // ListBackups returns a list of backups. Implements [EtcdBackupStore].
 func (s *Store) ListBackups(ctx context.Context, clusterUUID string) (iter.Seq2[etcdbackup.Info, error], error) {
 	result, err := s.client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{
-		Bucket: pointer.To(s.bucket),
-		Prefix: pointer.To(fmt.Sprintf("%s/", clusterUUID)),
+		Bucket: new(s.bucket),
+		Prefix: new(fmt.Sprintf("%s/", clusterUUID)),
 	})
 	if err != nil {
 		return nil, fmt.Errorf("failed to list backups: %w", err)
@@ -123,8 +125,8 @@ func (s *Store) ListBackups(ctx context.Context, clusterUUID string) (iter.Seq2[
 				Timestamp: timestamp,
 				Reader: func() (io.ReadCloser, error) {
 					result, err := s.client.GetObject(ctx, &s3.GetObjectInput{
-						Bucket: pointer.To(s.bucket),
-						Key:    pointer.To(key),
+						Bucket: new(s.bucket),
+						Key:    new(key),
 					})
 					if err != nil {
 						return nil, fmt.Errorf("failed to get object: %w", err)
diff --git a/internal/backend/runtime/omni/controllers/omni/internal/task/machine/poll.go b/internal/backend/runtime/omni/controllers/omni/internal/task/machine/poll.go
index d1ab8b62..acb6446c 100644
--- a/internal/backend/runtime/omni/controllers/omni/internal/task/machine/poll.go
+++ b/internal/backend/runtime/omni/controllers/omni/internal/task/machine/poll.go
@@ -17,7 +17,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
 	"github.com/siderolabs/gen/value"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/talos/pkg/machinery/api/storage"
 	"github.com/siderolabs/talos/pkg/machinery/client"
 	"github.com/siderolabs/talos/pkg/machinery/nethelpers"
@@ -89,16 +88,16 @@ func pollVersion(ctx context.Context, c *client.Client, info *Info) error {
 	}
 
 	for _, msg := range versionResp.GetMessages() {
-		info.TalosVersion = pointer.To(msg.GetVersion().GetTag())
-		info.Arch = pointer.To(msg.GetVersion().GetArch())
+		info.TalosVersion = new(msg.GetVersion().GetTag())
+		info.Arch = new(msg.GetVersion().GetArch())
 	}
 
 	return nil
 }
 
 func pollHostname(ctx context.Context, c *client.Client, info *Info) error {
-	info.Hostname = pointer.To("")
-	info.Domainname = pointer.To("")
+	info.Hostname = new("")
+	info.Domainname = new("")
 
 	return forEachResource(
 		ctx,
@@ -106,8 +105,8 @@ func pollHostname(ctx context.Context, c *client.Client, info *Info) error {
 		network.NamespaceName,
 		network.HostnameStatusType,
 		func(r *network.HostnameStatus) error {
-			info.Hostname = pointer.To(r.TypedSpec().Hostname)
-			info.Domainname = pointer.To(r.TypedSpec().Domainname)
+			info.Hostname = new(r.TypedSpec().Hostname)
+			info.Domainname = new(r.TypedSpec().Domainname)
 
 			return nil
 		})
diff --git a/internal/backend/runtime/omni/controllers/omni/key_pruner_test.go b/internal/backend/runtime/omni/controllers/omni/key_pruner_test.go
index c5012e77..6168c6a5 100644
--- a/internal/backend/runtime/omni/controllers/omni/key_pruner_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/key_pruner_test.go
@@ -11,7 +11,6 @@ import (
 
 	"github.com/benbjohnson/clock"
 	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/suite"
 	"google.golang.org/protobuf/types/known/timestamppb"
@@ -58,8 +57,8 @@ func (suite *KeyPrunerSuite) TestRemoveExpiredKey() {
 	publicKey2.TypedSpec().Value.Confirmed = true
 	publicKey2.TypedSpec().Value.Expiration = timestamppb.New(fakeClock.Now().Add(defaultExpirationTime))
 
-	suite.Assert().NoError(suite.state.Create(suite.ctx, publicKey, state.WithCreateOwner(pointer.To(omnictrl.KeyPrunerController{}).Name())))
-	suite.Assert().NoError(suite.state.Create(suite.ctx, publicKey2, state.WithCreateOwner(pointer.To(omnictrl.KeyPrunerController{}).Name())))
+	suite.Assert().NoError(suite.state.Create(suite.ctx, publicKey, state.WithCreateOwner(new(omnictrl.KeyPrunerController{}).Name())))
+	suite.Assert().NoError(suite.state.Create(suite.ctx, publicKey2, state.WithCreateOwner(new(omnictrl.KeyPrunerController{}).Name())))
 
 	assertResource(&suite.OmniSuite, publicKey.Metadata(), func(*authres.PublicKey, *assert.Assertions) {})
 
diff --git a/internal/backend/runtime/omni/controllers/omni/machine_set_etcd_audit_test.go b/internal/backend/runtime/omni/controllers/omni/machine_set_etcd_audit_test.go
index 30259c6a..ff252cd2 100644
--- a/internal/backend/runtime/omni/controllers/omni/machine_set_etcd_audit_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/machine_set_etcd_audit_test.go
@@ -457,6 +457,7 @@ func (suite *MachineSetEtcdAuditSuite) TestEtcdStatus() {
 				setServiceListResponse(etcdRunning, machines...)
 
 				services["n4"] = suite.createClusterMachineStatus("n4", clusterName, machineSet)
+
 				setConnected("n4")
 				initIdentities("n4")
 				setServiceListResponse(etcdRunning, "n4")
diff --git a/internal/backend/runtime/omni/controllers/omni/machine_set_node.go b/internal/backend/runtime/omni/controllers/omni/machine_set_node.go
index a50a6909..8e153307 100644
--- a/internal/backend/runtime/omni/controllers/omni/machine_set_node.go
+++ b/internal/backend/runtime/omni/controllers/omni/machine_set_node.go
@@ -609,6 +609,7 @@ func (ctrl *MachineSetNodeController) deleteNodes(
 		}
 
 		machinesToDestroyCount--
+
 		if machineSetNode.Metadata().Finalizers().Empty() {
 			return r.Destroy(ctx, machineSetNode.Metadata(), controller.WithOwner(""))
 		}
diff --git a/internal/backend/runtime/omni/controllers/omni/machine_status_test.go b/internal/backend/runtime/omni/controllers/omni/machine_status_test.go
index ec77b68c..9eac9f06 100644
--- a/internal/backend/runtime/omni/controllers/omni/machine_status_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/machine_status_test.go
@@ -13,7 +13,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/cosi-project/runtime/pkg/resource/rtestutils"
 	"github.com/cosi-project/runtime/pkg/safe"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/image-factory/pkg/constants"
 	"github.com/siderolabs/image-factory/pkg/schematic"
 	machineapi "github.com/siderolabs/talos/pkg/machinery/api/machine"
@@ -339,7 +338,7 @@ func (suite *MachineStatusSuite) TestMachineSchematic() {
 		"talos.logging.kernel=tcp://[fdae:41e4:649b:9303::1]:8092",
 	}
 
-	vanillaID, err := pointer.To(schematic.Schematic{
+	vanillaID, err := new(schematic.Schematic{
 		Customization: schematic.Customization{
 			ExtraKernelArgs: kernelArgs,
 		},
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/diff.go b/internal/backend/runtime/omni/controllers/omni/machineconfig/diff.go
deleted file mode 100644
index d16bbb75..00000000
--- a/internal/backend/runtime/omni/controllers/omni/machineconfig/diff.go
+++ /dev/null
@@ -1,110 +0,0 @@
-// Copyright (c) 2026 Sidero Labs, Inc.
-//
-// Use of this software is governed by the Business Source License
-// included in the LICENSE file.
-
-package machineconfig
-
-import (
-	"bytes"
-	"fmt"
-	"strings"
-
-	"github.com/hexops/gotextdiff"
-	"github.com/hexops/gotextdiff/myers"
-)
-
-func ComputeDiff(previousData, newData []byte) (string, error) {
-	if bytes.Equal(previousData, newData) {
-		return "", nil
-	}
-
-	oldConfigString := string(previousData)
-	newConfigString := string(newData)
-
-	edits := myers.ComputeEdits("", oldConfigString, newConfigString)
-	diff := gotextdiff.ToUnified("", "", oldConfigString, edits)
-
-	return formatDiff(diff)
-}
-
-//nolint:gocognit
-func formatDiff(u gotextdiff.Unified) (string, error) {
-	if len(u.Hunks) == 0 {
-		return "", nil
-	}
-
-	var sb strings.Builder
-
-	for _, hunk := range u.Hunks {
-		fromCount, toCount := 0, 0
-
-		for _, l := range hunk.Lines {
-			//nolint:exhaustive
-			switch l.Kind {
-			case gotextdiff.Delete:
-				fromCount++
-			case gotextdiff.Insert:
-				toCount++
-			default:
-				fromCount++
-				toCount++
-			}
-		}
-
-		_, err := sb.WriteString("@@")
-		if err != nil {
-			return "", err
-		}
-
-		if fromCount > 1 {
-			_, err = fmt.Fprintf(&sb, " -%d,%d", hunk.FromLine, fromCount)
-		} else {
-			_, err = fmt.Fprintf(&sb, " -%d", hunk.FromLine)
-		}
-
-		if err != nil {
-			return "", err
-		}
-
-		if toCount > 1 {
-			_, err = fmt.Fprintf(&sb, " +%d,%d", hunk.ToLine, toCount)
-		} else {
-			_, err = fmt.Fprintf(&sb, " +%d", hunk.ToLine)
-		}
-
-		if err != nil {
-			return "", err
-		}
-
-		_, err = sb.WriteString(" @@\n")
-		if err != nil {
-			return "", err
-		}
-
-		for _, l := range hunk.Lines {
-			//nolint:exhaustive
-			switch l.Kind {
-			case gotextdiff.Delete:
-				_, err = fmt.Fprintf(&sb, "-%s", l.Content)
-			case gotextdiff.Insert:
-				_, err = fmt.Fprintf(&sb, "+%s", l.Content)
-			default:
-				_, err = fmt.Fprintf(&sb, " %s", l.Content)
-			}
-
-			if err != nil {
-				return "", err
-			}
-
-			if !strings.HasSuffix(l.Content, "\n") {
-				_, err := sb.WriteString("\n\\ No newline at end of file\n")
-				if err != nil {
-					return "", err
-				}
-			}
-		}
-	}
-
-	return sb.String(), nil
-}
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/diff_test.go b/internal/backend/runtime/omni/controllers/omni/machineconfig/diff_test.go
deleted file mode 100644
index 87a11da1..00000000
--- a/internal/backend/runtime/omni/controllers/omni/machineconfig/diff_test.go
+++ /dev/null
@@ -1,181 +0,0 @@
-// Copyright (c) 2026 Sidero Labs, Inc.
-//
-// Use of this software is governed by the Business Source License
-// included in the LICENSE file.
-
-package machineconfig_test
-
-import (
-	_ "embed"
-	"testing"
-
-	"github.com/siderolabs/talos/pkg/machinery/config/configloader"
-	"github.com/siderolabs/talos/pkg/machinery/config/container"
-	"github.com/siderolabs/talos/pkg/machinery/config/encoder"
-	"github.com/siderolabs/talos/pkg/machinery/config/types/v1alpha1"
-	"github.com/stretchr/testify/require"
-
-	"github.com/siderolabs/omni/internal/backend/runtime/omni/controllers/omni/machineconfig"
-)
-
-// BenchmarkComputeDiff tests various state transitions of the diff logic.
-func BenchmarkComputeDiff(b *testing.B) {
-	modifiedConfigBytes := modifyConfig(b, baseConfigBytes, func(c *v1alpha1.Config) {
-		c.MachineConfig.MachineFiles = append(c.MachineConfig.MachineFiles,
-			&v1alpha1.MachineFile{
-				FileContent:     "aaa",
-				FilePermissions: 0o777,
-				FilePath:        "/var/f",
-				FileOp:          "create",
-			},
-		)
-	})
-
-	installChangeConfigBytes := modifyConfig(b, baseConfigBytes, func(c *v1alpha1.Config) {
-		c.MachineConfig.MachineInstall.InstallDisk = "/dev/sdb"
-	})
-
-	b.ResetTimer()
-
-	b.Run("EmptyToEmpty", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(nil, nil) //nolint:errcheck
-		}
-	})
-
-	b.Run("EmptyToPopulated", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(nil, baseConfigBytes) //nolint:errcheck
-		}
-	})
-
-	b.Run("PopulatedToEmpty", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(baseConfigBytes, nil) //nolint:errcheck
-		}
-	})
-
-	b.Run("Identical", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(baseConfigBytes, baseConfigBytes) //nolint:errcheck
-		}
-	})
-
-	b.Run("RealDiff", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(baseConfigBytes, modifiedConfigBytes) //nolint:errcheck
-		}
-	})
-
-	b.Run("InstallSectionIgnored", func(b *testing.B) {
-		for range b.N {
-			machineconfig.ComputeDiff(baseConfigBytes, installChangeConfigBytes) //nolint:errcheck
-		}
-	})
-}
-
-func modifyConfig(t testing.TB, data []byte, update func(*v1alpha1.Config)) []byte {
-	cfg, err := configloader.NewFromBytes(data)
-	require.NoError(t, err)
-
-	c, err := container.New(cfg.Documents()...)
-	require.NoError(t, err)
-
-	v1Cfg := c.RawV1Alpha1()
-	require.NotNil(t, v1Cfg)
-
-	update(v1Cfg)
-
-	newData, err := c.EncodeBytes(encoder.WithComments(encoder.CommentsDisabled))
-	require.NoError(t, err)
-
-	return newData
-}
-
-//go:embed testdata/base-config.yaml
-var baseConfigBytes []byte
-
-//go:embed testdata/empty-to-populated.diff
-var emptyToPopulatedDiff string
-
-//go:embed testdata/populated-to-empty.diff
-var populatedToEmptyDiff string
-
-// TestComputeDiff tests the ComputeDiff function with various state transitions.
-func TestComputeDiff(t *testing.T) {
-	modifiedConfigBytes := modifyConfig(t, baseConfigBytes, func(c *v1alpha1.Config) {
-		c.MachineConfig.MachineFiles = append(c.MachineConfig.MachineFiles,
-			&v1alpha1.MachineFile{
-				FileContent:     "aaa",
-				FilePermissions: 0o777,
-				FilePath:        "/var/f",
-				FileOp:          "create",
-			},
-		)
-	})
-
-	tests := []struct {
-		name         string
-		wantDiff     string
-		previousData []byte
-		newData      []byte
-		wantErr      bool
-	}{
-		{
-			name:         "empty to empty",
-			previousData: nil,
-			newData:      nil,
-		},
-		{
-			name:         "empty to populated",
-			previousData: nil,
-			newData:      baseConfigBytes,
-			wantDiff:     emptyToPopulatedDiff,
-		},
-		{
-			name:         "populated to empty",
-			previousData: baseConfigBytes,
-			newData:      nil,
-			wantDiff:     populatedToEmptyDiff,
-		},
-		{
-			name:         "identical",
-			previousData: baseConfigBytes,
-			newData:      baseConfigBytes,
-			wantDiff:     "",
-		},
-		{
-			name:         "real diff",
-			previousData: baseConfigBytes,
-			newData:      modifiedConfigBytes,
-			wantDiff: `@@ -15,6 +15,11 @@
-     install:
-         wipe: false
-         grubUseUKICmdline: true
-+    files:
-+        - content: aaa
-+          permissions: 0o777
-+          path: /var/f
-+          op: create
-     features:
-         diskQuotaSupport: true
-         kubePrism:
-`,
-		},
-	}
-
-	for _, tt := range tests {
-		t.Run(tt.name, func(t *testing.T) {
-			diff, err := machineconfig.ComputeDiff(tt.previousData, tt.newData)
-
-			if tt.wantErr {
-				require.Error(t, err)
-
-				return
-			}
-
-			require.NoError(t, err)
-			require.Equal(t, tt.wantDiff, diff)
-		})
-	}
-}
diff --git a/internal/backend/runtime/omni/controllers/omni/machineconfig/status.go b/internal/backend/runtime/omni/controllers/omni/machineconfig/status.go
index 925887c4..e1272065 100644
--- a/internal/backend/runtime/omni/controllers/omni/machineconfig/status.go
+++ b/internal/backend/runtime/omni/controllers/omni/machineconfig/status.go
@@ -34,6 +34,7 @@ import (
 	"google.golang.org/grpc/status"
 
 	"github.com/siderolabs/omni/client/api/omni/specs"
+	"github.com/siderolabs/omni/client/pkg/diff"
 	"github.com/siderolabs/omni/client/pkg/meta"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/infra"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
@@ -915,7 +916,7 @@ func (ctrl *ClusterMachineConfigStatusController) computePendingUpdates(ctx cont
 
 	defer currentRedactedMachineConfig.Free()
 
-	configDiff, err := ComputeDiff(currentRedactedMachineConfig.Data(), rc.redactedMachineConfig)
+	configDiff, err := diff.Compute(currentRedactedMachineConfig.Data(), rc.redactedMachineConfig)
 	if err != nil {
 		return err
 	}
diff --git a/internal/backend/runtime/omni/controllers/omni/redactedmachineconfig/redacted_cluster_machine_config.go b/internal/backend/runtime/omni/controllers/omni/redactedmachineconfig/redacted_cluster_machine_config.go
index 650b9dd3..88954f39 100644
--- a/internal/backend/runtime/omni/controllers/omni/redactedmachineconfig/redacted_cluster_machine_config.go
+++ b/internal/backend/runtime/omni/controllers/omni/redactedmachineconfig/redacted_cluster_machine_config.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package redactedmachineconfig contains Controller which manages redacted machine configurations for each cluster machine.
 package redactedmachineconfig
 
 import (
@@ -16,14 +17,13 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/hexops/gotextdiff"
-	"github.com/hexops/gotextdiff/myers"
 	"github.com/siderolabs/crypto/x509"
 	"github.com/siderolabs/gen/xslices"
 	"github.com/siderolabs/talos/pkg/machinery/config/configloader"
 	"github.com/siderolabs/talos/pkg/machinery/config/encoder"
 	"go.uber.org/zap"
 
+	"github.com/siderolabs/omni/client/pkg/diff"
 	"github.com/siderolabs/omni/client/pkg/omni/resources"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 	"github.com/siderolabs/omni/internal/backend/runtime/omni/controllers/helpers"
@@ -255,15 +255,12 @@ const modifiedAtFormat = "2006-01-02T15:04:05.000000000Z07:00"
 func (ctrl *Controller) saveDiff(ctx context.Context, r controller.ReaderWriter,
 	cmcr *omni.RedactedClusterMachineConfig, previousData, newData []byte, logger *zap.Logger,
 ) error {
-	oldConfig := string(previousData)
-	newConfig := string(newData)
-
-	edits := myers.ComputeEdits("", oldConfig, newConfig)
-	diff := gotextdiff.ToUnified("", "", oldConfig, edits)
-	diffStr := strings.TrimSpace(fmt.Sprint(diff))
-	diffStr = strings.Replace(diffStr, "--- \n+++ \n", "", 1) // trim the URIs, as they do not make sense in this context
+	diffStr, err := diff.Compute(previousData, newData)
+	if err != nil {
+		return fmt.Errorf("failed to compute diff: %w", err)
+	}
 
-	if strings.TrimSpace(diffStr) == "" {
+	if diffStr == "" {
 		return nil
 	}
 
@@ -272,7 +269,7 @@ func (ctrl *Controller) saveDiff(ctx context.Context, r controller.ReaderWriter,
 	diffID := cmcr.Metadata().ID() + "-" + modifiedAt
 	diffRes := omni.NewMachineConfigDiff(diffID)
 
-	if err := safe.WriterModify(ctx, r, diffRes, func(res *omni.MachineConfigDiff) error {
+	if err = safe.WriterModify(ctx, r, diffRes, func(res *omni.MachineConfigDiff) error {
 		res.Metadata().Annotations().Set(ctrl.modifiedAtAnnotationKey, modifiedAt)
 		res.Metadata().Labels().Set(omni.LabelMachine, cmcr.Metadata().ID())
 
diff --git a/internal/backend/runtime/omni/controllers/omni/reporting.go b/internal/backend/runtime/omni/controllers/omni/reporting.go
index d22c96eb..0d0f24eb 100644
--- a/internal/backend/runtime/omni/controllers/omni/reporting.go
+++ b/internal/backend/runtime/omni/controllers/omni/reporting.go
@@ -159,7 +159,7 @@ func updateStripeSubscriptionItemQuantity(ctx context.Context, subscriptionItemI
 		log.Info("Updating subscription item quantity", zap.String("subscription_item_id", subscriptionItemID), zap.Uint32("new_quantity", newQuantity))
 
 		updateParams := &stripe.SubscriptionItemParams{
-			Quantity: stripe.Int64(int64(newQuantity)),
+			Quantity: new(int64(newQuantity)),
 		}
 
 		_, err := subscriptionitem.Update(subscriptionItemID, updateParams)
diff --git a/internal/backend/runtime/omni/controllers/omni/secrets/secrets.go b/internal/backend/runtime/omni/controllers/omni/secrets/secrets.go
index fbe8fa82..fab939e1 100644
--- a/internal/backend/runtime/omni/controllers/omni/secrets/secrets.go
+++ b/internal/backend/runtime/omni/controllers/omni/secrets/secrets.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package secrets contains the Controller.
 package secrets
 
 import (
@@ -31,18 +32,18 @@ import (
 	"github.com/siderolabs/omni/internal/backend/runtime/omni/controllers/omni/internal/mappers"
 )
 
-// SecretsController creates omni.ClusterSecrets for each inputed omni.Cluster.
+// Controller creates omni.ClusterSecrets for each inputed omni.Cluster.
 //
-// SecretsController generates and stores initial cluster-wide secrets.
-type SecretsController struct {
+// Controller generates and stores initial cluster-wide secrets.
+type Controller struct {
 	*qtransform.QController[*omni.Cluster, *omni.ClusterSecrets]
 }
 
 // NewSecretsController instantiates the secrets' controller.
 //
 //nolint:gocognit,gocyclo,cyclop,maintidx
-func NewSecretsController(etcdBackupStoreFactory store.Factory) *SecretsController {
-	ctrl := &SecretsController{}
+func NewSecretsController(etcdBackupStoreFactory store.Factory) *Controller {
+	ctrl := &Controller{}
 
 	ctrl.QController = qtransform.NewQController(
 		qtransform.Settings[*omni.Cluster, *omni.ClusterSecrets]{
@@ -206,7 +207,7 @@ func NewSecretsController(etcdBackupStoreFactory store.Factory) *SecretsControll
 	return ctrl
 }
 
-func (s *SecretsController) getBackupDataFromBootstrapSpec(
+func (s *Controller) getBackupDataFromBootstrapSpec(
 	ctx context.Context,
 	r controller.Reader,
 	etcdBackupStoreFactory store.Factory,
@@ -246,7 +247,7 @@ func (s *SecretsController) getBackupDataFromBootstrapSpec(
 	return downloadedBackupData, nil
 }
 
-func (s *SecretsController) handleSecretRotation(
+func (s *Controller) handleSecretRotation(
 	secrets *omni.ClusterSecrets,
 	secretRotation *omni.SecretRotation,
 ) error {
diff --git a/internal/backend/runtime/omni/controllers/omni/talos_upgrade_status_test.go b/internal/backend/runtime/omni/controllers/omni/talos_upgrade_status_test.go
index 2ad3f740..348f8a9a 100644
--- a/internal/backend/runtime/omni/controllers/omni/talos_upgrade_status_test.go
+++ b/internal/backend/runtime/omni/controllers/omni/talos_upgrade_status_test.go
@@ -210,7 +210,7 @@ func TestTalosUpgradeStatus(t *testing.T) {
 				st := testContext.State
 				machineServices := testutils.NewMachineServices(t, st)
 				clusterName := "talos-upgrade-cluster"
-				talosVersion := "1.12.1"
+				talosVersion := "1.12.3"
 				anotherTalosVersion := "1.12.0"
 				stableTalosVersion := "1.11.6"
 
diff --git a/internal/backend/runtime/omni/controllers/testutils/rmock/options/mock.go b/internal/backend/runtime/omni/controllers/testutils/rmock/options/mock.go
index 24d5bb87..f996fcf9 100644
--- a/internal/backend/runtime/omni/controllers/testutils/rmock/options/mock.go
+++ b/internal/backend/runtime/omni/controllers/testutils/rmock/options/mock.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package options defines the options for the rmock.
 package options
 
 import (
diff --git a/internal/backend/runtime/omni/controllers/testutils/rmock/rmock.go b/internal/backend/runtime/omni/controllers/testutils/rmock/rmock.go
index 06f02165..7afdf444 100644
--- a/internal/backend/runtime/omni/controllers/testutils/rmock/rmock.go
+++ b/internal/backend/runtime/omni/controllers/testutils/rmock/rmock.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package rmock provides utilities for creating resources with default values in tests.
 package rmock
 
 import (
diff --git a/internal/backend/runtime/omni/controllers/testutils/testutils.go b/internal/backend/runtime/omni/controllers/testutils/testutils.go
index 7a50799f..4365e926 100644
--- a/internal/backend/runtime/omni/controllers/testutils/testutils.go
+++ b/internal/backend/runtime/omni/controllers/testutils/testutils.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package testutils contains helper functions for testing the controllers.
 package testutils
 
 import (
diff --git a/internal/backend/runtime/omni/loader.go b/internal/backend/runtime/omni/loader.go
index e95b5b85..82c58ae5 100644
--- a/internal/backend/runtime/omni/loader.go
+++ b/internal/backend/runtime/omni/loader.go
@@ -18,6 +18,7 @@ import (
 	"go.uber.org/zap"
 
 	"github.com/siderolabs/omni/internal/backend/runtime/keyprovider"
+	"github.com/siderolabs/omni/internal/pkg/config"
 )
 
 // Loader is an interface that returns a private key.
@@ -43,16 +44,16 @@ type Loader interface {
 //	 file:///path/to/file
 //
 //			path to a private key file
-func NewLoader(source string, logger *zap.Logger, vaultToken, vaultURL string) (Loader, error) {
+func NewLoader(source string, logger *zap.Logger, vaultConfig config.Vault) (Loader, error) {
 	if source == "" {
 		return nil, errors.New("private key source is not set")
 	}
 
 	switch {
 	case os.Getenv("VAULT_K8S_ROLE") != "" && (vaultMatcher.MatchString(source) || vaultTokenMatcher.MatchString(source)):
-		return makeVaultK8sLoader(source, os.Getenv("VAULT_K8S_ROLE"), logger)
+		return makeVaultK8sLoader(source, os.Getenv("VAULT_K8S_ROLE"), vaultConfig.K8SAuthMountPath, logger)
 	case vaultMatcher.MatchString(source):
-		return makeVaultHTTPLoader(source, logger, vaultToken, vaultURL)
+		return makeVaultHTTPLoader(source, logger, vaultConfig)
 	case strings.HasPrefix(source, "file://"):
 		return makeFileLoader(source, logger)
 	}
@@ -91,7 +92,7 @@ func (f *FileLoader) PrivateKey() (keyprovider.PrivateKeyData, error) {
 	return data, nil
 }
 
-func makeVaultHTTPLoader(source string, logger *zap.Logger, vaultToken, vaultURL string) (Loader, error) {
+func makeVaultHTTPLoader(source string, logger *zap.Logger, vaultConfig config.Vault) (Loader, error) {
 	matched := vaultMatcher.FindStringSubmatch(source)
 	if len(matched) != 3 {
 		return nil, errors.New("failed to parse vault-url source")
@@ -102,7 +103,7 @@ func makeVaultHTTPLoader(source string, logger *zap.Logger, vaultToken, vaultURL
 
 	token, ok := os.LookupEnv("VAULT_TOKEN")
 	if !ok {
-		token = vaultToken
+		token = vaultConfig.GetToken()
 
 		if token == "" {
 			return nil, errors.New("VAULT_TOKEN is not set")
@@ -111,7 +112,7 @@ func makeVaultHTTPLoader(source string, logger *zap.Logger, vaultToken, vaultURL
 
 	addr, ok := os.LookupEnv("VAULT_ADDR")
 	if !ok {
-		addr = vaultURL
+		addr = vaultConfig.GetUrl()
 		if addr == "" {
 			return nil, errors.New("VAULT_ADDR is not set")
 		}
@@ -158,7 +159,7 @@ func (v *VaultHTTPLoader) PrivateKey() (keyprovider.PrivateKeyData, error) {
 	return loadKeyData(client, v.Mount, v.SecretPath)
 }
 
-func makeVaultK8sLoader(source string, role string, logger *zap.Logger) (Loader, error) {
+func makeVaultK8sLoader(source string, role string, k8sAuthMountPath *string, logger *zap.Logger) (Loader, error) {
 	var (
 		tokenPath  string
 		mount      string
@@ -177,11 +178,12 @@ func makeVaultK8sLoader(source string, role string, logger *zap.Logger) (Loader,
 	}
 
 	return &VaultK8sLoader{
-		Role:       role,
-		TokenPath:  tokenPath,
-		Mount:      mount,
-		SecretPath: secretPath,
-		logger:     logger,
+		Role:             role,
+		TokenPath:        tokenPath,
+		K8sAuthMountPath: k8sAuthMountPath,
+		Mount:            mount,
+		SecretPath:       secretPath,
+		logger:           logger,
 	}, nil
 }
 
@@ -189,10 +191,11 @@ func makeVaultK8sLoader(source string, role string, logger *zap.Logger) (Loader,
 type VaultK8sLoader struct {
 	logger *zap.Logger
 
-	Role       string
-	TokenPath  string
-	Mount      string
-	SecretPath string
+	Role             string
+	TokenPath        string
+	K8sAuthMountPath *string
+	Mount            string
+	SecretPath       string
 }
 
 // PrivateKey loads a private key from a Vault instance using Kubernetes authentication.
@@ -207,6 +210,10 @@ func (v *VaultK8sLoader) PrivateKey() (keyprovider.PrivateKeyData, error) {
 		opts = append(opts, auth.WithServiceAccountTokenPath(v.TokenPath))
 	}
 
+	if v.K8sAuthMountPath != nil {
+		opts = append(opts, auth.WithMountPath(*v.K8sAuthMountPath))
+	}
+
 	k8sAuth, err := auth.NewKubernetesAuth(
 		v.Role,
 		opts...,
diff --git a/internal/backend/runtime/omni/loader_test.go b/internal/backend/runtime/omni/loader_test.go
index 1484c273..9516c5e4 100644
--- a/internal/backend/runtime/omni/loader_test.go
+++ b/internal/backend/runtime/omni/loader_test.go
@@ -16,11 +16,13 @@ import (
 	"go.uber.org/zap/zaptest"
 
 	"github.com/siderolabs/omni/internal/backend/runtime/omni"
+	"github.com/siderolabs/omni/internal/pkg/config"
 )
 
 func TestNewLoader(t *testing.T) {
 	type args struct {
-		source string
+		k8sAuthMountPath *string
+		source           string
 	}
 
 	tests := map[string]struct {
@@ -133,6 +135,21 @@ func TestNewLoader(t *testing.T) {
 				SecretPath: "omni/account/etcdEnc",
 			}),
 		},
+		"k8s vault with custom auth mount path": {
+			pre: func(t *testing.T) {
+				t.Setenv("VAULT_K8S_ROLE", "k8s-role")
+			},
+			args: args{
+				source:           "vault://secret/omni/account/etcdEnc",
+				k8sAuthMountPath: new("auth/remote-cluster"),
+			},
+			want: equalTo(&omni.VaultK8sLoader{
+				Role:             "k8s-role",
+				K8sAuthMountPath: new("auth/remote-cluster"),
+				Mount:            "secret",
+				SecretPath:       "omni/account/etcdEnc",
+			}),
+		},
 		"unknown source": {
 			args: args{
 				source: "vault-k9s://my-role:/path/to/token",
@@ -147,7 +164,7 @@ func TestNewLoader(t *testing.T) {
 				tt.pre(t)
 			}
 
-			got, err := omni.NewLoader(tt.args.source, zaptest.NewLogger(t), "", "")
+			got, err := omni.NewLoader(tt.args.source, zaptest.NewLogger(t), config.Vault{K8SAuthMountPath: tt.args.k8sAuthMountPath})
 			tt.want(t, got, err)
 		})
 	}
diff --git a/internal/backend/runtime/omni/pkg/check/etcd.go b/internal/backend/runtime/omni/pkg/check/etcd.go
index a5b6b519..7ee8cb0d 100644
--- a/internal/backend/runtime/omni/pkg/check/etcd.go
+++ b/internal/backend/runtime/omni/pkg/check/etcd.go
@@ -204,7 +204,7 @@ func checkEtcdStatus(ctx context.Context, talosClient *client.Client) error {
 	for _, message := range status.Messages {
 		memberErrors := message.GetMemberStatus().GetErrors()
 		if len(memberErrors) > 0 {
-			return fmt.Errorf("etcd member %q has errors: %s", message.GetMemberStatus().GetMemberId(), strings.Join(memberErrors, ", "))
+			return fmt.Errorf("etcd member %v has errors: %s", message.GetMemberStatus().GetMemberId(), strings.Join(memberErrors, ", "))
 		}
 	}
 
diff --git a/internal/backend/runtime/omni/sqlite/metrics.go b/internal/backend/runtime/omni/sqlite/metrics.go
new file mode 100644
index 00000000..e59a825c
--- /dev/null
+++ b/internal/backend/runtime/omni/sqlite/metrics.go
@@ -0,0 +1,319 @@
+// Copyright (c) 2026 Sidero Labs, Inc.
+//
+// Use of this software is governed by the Business Source License
+// included in the LICENSE file.
+
+package sqlite
+
+import (
+	"context"
+	"fmt"
+	"sync"
+	"time"
+
+	"github.com/cosi-project/runtime/pkg/state"
+	"github.com/cosi-project/state-sqlite/pkg/sqlitexx"
+	"github.com/prometheus/client_golang/prometheus"
+	"go.uber.org/zap"
+	zombiesqlite "zombiezen.com/go/sqlite"
+	"zombiezen.com/go/sqlite/sqlitex"
+
+	"github.com/siderolabs/omni/internal/backend/discovery"
+	"github.com/siderolabs/omni/internal/backend/runtime/omni/audit/auditlog/auditlogsqlite"
+	"github.com/siderolabs/omni/internal/pkg/siderolink/logstore/sqlitelog"
+)
+
+const (
+	defaultRefreshInterval = 60 * time.Second
+	queryTimeout           = 10 * time.Second
+)
+
+// Subsystem names used as label values.
+const (
+	SubsystemAuditLogs   = "audit_logs"
+	SubsystemMachineLogs = "machine_logs"
+	SubsystemDiscovery   = "discovery"
+	SubsystemState       = "state"
+)
+
+// subsystemTables maps each Omni subsystem to the SQLite tables it owns.
+// The state subsystem is handled separately via sqlState, which implements DBSize to satisfy sqlite.State.
+var subsystemTables = map[string][]string{
+	SubsystemAuditLogs:   {auditlogsqlite.TableName},
+	SubsystemMachineLogs: {sqlitelog.TableName},
+	SubsystemDiscovery:   {discovery.TableName},
+}
+
+type sqlState interface {
+	DBSize(ctx context.Context) (int64, error)
+}
+
+// Metrics implements prometheus.Collector to expose SQLite database metrics.
+type Metrics struct {
+	lastRefresh              time.Time
+	sqlState                 sqlState
+	subsystemRowCountDesc    *prometheus.Desc
+	dbSizeDesc               *prometheus.Desc
+	subsystemSizeDesc        *prometheus.Desc
+	cleanupRowsDeleted       *prometheus.CounterVec
+	db                       *sqlitex.Pool
+	logger                   *zap.Logger
+	cachedSubsystemSizes     map[string]float64
+	cachedSubsystemRowCounts map[string]float64
+	refreshInterval          time.Duration
+	cachedDBSize             float64
+	mu                       sync.Mutex
+}
+
+var _ prometheus.Collector = &Metrics{}
+
+// MetricsOption configures optional metrics behavior.
+type MetricsOption func(*Metrics)
+
+// WithRefreshInterval sets the cache refresh interval. Default is 60s.
+func WithRefreshInterval(d time.Duration) MetricsOption {
+	return func(m *Metrics) {
+		m.refreshInterval = d
+	}
+}
+
+// NewMetrics creates a *Metrics that exposes SQLite database metrics.
+// If cosiState implements sqlState, the state subsystem size is reported via its DBSize method.
+func NewMetrics(db *sqlitex.Pool, cosiState state.CoreState, logger *zap.Logger, opts ...MetricsOption) *Metrics {
+	dbSizer, ok := cosiState.(sqlState)
+	if !ok {
+		logger.Warn("COSI state does not implement sqlState, state subsystem size will not be reported")
+	}
+
+	m := &Metrics{
+		db:              db,
+		sqlState:        dbSizer,
+		logger:          logger,
+		refreshInterval: defaultRefreshInterval,
+
+		dbSizeDesc: prometheus.NewDesc(
+			"omni_sqlite_db_size_bytes",
+			"Total size of the SQLite database in bytes.",
+			nil, nil,
+		),
+		subsystemSizeDesc: prometheus.NewDesc(
+			"omni_sqlite_subsystem_size_bytes",
+			"Size of a subsystem's tables in the SQLite database in bytes.",
+			[]string{"subsystem"}, nil,
+		),
+		subsystemRowCountDesc: prometheus.NewDesc(
+			"omni_sqlite_subsystem_row_count",
+			"Total number of rows across a subsystem's tables.",
+			[]string{"subsystem"}, nil,
+		),
+		cleanupRowsDeleted: prometheus.NewCounterVec(prometheus.CounterOpts{
+			Name: "omni_sqlite_cleanup_rows_deleted_total",
+			Help: "Total rows deleted by cleanup.",
+		}, []string{"subsystem"}),
+	}
+
+	for _, opt := range opts {
+		opt(m)
+	}
+
+	return m
+}
+
+// CleanupCallback returns a callback that increments the cleanup rows deleted counter for the given subsystem.
+func (m *Metrics) CleanupCallback(subsystem string) func(int) {
+	return func(count int) {
+		if count > 0 {
+			m.cleanupRowsDeleted.WithLabelValues(subsystem).Add(float64(count))
+		}
+	}
+}
+
+// Describe implements prometheus.Collector using DescribeByCollect.
+func (m *Metrics) Describe(ch chan<- *prometheus.Desc) {
+	prometheus.DescribeByCollect(m, ch)
+}
+
+// Collect implements prometheus.Collector.
+func (m *Metrics) Collect(ch chan<- prometheus.Metric) {
+	m.mu.Lock()
+	defer m.mu.Unlock()
+
+	if time.Since(m.lastRefresh) > m.refreshInterval {
+		m.refresh()
+	}
+
+	ch <- prometheus.MustNewConstMetric(m.dbSizeDesc, prometheus.GaugeValue, m.cachedDBSize)
+
+	for subsystem, size := range m.cachedSubsystemSizes {
+		ch <- prometheus.MustNewConstMetric(m.subsystemSizeDesc, prometheus.GaugeValue, size, subsystem)
+	}
+
+	for subsystem, count := range m.cachedSubsystemRowCounts {
+		ch <- prometheus.MustNewConstMetric(m.subsystemRowCountDesc, prometheus.GaugeValue, count, subsystem)
+	}
+
+	m.cleanupRowsDeleted.Collect(ch)
+}
+
+// refresh queries the database and updates cached values.
+// On failure, lastRefresh is still updated to avoid retrying on every scrape.
+func (m *Metrics) refresh() {
+	// Always update lastRefresh to prevent tight retry loops when the DB is unavailable.
+	defer func() { m.lastRefresh = time.Now() }()
+
+	ctx, cancel := context.WithTimeout(context.Background(), queryTimeout)
+	defer cancel()
+
+	conn, err := m.db.Take(ctx)
+	if err != nil {
+		m.logger.Warn("failed to take connection for metrics refresh", zap.Error(err))
+
+		return
+	}
+
+	defer m.db.Put(conn)
+
+	existingTables, err := m.discoverTables(conn)
+	if err != nil {
+		m.logger.Warn("failed to discover tables for metrics", zap.Error(err))
+
+		return
+	}
+
+	dbSize, err := m.queryDBSize(conn)
+	if err != nil {
+		m.logger.Warn("failed to query db size for metrics", zap.Error(err))
+
+		return
+	}
+
+	tableSizes, err := m.queryTableSizes(conn)
+	if err != nil {
+		m.logger.Warn("failed to query table sizes for metrics", zap.Error(err))
+
+		return
+	}
+
+	subsystemSizes := make(map[string]float64, len(subsystemTables)+1)
+	subsystemRowCounts := make(map[string]float64, len(subsystemTables)+1)
+
+	for subsystem, tables := range subsystemTables {
+		var totalSize float64
+
+		for _, table := range tables {
+			totalSize += tableSizes[table] // 0 if table doesn't exist in dbstat
+		}
+
+		subsystemSizes[subsystem] = totalSize
+
+		rowCount, rowCountErr := m.querySubsystemRowCount(conn, tables, existingTables)
+		if rowCountErr != nil {
+			m.logger.Warn("failed to query row count for subsystem", zap.String("subsystem", subsystem), zap.Error(rowCountErr))
+
+			return
+		}
+
+		subsystemRowCounts[subsystem] = rowCount
+	}
+
+	// State subsystem: use the COSI sqlState for size if available.
+	// Row count is not reported for the state subsystem because it uses a separate database.
+	if m.sqlState != nil {
+		stateSize, sizeErr := m.sqlState.DBSize(ctx)
+		if sizeErr != nil {
+			m.logger.Warn("failed to query state subsystem size", zap.Error(sizeErr))
+
+			return
+		}
+
+		subsystemSizes[SubsystemState] = float64(stateSize)
+	}
+
+	m.cachedDBSize = dbSize
+	m.cachedSubsystemSizes = subsystemSizes
+	m.cachedSubsystemRowCounts = subsystemRowCounts
+}
+
+func (m *Metrics) discoverTables(conn *zombiesqlite.Conn) (map[string]struct{}, error) {
+	q, err := sqlitexx.NewQuery(conn, `SELECT name FROM sqlite_master WHERE type = 'table' AND name NOT LIKE 'sqlite_%'`)
+	if err != nil {
+		return nil, fmt.Errorf("failed to prepare table discovery query: %w", err)
+	}
+
+	tables := make(map[string]struct{})
+
+	if err = q.QueryAll(func(stmt *zombiesqlite.Stmt) error {
+		tables[stmt.ColumnText(0)] = struct{}{}
+
+		return nil
+	}); err != nil {
+		return nil, fmt.Errorf("failed to query tables: %w", err)
+	}
+
+	return tables, nil
+}
+
+func (m *Metrics) queryDBSize(conn *zombiesqlite.Conn) (float64, error) {
+	q, err := sqlitexx.NewQuery(conn, `SELECT COALESCE(SUM(pgsize), 0) FROM dbstat`)
+	if err != nil {
+		return 0, fmt.Errorf("failed to prepare db size query: %w", err)
+	}
+
+	var size float64
+
+	if err = q.QueryRow(func(stmt *zombiesqlite.Stmt) error {
+		size = stmt.ColumnFloat(0)
+
+		return nil
+	}); err != nil {
+		return 0, fmt.Errorf("failed to query db size: %w", err)
+	}
+
+	return size, nil
+}
+
+func (m *Metrics) queryTableSizes(conn *zombiesqlite.Conn) (map[string]float64, error) {
+	q, err := sqlitexx.NewQuery(conn, `SELECT name, SUM(pgsize) FROM dbstat GROUP BY name`)
+	if err != nil {
+		return nil, fmt.Errorf("failed to prepare table sizes query: %w", err)
+	}
+
+	sizes := make(map[string]float64)
+
+	if err = q.QueryAll(func(stmt *zombiesqlite.Stmt) error {
+		sizes[stmt.ColumnText(0)] = stmt.ColumnFloat(1)
+
+		return nil
+	}); err != nil {
+		return nil, fmt.Errorf("failed to query table sizes: %w", err)
+	}
+
+	return sizes, nil
+}
+
+// querySubsystemRowCount returns the total row count across all existing tables for a subsystem.
+func (m *Metrics) querySubsystemRowCount(conn *zombiesqlite.Conn, tables []string, existingTables map[string]struct{}) (float64, error) {
+	var total float64
+
+	for _, table := range tables {
+		if _, ok := existingTables[table]; !ok {
+			continue
+		}
+
+		// Table names come from package-level constants, so they are safe to interpolate.
+		q, err := sqlitexx.NewQuery(conn, fmt.Sprintf(`SELECT COUNT(*) FROM "%s"`, table))
+		if err != nil {
+			return 0, fmt.Errorf("failed to prepare row count query for %q: %w", table, err)
+		}
+
+		if err = q.QueryRow(func(stmt *zombiesqlite.Stmt) error {
+			total += stmt.ColumnFloat(0)
+
+			return nil
+		}); err != nil {
+			return 0, fmt.Errorf("failed to query row count for %q: %w", table, err)
+		}
+	}
+
+	return total, nil
+}
diff --git a/internal/backend/runtime/omni/sqlite/metrics_test.go b/internal/backend/runtime/omni/sqlite/metrics_test.go
new file mode 100644
index 00000000..db82f021
--- /dev/null
+++ b/internal/backend/runtime/omni/sqlite/metrics_test.go
@@ -0,0 +1,263 @@
+// Copyright (c) 2026 Sidero Labs, Inc.
+//
+// Use of this software is governed by the Business Source License
+// included in the LICENSE file.
+
+package sqlite_test
+
+import (
+	"context"
+	"path/filepath"
+	"strings"
+	"testing"
+
+	"github.com/cosi-project/runtime/pkg/state"
+	"github.com/cosi-project/runtime/pkg/state/impl/inmem"
+	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
+	"github.com/prometheus/client_golang/prometheus"
+	"github.com/prometheus/client_golang/prometheus/testutil"
+	"github.com/stretchr/testify/assert"
+	"github.com/stretchr/testify/require"
+	"go.uber.org/zap/zaptest"
+	"zombiezen.com/go/sqlite/sqlitex"
+
+	"github.com/siderolabs/omni/internal/backend/runtime/omni/sqlite"
+	"github.com/siderolabs/omni/internal/pkg/config"
+)
+
+func execSQL(t *testing.T, db *sqlitex.Pool, sql string) {
+	t.Helper()
+
+	conn, err := db.Take(t.Context())
+	require.NoError(t, err)
+
+	defer db.Put(conn)
+
+	require.NoError(t, sqlitex.ExecScript(conn, sql))
+}
+
+type fakeSQLState struct {
+	state.CoreState
+	size int64
+}
+
+func (f *fakeSQLState) DBSize(context.Context) (int64, error) {
+	return f.size, nil
+}
+
+func setupMetrics(t *testing.T, db *sqlitex.Pool, cosiState state.CoreState, opts ...sqlite.MetricsOption) *prometheus.Registry {
+	t.Helper()
+
+	logger := zaptest.NewLogger(t)
+	registry := prometheus.NewRegistry()
+
+	registry.MustRegister(sqlite.NewMetrics(db, cosiState, logger, opts...))
+
+	return registry
+}
+
+func TestMetricsCollect(t *testing.T) {
+	t.Parallel()
+
+	db, st := setupTestDB(t)
+
+	execSQL(t, db, `
+		CREATE TABLE machine_logs (id INTEGER PRIMARY KEY, machine_id TEXT, message TEXT);
+		INSERT INTO machine_logs (machine_id, message) VALUES ('m1', 'log1');
+		INSERT INTO machine_logs (machine_id, message) VALUES ('m1', 'log2');
+		INSERT INTO machine_logs (machine_id, message) VALUES ('m2', 'log3');
+
+		CREATE TABLE audit_logs (id INTEGER PRIMARY KEY, event TEXT);
+		INSERT INTO audit_logs (event) VALUES ('e1');
+
+		CREATE TABLE discovery_service_state (id TEXT PRIMARY KEY, data BLOB);
+		INSERT INTO discovery_service_state (id, data) VALUES ('state', x'00');
+	`)
+
+	registry := setupMetrics(t, db, &fakeSQLState{CoreState: st, size: 8192})
+
+	// Verify subsystem row counts (state has no row count since it uses sqlState).
+	expected := `
+		# HELP omni_sqlite_subsystem_row_count Total number of rows across a subsystem's tables.
+		# TYPE omni_sqlite_subsystem_row_count gauge
+		omni_sqlite_subsystem_row_count{subsystem="audit_logs"} 1
+		omni_sqlite_subsystem_row_count{subsystem="discovery"} 1
+		omni_sqlite_subsystem_row_count{subsystem="machine_logs"} 3
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_subsystem_row_count"))
+
+	// Verify subsystem sizes: 3 Omni subsystems + 1 state (from sqlState).
+	families, err := registry.Gather()
+	require.NoError(t, err)
+
+	for _, f := range families {
+		if f.GetName() == "omni_sqlite_subsystem_size_bytes" {
+			assert.Len(t, f.GetMetric(), 4)
+
+			for _, m := range f.GetMetric() {
+				for _, lp := range m.GetLabel() {
+					if lp.GetName() == "subsystem" && lp.GetValue() == "state" {
+						assert.Equal(t, float64(8192), m.GetGauge().GetValue())
+					}
+				}
+			}
+		}
+
+		if f.GetName() == "omni_sqlite_db_size_bytes" {
+			require.Len(t, f.GetMetric(), 1)
+			assert.Greater(t, f.GetMetric()[0].GetGauge().GetValue(), float64(0))
+		}
+	}
+}
+
+func TestMetricsCaching(t *testing.T) {
+	t.Parallel()
+
+	db, st := setupTestDB(t)
+
+	execSQL(t, db, `
+		CREATE TABLE audit_logs (id INTEGER PRIMARY KEY, data TEXT);
+		INSERT INTO audit_logs (data) VALUES ('row1');
+	`)
+
+	registry := setupMetrics(t, db, &fakeSQLState{CoreState: st})
+
+	// First gather triggers refresh  audit_logs has 1 row.
+	expected := `
+		# HELP omni_sqlite_subsystem_row_count Total number of rows across a subsystem's tables.
+		# TYPE omni_sqlite_subsystem_row_count gauge
+		omni_sqlite_subsystem_row_count{subsystem="audit_logs"} 1
+		omni_sqlite_subsystem_row_count{subsystem="discovery"} 0
+		omni_sqlite_subsystem_row_count{subsystem="machine_logs"} 0
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_subsystem_row_count"))
+
+	// Insert another row.
+	execSQL(t, db, `INSERT INTO audit_logs (data) VALUES ('row2')`)
+
+	// Second gather should return cached value (default 60s interval not elapsed).
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_subsystem_row_count"))
+
+	// A new metrics instance with zero interval should see the new row.
+	registry2 := setupMetrics(t, db, &fakeSQLState{CoreState: st}, sqlite.WithRefreshInterval(0))
+
+	expected2 := `
+		# HELP omni_sqlite_subsystem_row_count Total number of rows across a subsystem's tables.
+		# TYPE omni_sqlite_subsystem_row_count gauge
+		omni_sqlite_subsystem_row_count{subsystem="audit_logs"} 2
+		omni_sqlite_subsystem_row_count{subsystem="discovery"} 0
+		omni_sqlite_subsystem_row_count{subsystem="machine_logs"} 0
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry2, strings.NewReader(expected2), "omni_sqlite_subsystem_row_count"))
+}
+
+func TestMetricsStateSubsystemUsesDBSizer(t *testing.T) {
+	t.Parallel()
+
+	db, st := setupTestDB(t)
+
+	registry := setupMetrics(t, db, &fakeSQLState{CoreState: st, size: 42000})
+
+	expected := `
+		# HELP omni_sqlite_subsystem_size_bytes Size of a subsystem's tables in the SQLite database in bytes.
+		# TYPE omni_sqlite_subsystem_size_bytes gauge
+		omni_sqlite_subsystem_size_bytes{subsystem="audit_logs"} 0
+		omni_sqlite_subsystem_size_bytes{subsystem="discovery"} 0
+		omni_sqlite_subsystem_size_bytes{subsystem="machine_logs"} 0
+		omni_sqlite_subsystem_size_bytes{subsystem="state"} 42000
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_subsystem_size_bytes"))
+}
+
+func TestMetricsEmptyDB(t *testing.T) {
+	t.Parallel()
+
+	db, st := setupTestDB(t)
+
+	registry := setupMetrics(t, db, &fakeSQLState{CoreState: st})
+
+	// All Omni subsystems should report 0 rows since no tables exist.
+	expected := `
+		# HELP omni_sqlite_subsystem_row_count Total number of rows across a subsystem's tables.
+		# TYPE omni_sqlite_subsystem_row_count gauge
+		omni_sqlite_subsystem_row_count{subsystem="audit_logs"} 0
+		omni_sqlite_subsystem_row_count{subsystem="discovery"} 0
+		omni_sqlite_subsystem_row_count{subsystem="machine_logs"} 0
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_subsystem_row_count"))
+}
+
+func TestCleanupCallback(t *testing.T) {
+	t.Parallel()
+
+	db, st := setupTestDB(t)
+	logger := zaptest.NewLogger(t)
+
+	m := sqlite.NewMetrics(db, &fakeSQLState{CoreState: st}, logger)
+
+	registry := prometheus.NewRegistry()
+	registry.MustRegister(m)
+
+	cb := m.CleanupCallback(sqlite.SubsystemAuditLogs)
+
+	// No calls yet  counter should not appear in output (no initialized series).
+	families, err := registry.Gather()
+	require.NoError(t, err)
+
+	for _, f := range families {
+		assert.NotEqual(t, "omni_sqlite_cleanup_rows_deleted_total", f.GetName(), "counter should not appear before any callback")
+	}
+
+	// Call with 0  should not initialize the counter.
+	cb(0)
+
+	families, err = registry.Gather()
+	require.NoError(t, err)
+
+	for _, f := range families {
+		assert.NotEqual(t, "omni_sqlite_cleanup_rows_deleted_total", f.GetName(), "counter should not appear after cb(0)")
+	}
+
+	// Call with positive value.
+	cb(5)
+	cb(3)
+
+	expected := `
+		# HELP omni_sqlite_cleanup_rows_deleted_total Total rows deleted by cleanup.
+		# TYPE omni_sqlite_cleanup_rows_deleted_total counter
+		omni_sqlite_cleanup_rows_deleted_total{subsystem="audit_logs"} 8
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected), "omni_sqlite_cleanup_rows_deleted_total"))
+
+	// Multiple subsystems.
+	mlCb := m.CleanupCallback(sqlite.SubsystemMachineLogs)
+	mlCb(10)
+
+	expected2 := `
+		# HELP omni_sqlite_cleanup_rows_deleted_total Total rows deleted by cleanup.
+		# TYPE omni_sqlite_cleanup_rows_deleted_total counter
+		omni_sqlite_cleanup_rows_deleted_total{subsystem="audit_logs"} 8
+		omni_sqlite_cleanup_rows_deleted_total{subsystem="machine_logs"} 10
+	`
+	assert.NoError(t, testutil.GatherAndCompare(registry, strings.NewReader(expected2), "omni_sqlite_cleanup_rows_deleted_total"))
+}
+
+// setupTestDB helper handles the standard SQLite test setup.
+func setupTestDB(t *testing.T) (*sqlitex.Pool, state.State) {
+	t.Helper()
+
+	path := filepath.Join(t.TempDir(), "test.db")
+	conf := config.Default().Storage.Sqlite
+	conf.SetPath(path)
+
+	db, err := sqlite.OpenDB(conf)
+	require.NoError(t, err)
+
+	t.Cleanup(func() {
+		require.NoError(t, db.Close())
+	})
+
+	state := state.WrapCore(namespaced.NewState(inmem.Build))
+
+	return db, state
+}
diff --git a/internal/backend/runtime/omni/sqlite/sqlite.go b/internal/backend/runtime/omni/sqlite/sqlite.go
index 4a3a20e6..b76a5872 100644
--- a/internal/backend/runtime/omni/sqlite/sqlite.go
+++ b/internal/backend/runtime/omni/sqlite/sqlite.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package sqlite provides helper functions for working with SQLite databases in the Omni runtime.
 package sqlite
 
 import (
diff --git a/internal/backend/runtime/omni/state.go b/internal/backend/runtime/omni/state.go
index 266cc4b4..144db013 100644
--- a/internal/backend/runtime/omni/state.go
+++ b/internal/backend/runtime/omni/state.go
@@ -49,10 +49,11 @@ type PersistentState struct {
 
 // State wraps virtual and default cosi states.
 type State struct {
-	virtualState *virtual.State
-	defaultState state.State
-	auditWrap    *AuditWrap
-	storeFactory store.FactoryWithMetrics
+	virtualState  *virtual.State
+	defaultState  state.State
+	auditWrap     *AuditWrap
+	storeFactory  store.FactoryWithMetrics
+	sqliteMetrics *sqlite.Metrics
 
 	logger *zap.Logger
 
@@ -71,6 +72,16 @@ func (s *State) SecondaryStorageDB() *sqlitex.Pool {
 	return s.secondaryStorageDB
 }
 
+// SecondaryPersistentState returns the secondary persistent state.
+func (s *State) SecondaryPersistentState() *PersistentState {
+	return s.secondaryPersistentState
+}
+
+// SQLiteMetrics returns the SQLite metrics collector.
+func (s *State) SQLiteMetrics() *sqlite.Metrics {
+	return s.sqliteMetrics
+}
+
 // Virtual returns the virtual state.
 func (s *State) Virtual() *virtual.State {
 	return s.virtualState
@@ -192,7 +203,10 @@ func NewState(ctx context.Context, params *config.Params, logger *zap.Logger, me
 		return nil, err
 	}
 
-	auditWrap, err := NewAuditWrap(ctx, defaultState, params, secondaryStorageDB, logger)
+	sqliteMetrics := sqlite.NewMetrics(secondaryStorageDB, secondaryPersistentState.State, logger)
+	metricsRegistry.MustRegister(sqliteMetrics)
+
+	auditWrap, err := NewAuditWrap(ctx, defaultState, params, secondaryStorageDB, logger, sqliteMetrics.CleanupCallback(sqlite.SubsystemAuditLogs))
 	if err != nil {
 		return nil, err
 	}
@@ -200,10 +214,11 @@ func NewState(ctx context.Context, params *config.Params, logger *zap.Logger, me
 	defaultState = auditWrap.WrapState(defaultState)
 
 	return &State{
-		defaultState: defaultState,
-		virtualState: virtualState,
-		auditWrap:    auditWrap,
-		storeFactory: storeFactory,
+		defaultState:  defaultState,
+		virtualState:  virtualState,
+		auditWrap:     auditWrap,
+		storeFactory:  storeFactory,
+		sqliteMetrics: sqliteMetrics,
 
 		defaultPersistentState:   defaultPersistentState,
 		secondaryPersistentState: secondaryPersistentState,
@@ -313,7 +328,7 @@ func stateWithMetrics(namespacedState *namespaced.State, metricsRegistry prometh
 }
 
 // NewAuditWrap creates a new audit wrap.
-func NewAuditWrap(ctx context.Context, resState state.State, params *config.Params, auditLogDB *sqlitex.Pool, logger *zap.Logger) (*AuditWrap, error) {
+func NewAuditWrap(ctx context.Context, resState state.State, params *config.Params, auditLogDB *sqlitex.Pool, logger *zap.Logger, onCleanup func(int)) (*AuditWrap, error) {
 	path := params.Logs.Audit.GetPath() //nolint:staticcheck
 
 	if path == "" && !params.Logs.Audit.GetEnabled() {
@@ -324,7 +339,12 @@ func NewAuditWrap(ctx context.Context, resState state.State, params *config.Para
 
 	logger.Info("audit log enabled")
 
-	a, err := audit.NewLog(ctx, params.Logs.Audit, auditLogDB, logger)
+	var logOpts []audit.LogOption
+	if onCleanup != nil {
+		logOpts = append(logOpts, audit.WithCleanupCallback(onCleanup))
+	}
+
+	a, err := audit.NewLog(ctx, params.Logs.Audit, auditLogDB, logger, logOpts...)
 	if err != nil {
 		return nil, err
 	}
diff --git a/internal/backend/runtime/omni/state_access.go b/internal/backend/runtime/omni/state_access.go
index e60d021f..bbbbd67a 100644
--- a/internal/backend/runtime/omni/state_access.go
+++ b/internal/backend/runtime/omni/state_access.go
@@ -349,7 +349,7 @@ func verbToRole(verb state.Verb) role.Role {
 	case state.Get, state.List, state.Watch:
 		return role.Reader
 	default:
-		panic(fmt.Sprintf("unknown verb %q", verb))
+		panic(fmt.Sprintf("unknown verb: %v", verb))
 	}
 }
 
diff --git a/internal/backend/runtime/omni/state_etcd.go b/internal/backend/runtime/omni/state_etcd.go
index d86ed8d5..952bd02f 100644
--- a/internal/backend/runtime/omni/state_etcd.go
+++ b/internal/backend/runtime/omni/state_etcd.go
@@ -77,7 +77,7 @@ func newEtcdPersistentState(ctx context.Context, params *config.Params, logger *
 
 	var cipher *encryption.Cipher
 
-	cipher, err = makeCipher(accountID, params.Storage.Default.Etcd, etcdState.Client(), logger, params.Storage.Vault.GetToken(), params.Storage.Vault.GetUrl()) //nolint:contextcheck
+	cipher, err = makeCipher(accountID, params.Storage.Default.Etcd, etcdState.Client(), logger, params.Storage.Vault) //nolint:contextcheck
 	if err != nil {
 		return nil, err
 	}
@@ -105,13 +105,13 @@ func newEtcdPersistentState(ctx context.Context, params *config.Params, logger *
 	}, nil
 }
 
-func makeCipher(name string, etcdParams config.EtcdParams, etcdClient etcd.Client, logger *zap.Logger, vaultToken, vaultURL string) (*encryption.Cipher, error) {
+func makeCipher(name string, etcdParams config.EtcdParams, etcdClient etcd.Client, logger *zap.Logger, vaultConfig config.Vault) (*encryption.Cipher, error) {
 	publicKeys, err := loadPublicKeys(etcdParams)
 	if err != nil {
 		return nil, err
 	}
 
-	loader, err := NewLoader(etcdParams.GetPrivateKeySource(), logger, vaultToken, vaultURL)
+	loader, err := NewLoader(etcdParams.GetPrivateKeySource(), logger, vaultConfig)
 	if err != nil {
 		return nil, err
 	}
diff --git a/internal/backend/runtime/omni/state_etcd_election_test.go b/internal/backend/runtime/omni/state_etcd_election_test.go
index 258abe48..4a454ae3 100644
--- a/internal/backend/runtime/omni/state_etcd_election_test.go
+++ b/internal/backend/runtime/omni/state_etcd_election_test.go
@@ -12,7 +12,6 @@ import (
 	"time"
 
 	"github.com/google/uuid"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
@@ -44,10 +43,10 @@ func TestEtcdElectionsLost(t *testing.T) {
 	logger := zaptest.NewLogger(t)
 
 	state, err := omni.GetEmbeddedEtcdClientWithServer(&config.EtcdParams{
-		Embedded:       pointer.To(true),
-		EmbeddedDBPath: pointer.To(t.TempDir()),
+		Embedded:       new(true),
+		EmbeddedDBPath: new(t.TempDir()),
 		Endpoints:      []string{"http://localhost:0"},
-		RunElections:   pointer.To(true),
+		RunElections:   new(true),
 	}, logger)
 
 	require.NoError(t, err)
@@ -94,10 +93,10 @@ func TestEtcdElections(t *testing.T) {
 	logger := zaptest.NewLogger(t)
 
 	state, err := omni.GetEmbeddedEtcdClientWithServer(&config.EtcdParams{
-		Embedded:       pointer.To(true),
-		EmbeddedDBPath: pointer.To(t.TempDir()),
+		Embedded:       new(true),
+		EmbeddedDBPath: new(t.TempDir()),
 		Endpoints:      []string{"http://localhost:0"},
-		RunElections:   pointer.To(true),
+		RunElections:   new(true),
 	}, logger)
 
 	require.NoError(t, err)
diff --git a/internal/backend/runtime/omni/state_etcd_test.go b/internal/backend/runtime/omni/state_etcd_test.go
index d2aa801c..473efa24 100644
--- a/internal/backend/runtime/omni/state_etcd_test.go
+++ b/internal/backend/runtime/omni/state_etcd_test.go
@@ -18,7 +18,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/cosi-project/runtime/pkg/state"
 	"github.com/siderolabs/gen/xtesting/check"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
 
@@ -129,14 +128,14 @@ func TestEtcdInitialization(t *testing.T) {
 			state, err := omni.NewEtcdPersistentState(ctx,
 				&config.Params{
 					Account: config.Account{
-						Name: pointer.To("instance-name"),
+						Name: new("instance-name"),
 					},
 					Storage: config.Storage{
 						Default: config.StorageDefault{
 							Etcd: config.EtcdParams{
-								Embedded:         pointer.To(true),
-								EmbeddedDBPath:   pointer.To(etcdDir),
-								PrivateKeySource: pointer.To(step.args.privateKeySource),
+								Embedded:         new(true),
+								EmbeddedDBPath:   new(etcdDir),
+								PrivateKeySource: new(step.args.privateKeySource),
 								PublicKeyFiles:   step.args.publicKeyFiles,
 								Endpoints:        []string{"http://localhost:0"},
 							},
@@ -208,14 +207,14 @@ func TestEncryptDecrypt(t *testing.T) {
 			state, err := omni.NewEtcdPersistentState(ctx,
 				&config.Params{
 					Account: config.Account{
-						Name: pointer.To("instance-name"),
+						Name: new("instance-name"),
 					},
 					Storage: config.Storage{
 						Default: config.StorageDefault{
 							Etcd: config.EtcdParams{
-								Embedded:         pointer.To(true),
-								EmbeddedDBPath:   pointer.To(etcdDir),
-								PrivateKeySource: pointer.To(step.args.privateKeySource),
+								Embedded:         new(true),
+								EmbeddedDBPath:   new(etcdDir),
+								PrivateKeySource: new(step.args.privateKeySource),
 								PublicKeyFiles:   step.args.publicKeyFiles,
 								Endpoints:        []string{"http://localhost:0"},
 							},
diff --git a/internal/backend/runtime/omni/state_validation_test.go b/internal/backend/runtime/omni/state_validation_test.go
index 304d4b49..0388a066 100644
--- a/internal/backend/runtime/omni/state_validation_test.go
+++ b/internal/backend/runtime/omni/state_validation_test.go
@@ -26,7 +26,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	"github.com/google/uuid"
 	"github.com/siderolabs/gen/xiter"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap"
@@ -73,9 +72,9 @@ func TestClusterValidation(t *testing.T) { //nolint:gocognit,maintidx
 	t.Cleanup(cancel)
 
 	etcdBackupConfig := config.EtcdBackup{
-		TickInterval: pointer.To(time.Minute),
-		MinInterval:  pointer.To(time.Hour),
-		MaxInterval:  pointer.To(24 * time.Hour),
+		TickInterval: new(time.Minute),
+		MinInterval:  new(time.Hour),
+		MaxInterval:  new(24 * time.Hour),
 	}
 
 	innerSt := state.WrapCore(namespaced.NewState(inmem.Build))
@@ -474,7 +473,7 @@ func TestClusterUseEmbeddedDiscoveryServiceValidation(t *testing.T) {
 		t.Parallel()
 
 		_, st := buildState(config.EmbeddedDiscoveryService{
-			Enabled: pointer.To(false),
+			Enabled: new(false),
 		})
 
 		cluster := omnires.NewCluster("test")
@@ -494,7 +493,7 @@ func TestClusterUseEmbeddedDiscoveryServiceValidation(t *testing.T) {
 
 		// prepare a cluster which has the feature enabled, while it is disabled instance-wide
 		innerSt, st := buildState(config.EmbeddedDiscoveryService{
-			Enabled: pointer.To(false),
+			Enabled: new(false),
 		})
 
 		talosVersion := omnires.NewTalosVersion("1.7.4")
@@ -523,7 +522,7 @@ func TestClusterUseEmbeddedDiscoveryServiceValidation(t *testing.T) {
 		t.Parallel()
 
 		_, st := buildState(config.EmbeddedDiscoveryService{
-			Enabled: pointer.To(true),
+			Enabled: new(true),
 		})
 
 		talosVersion := omnires.NewTalosVersion("1.7.4")
@@ -558,7 +557,7 @@ func TestRelationLabelsValidation(t *testing.T) {
 	differentClusterID := "different-cluster"
 	machineSetID := "test-machine-set"
 	differentMachineSetID := "different-machine-set"
-	machineSetNodeId := "test-machine-set-node"
+	machineSetNodeID := "test-machine-set-node"
 
 	// MachineSet
 
@@ -592,7 +591,7 @@ func TestRelationLabelsValidation(t *testing.T) {
 
 	machineSet.Metadata().Labels().Set(omnires.LabelCluster, clusterID)
 
-	machineSetNode := omnires.NewMachineSetNode(machineSetNodeId, machineSet)
+	machineSetNode := omnires.NewMachineSetNode(machineSetNodeID, machineSet)
 
 	machineSetNode.Metadata().Labels().Delete(omnires.LabelCluster)
 	machineSetNode.Metadata().Labels().Delete(omnires.LabelMachineSet)
@@ -911,9 +910,9 @@ func TestClusterLockedAnnotation(t *testing.T) {
 	innerSt := state.WrapCore(namespaced.NewState(inmem.Build))
 	etcdBackupStoreFactory, err := store.NewStoreFactory(config.EtcdBackup{})
 	etcdBackupConfig := config.EtcdBackup{
-		TickInterval: pointer.To(time.Minute),
-		MinInterval:  pointer.To(time.Hour),
-		MaxInterval:  pointer.To(24 * time.Hour),
+		TickInterval: new(time.Minute),
+		MinInterval:  new(time.Hour),
+		MaxInterval:  new(24 * time.Hour),
 	}
 
 	require.NoError(t, err)
@@ -1027,9 +1026,9 @@ func TestClusterImport(t *testing.T) {
 	innerSt := state.WrapCore(namespaced.NewState(inmem.Build))
 	etcdBackupStoreFactory, err := store.NewStoreFactory(config.EtcdBackup{})
 	etcdBackupConfig := config.EtcdBackup{
-		TickInterval: pointer.To(time.Minute),
-		MinInterval:  pointer.To(time.Hour),
-		MaxInterval:  pointer.To(24 * time.Hour),
+		TickInterval: new(time.Minute),
+		MinInterval:  new(time.Hour),
+		MaxInterval:  new(24 * time.Hour),
 	}
 
 	require.NoError(t, err)
@@ -1093,7 +1092,7 @@ func TestIdentitySAMLValidation(t *testing.T) {
 
 	innerSt := state.WrapCore(namespaced.NewState(inmem.Build))
 	st := validated.NewState(innerSt, omni.IdentityValidationOptions(config.SAML{
-		Enabled: pointer.To(true),
+		Enabled: new(true),
 	})...)
 
 	user := auth.NewIdentity("aaa@example.org")
diff --git a/internal/backend/runtime/proxy_runtime_test.go b/internal/backend/runtime/proxy_runtime_test.go
index cd081b8b..c333f3f0 100644
--- a/internal/backend/runtime/proxy_runtime_test.go
+++ b/internal/backend/runtime/proxy_runtime_test.go
@@ -15,7 +15,6 @@ import (
 
 	"github.com/cosi-project/runtime/pkg/resource"
 	"github.com/siderolabs/gen/ensure"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 
@@ -129,7 +128,7 @@ func TestProxyRuntime_Watch(t *testing.T) {
 }
 
 func makeResponse(i int) runtime.WatchResponse {
-	return pointer.To(runtime.NewBasicResponse(
+	return new(runtime.NewBasicResponse(
 		fmt.Sprintf("id-%d", i),
 		fmt.Sprintf("msg-%d", i),
 		&resources.WatchResponse{Event: &resources.Event{}},
@@ -210,7 +209,7 @@ func appendBootstrapped(msgs []runtime.WatchResponse) []runtime.WatchResponse {
 	if !slices.ContainsFunc(msgs, func(response runtime.WatchResponse) bool {
 		return runtime.EventType(response) == resources.EventType_BOOTSTRAPPED
 	}) {
-		msgs = append(msgs, pointer.To(runtime.NewBasicResponse(
+		msgs = append(msgs, new(runtime.NewBasicResponse(
 			"",
 			"",
 			&resources.WatchResponse{Event: &resources.Event{EventType: resources.EventType_BOOTSTRAPPED}},
diff --git a/internal/integration/auth_test.go b/internal/integration/auth_test.go
index 921243d0..d29065af 100644
--- a/internal/integration/auth_test.go
+++ b/internal/integration/auth_test.go
@@ -10,6 +10,7 @@ package integration_test
 import (
 	"bytes"
 	"context"
+	"crypto/md5"
 	_ "embed"
 	"encoding/base64"
 	"encoding/json"
@@ -23,6 +24,7 @@ import (
 	"slices"
 	"strconv"
 	"strings"
+	"sync"
 	"testing"
 	"time"
 
@@ -36,7 +38,6 @@ import (
 	"github.com/google/uuid"
 	"github.com/siderolabs/gen/maps"
 	"github.com/siderolabs/gen/xslices"
-	authcli "github.com/siderolabs/go-api-signature/pkg/client/auth"
 	"github.com/siderolabs/go-api-signature/pkg/client/interceptor"
 	"github.com/siderolabs/go-api-signature/pkg/message"
 	"github.com/siderolabs/go-api-signature/pkg/pgp"
@@ -73,10 +74,114 @@ import (
 	"github.com/siderolabs/omni/internal/backend/runtime/omni/validated"
 	"github.com/siderolabs/omni/internal/pkg/auth"
 	"github.com/siderolabs/omni/internal/pkg/auth/role"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
 	"github.com/siderolabs/omni/internal/pkg/grpcutil"
 )
 
+// testClientFactory creates test clients with specific roles for authorization testing.
+// It uses the root client (automation SA) to create new service accounts with the specified role,
+// then returns a client authenticated as that SA. Clients are cached by role.
+type testClientFactory struct {
+	endpoint          string
+	serviceAccountKey string
+	rootCli           *client.Client
+
+	mu      sync.Mutex
+	clients map[role.Role]*client.Client
+}
+
+func newTestClientFactory(endpoint string, rootCli *client.Client) *testClientFactory {
+	return &testClientFactory{
+		endpoint: endpoint,
+		rootCli:  rootCli,
+		clients:  make(map[role.Role]*client.Client),
+	}
+}
+
+func (f *testClientFactory) getClient(ctx context.Context, r role.Role) (*client.Client, error) {
+	f.mu.Lock()
+	defer f.mu.Unlock()
+
+	if cli, ok := f.clients[r]; ok {
+		return cli, nil
+	}
+
+	cli, err := f.createClientForRole(ctx, r)
+	if err != nil {
+		return nil, err
+	}
+
+	f.clients[r] = cli
+
+	return cli, nil
+}
+
+func (f *testClientFactory) createClientForRole(ctx context.Context, r role.Role) (*client.Client, error) {
+	name := fmt.Sprintf("%x", md5.Sum([]byte(string(r))))
+
+	comment := fmt.Sprintf("%s/%s", runtime.GOOS, runtime.GOARCH)
+
+	suffix := access.ServiceAccountNameSuffix
+	if r == role.InfraProvider {
+		suffix = access.InfraProviderServiceAccountNameSuffix
+	}
+
+	serviceAccountEmail := name + suffix
+
+	key, err := pgp.GenerateKey(name, comment, serviceAccountEmail, auth.ServiceAccountMaxAllowedLifetime)
+	if err != nil {
+		return nil, err
+	}
+
+	if r == role.InfraProvider {
+		name = access.InfraProviderServiceAccountPrefix + name
+	}
+
+	armoredPublicKey, err := key.ArmorPublic()
+	if err != nil {
+		return nil, err
+	}
+
+	serviceAccounts, err := f.rootCli.Management().ListServiceAccounts(ctx)
+	if err != nil {
+		return nil, err
+	}
+
+	if slices.IndexFunc(serviceAccounts, func(account *management.ListServiceAccountsResponse_ServiceAccount) bool {
+		return account.Name == name
+	}) != -1 {
+		if err = f.rootCli.Management().DestroyServiceAccount(ctx, name); err != nil {
+			return nil, err
+		}
+	}
+
+	_, err = f.rootCli.Management().CreateServiceAccount(ctx, name, armoredPublicKey, string(r), false)
+	if err != nil {
+		return nil, err
+	}
+
+	encodedKey, err := serviceaccount.Encode(name, key)
+	if err != nil {
+		return nil, err
+	}
+
+	return client.New(f.endpoint, client.WithServiceAccount(encodedKey))
+}
+
+func (f *testClientFactory) close() error {
+	f.mu.Lock()
+	defer f.mu.Unlock()
+
+	var errs []error
+
+	for _, cli := range f.clients {
+		if err := cli.Close(); err != nil {
+			errs = append(errs, err)
+		}
+	}
+
+	return errors.Join(errs...)
+}
+
 // AssertAnonymousAuthentication tests the authentication without any credentials.
 func AssertAnonymousAuthentication(testCtx context.Context, client *client.Client) TestFunc {
 	return func(t *testing.T) {
@@ -336,7 +441,7 @@ type apiAuthzTestCase struct {
 // AssertAPIAuthz tests the authorization checks of the API endpoints.
 //
 //nolint:gocognit,gocyclo,cyclop,maintidx
-func AssertAPIAuthz(rootCtx context.Context, rootCli *client.Client, clientConfig *clientconfig.ClientConfig, clusterName string) TestFunc {
+func AssertAPIAuthz(rootCtx context.Context, rootCli *client.Client, clientFactory *testClientFactory, clusterName string) TestFunc {
 	rootCtx = metadata.NewOutgoingContext(rootCtx, metadata.Pairs(grpcutil.LogLevelOverrideMetadataKey, zapcore.PanicLevel.String()))
 
 	assertSuccess := func(t *testing.T, err error) {
@@ -555,13 +660,10 @@ func AssertAPIAuthz(rootCtx context.Context, rootCli *client.Client, clientConfi
 		for _, tc := range testCases {
 			// test each test case without signature
 			t.Run(fmt.Sprintf("%s-no-signature", tc.namePrefix), func(t *testing.T) {
-				scopedClient, testErr := clientConfig.GetClient(rootCtx)
-				require.NoError(t, testErr)
-
 				// skip signing the request
 				ctx := context.WithValue(rootCtx, interceptor.SkipInterceptorContextKey{}, struct{}{})
 
-				testErr = tc.fn(ctx, scopedClient)
+				testErr := tc.fn(ctx, rootCli)
 
 				// public resources will either succeed or fail with a permission denied if they are read-only resources
 				if tc.isPublic {
@@ -586,11 +688,7 @@ func AssertAPIAuthz(rootCtx context.Context, rootCli *client.Client, clientConfi
 
 			// test with the role which should succeed
 			t.Run(fmt.Sprintf("%s-success", tc.namePrefix), func(t *testing.T) {
-				scopedClient, testErr := clientConfig.GetClient(
-					rootCtx,
-					authcli.WithRole(string(tc.requiredRole)),
-					authcli.WithSkipUserRole(true),
-				)
+				scopedClient, testErr := clientFactory.getClient(rootCtx, tc.requiredRole)
 				require.NoError(t, testErr)
 
 				assertCurrentUserRole(rootCtx, t, scopedClient.Omni().State(), tc.requiredRole)
@@ -613,10 +711,7 @@ func AssertAPIAuthz(rootCtx context.Context, rootCli *client.Client, clientConfi
 			require.NoError(t, err)
 
 			t.Run(fmt.Sprintf("%s-failure", tc.namePrefix), func(t *testing.T) {
-				scopedClient, testErr := clientConfig.GetClient(
-					rootCtx,
-					authcli.WithRole(string(failureRole)),
-					authcli.WithSkipUserRole(true))
+				scopedClient, testErr := clientFactory.getClient(rootCtx, failureRole)
 				require.NoError(t, testErr)
 
 				assertCurrentUserRole(rootCtx, t, scopedClient.Omni().State(), failureRole)
@@ -641,7 +736,7 @@ type resourceAuthzTestCase struct {
 // AssertResourceAuthz tests the authorization checks of the resources (state).
 //
 //nolint:gocognit,gocyclo,cyclop,maintidx
-func AssertResourceAuthz(rootCtx context.Context, rootCli *client.Client, clientConfig *clientconfig.ClientConfig) TestFunc {
+func AssertResourceAuthz(rootCtx context.Context, rootCli *client.Client, clientFactory *testClientFactory) TestFunc {
 	rootCtx = metadata.NewOutgoingContext(rootCtx, metadata.Pairs(grpcutil.LogLevelOverrideMetadataKey, zapcore.PanicLevel.String()))
 
 	return func(t *testing.T) {
@@ -1247,11 +1342,7 @@ func AssertResourceAuthz(rootCtx context.Context, rootCli *client.Client, client
 					delete(untestedResourceTypes, tc.resource.Metadata().Type())
 
 					t.Run(name, func(t *testing.T) {
-						scopedCli, testErr := clientConfig.GetClient(
-							rootCtx,
-							authcli.WithRole(string(testRole)),
-							authcli.WithSkipUserRole(true),
-						)
+						scopedCli, testErr := clientFactory.getClient(rootCtx, testRole)
 						require.NoError(t, testErr)
 
 						// ensure that scopedCli is operating with the correct role
@@ -1377,12 +1468,13 @@ var (
 
 const grpcMetadataPrefix = "Grpc-Metadata-"
 
-func AssertFrontendResourceAPI(ctx context.Context, rootCli *client.Client, clientConfig *clientconfig.ClientConfig, httpEndpoint, clusterName string) TestFunc {
+func AssertFrontendResourceAPI(ctx context.Context, rootCli *client.Client, serviceAccountKey, httpEndpoint, clusterName string) TestFunc {
 	return func(t *testing.T) {
-		key, err := clientConfig.GetKey(ctx)
+		sa, err := serviceaccount.Decode(serviceAccountKey)
 		require.NoError(t, err)
 
-		email := clientconfig.DefaultServiceAccount
+		key := sa.Key
+		email := sa.Name + access.ServiceAccountNameSuffix
 
 		// do the same flow for the signature as in the JS code
 		signRequest := func(request *http.Request) error {
@@ -1780,10 +1872,10 @@ func assertCurrentUserRole(ctx context.Context, t *testing.T, st state.State, ex
 	assert.Equal(t, string(expected), currentUser.TypedSpec().Value.GetRole(), "invalid role on current user virtual resource: %v", currentUser.TypedSpec().Value.GetRole())
 }
 
-func destroy(ctx context.Context, t *testing.T, rootClient *client.Client, md *resource.Metadata) {
+func destroy(ctx context.Context, t *testing.T, omniClient *client.Client, md *resource.Metadata) {
 	t.Logf("destroying created resource %s", md.String())
 
-	_, err := rootClient.Omni().State().Teardown(ctx, md)
+	_, err := omniClient.Omni().State().Teardown(ctx, md)
 	if state.IsNotFoundError(err) {
 		return
 	}
@@ -1791,7 +1883,7 @@ func destroy(ctx context.Context, t *testing.T, rootClient *client.Client, md *r
 	require.NoError(t, err)
 
 	err = retry.Constant(5*time.Second, retry.WithUnits(100*time.Millisecond)).RetryWithContext(ctx, func(ctx context.Context) error {
-		err = rootClient.Omni().State().Destroy(ctx, md)
+		err = omniClient.Omni().State().Destroy(ctx, md)
 		if err != nil {
 			if state.IsNotFoundError(err) {
 				return nil
diff --git a/internal/integration/blocks_test.go b/internal/integration/blocks_test.go
index e2938c8e..8bbe6a4c 100644
--- a/internal/integration/blocks_test.go
+++ b/internal/integration/blocks_test.go
@@ -14,27 +14,28 @@ import (
 	"github.com/cosi-project/runtime/pkg/resource"
 
 	"github.com/siderolabs/omni/client/api/omni/specs"
-	"github.com/siderolabs/omni/client/pkg/client"
 	"github.com/siderolabs/omni/client/pkg/client/management"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 )
 
 // AssertBlockClusterShouldBeReady is a reusable block of assertions that can be used to verify that a cluster is fully ready.
-func AssertBlockClusterShouldBeReady(ctx context.Context, rootClient *client.Client, clusterName,
+func AssertBlockClusterShouldBeReady(ctx context.Context, options *TestOptions, clusterName,
 	expectedTalosVersion string,
 ) subTestList { //nolint:nolintlint,revive
+	omniClient := options.omniClient
+
 	return subTestList{
 		{
 			"ClusterMachinesShouldBeRunning",
-			AssertClusterMachinesStage(ctx, rootClient.Omni().State(), clusterName, specs.ClusterMachineStatusSpec_RUNNING),
+			AssertClusterMachinesStage(ctx, omniClient.Omni().State(), clusterName, specs.ClusterMachineStatusSpec_RUNNING),
 		},
 		{
 			"ClusterMachinesShouldBeReady",
-			AssertClusterMachinesReady(ctx, rootClient.Omni().State(), clusterName),
+			AssertClusterMachinesReady(ctx, omniClient.Omni().State(), clusterName),
 		},
 		{
 			"MachinesStatusShouldBeNotAvailable",
-			AssertMachineStatus(ctx, rootClient.Omni().State(), false, clusterName, map[string]string{
+			AssertMachineStatus(ctx, omniClient.Omni().State(), false, clusterName, map[string]string{
 				omni.MachineStatusLabelConnected:       "",
 				omni.MachineStatusLabelReportingEvents: "",
 			},
@@ -43,37 +44,37 @@ func AssertBlockClusterShouldBeReady(ctx context.Context, rootClient *client.Cli
 		},
 		{
 			"ClusterShouldHaveStatusReady",
-			AssertClusterStatusReady(ctx, rootClient.Omni().State(), clusterName),
+			AssertClusterStatusReady(ctx, omniClient.Omni().State(), clusterName),
 		},
 		{
 			"ClusterLoadBalancerShouldBeReady",
-			AssertClusterLoadBalancerReady(ctx, rootClient.Omni().State(), clusterName),
+			AssertClusterLoadBalancerReady(ctx, omniClient.Omni().State(), clusterName),
 		},
 		{
 			"EtcdMembersShouldMatchOmniResources",
-			AssertEtcdMembershipMatchesOmniResources(ctx, rootClient, clusterName),
+			AssertEtcdMembershipMatchesOmniResources(ctx, options, clusterName),
 		},
 		{
 			"TalosMembersShouldMatchOmniResources",
-			AssertTalosMembersMatchOmni(ctx, rootClient, clusterName),
+			AssertTalosMembersMatchOmni(ctx, options, clusterName),
 		},
 		{
 			"TalosVersionShouldMatchExpected",
-			AssertTalosVersion(ctx, rootClient, clusterName, expectedTalosVersion),
+			AssertTalosVersion(ctx, options, clusterName, expectedTalosVersion),
 		},
 	}
 }
 
 // AssertBlockProxyAPIAccessShouldWork is a reusable block of assertions that can be used to verify that Omni API proxies work.
-func AssertBlockProxyAPIAccessShouldWork(ctx context.Context, rootClient *client.Client, clusterName string) []subTest { //nolint:nolintlint,revive
+func AssertBlockProxyAPIAccessShouldWork(ctx context.Context, options *TestOptions, clusterName string) []subTest { //nolint:nolintlint,revive
 	return []subTest{
 		{
 			"ClusterKubernetesAPIShouldBeAccessibleViaOmni",
-			AssertKubernetesAPIAccessViaOmni(ctx, rootClient, clusterName, true, 5*time.Minute),
+			AssertKubernetesAPIAccessViaOmni(ctx, options.omniClient, clusterName, true, 5*time.Minute),
 		},
 		{
 			"ClusterTalosAPIShouldBeAccessibleViaOmni",
-			AssertTalosAPIAccessViaOmni(ctx, rootClient, clusterName),
+			AssertTalosAPIAccessViaOmni(ctx, options, clusterName),
 		},
 	}
 }
@@ -84,46 +85,49 @@ func AssertBlockProxyAPIAccessShouldWork(ctx context.Context, rootClient *client
 //
 // This block is a bit slower than TestsBlockClusterShouldBeReady, because it also verifies Kubernetes version.
 func AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(
-	ctx context.Context, rootClient *client.Client,
+	ctx context.Context, options *TestOptions,
 	clusterName, expectedTalosVersion, expectedKubernetesVersion string,
 ) []subTest { //nolint:nolintlint,revive
-	return AssertBlockClusterShouldBeReady(ctx, rootClient, clusterName, expectedTalosVersion).
-		Append(AssertBlockProxyAPIAccessShouldWork(ctx, rootClient, clusterName)...).
+	omniState := options.omniClient.Omni().State()
+	return AssertBlockClusterShouldBeReady(ctx, options, clusterName, expectedTalosVersion).
+		Append(AssertBlockProxyAPIAccessShouldWork(ctx, options, clusterName)...).
 		Append(
 			subTest{
 				"ClusterKubernetesVersionShouldBeCorrect",
-				AssertClusterKubernetesVersion(ctx, rootClient.Omni().State(), clusterName, expectedKubernetesVersion),
+				AssertClusterKubernetesVersion(ctx, omniState, clusterName, expectedKubernetesVersion),
 			},
 			subTest{
 				"ClusterBootstrapManifestsShouldBeInSync",
-				AssertClusterBootstrapManifestStatus(ctx, rootClient.Omni().State(), clusterName),
+				AssertClusterBootstrapManifestStatus(ctx, omniState, clusterName),
 			},
 		).
 		Append(
 			subTest{
 				"ClusterKubernetesUsageShouldBeCorrect",
-				AssertClusterKubernetesUsage(ctx, rootClient.Omni().State(), clusterName),
+				AssertClusterKubernetesUsage(ctx, omniState, clusterName),
 			},
 		)
 }
 
 // AssertBlockRestoreEtcdFromLatestBackup is a reusable block of assertions that can be used to verify that a
 // cluster's control plane can be broken, destroyed and then restored from an etcd backup.
-func AssertBlockRestoreEtcdFromLatestBackup(ctx context.Context, rootClient *client.Client,
+func AssertBlockRestoreEtcdFromLatestBackup(ctx context.Context, testOptions *TestOptions,
 	options Options, controlPlaneNodeCount int, clusterName, assertDeploymentNS, assertDeploymentName string,
 ) subTestList { //nolint:nolintlint,revive
+	omniClient := testOptions.omniClient
+
 	return subTestList{
 		subTest{
 			"ControlPlaneShouldBeBrokenThenDestroyed",
-			AssertBreakAndDestroyControlPlane(ctx, rootClient.Omni().State(), clusterName, options),
+			AssertBreakAndDestroyControlPlane(ctx, omniClient.Omni().State(), clusterName, options),
 		},
 		subTest{
 			"ControlPlaneShouldBeRestoredFromBackup",
-			AssertControlPlaneCanBeRestoredFromBackup(ctx, rootClient.Omni().State(), clusterName),
+			AssertControlPlaneCanBeRestoredFromBackup(ctx, omniClient.Omni().State(), clusterName),
 		},
 		subTest{
 			"ControlPlaneShouldBeScaledUp",
-			ScaleClusterUp(ctx, rootClient.Omni().State(), ClusterOptions{
+			ScaleClusterUp(ctx, omniClient.Omni().State(), ClusterOptions{
 				Name:           clusterName,
 				ControlPlanes:  controlPlaneNodeCount,
 				MachineOptions: options.MachineOptions,
@@ -133,47 +137,49 @@ func AssertBlockRestoreEtcdFromLatestBackup(ctx context.Context, rootClient *cli
 	}.Append(
 		subTest{
 			"ClusterShouldHaveStatusReady",
-			AssertClusterStatusReady(ctx, rootClient.Omni().State(), clusterName),
+			AssertClusterStatusReady(ctx, omniClient.Omni().State(), clusterName),
 		},
 		subTest{
 			"ClusterLoadBalancerShouldBeReady",
-			AssertClusterLoadBalancerReady(ctx, rootClient.Omni().State(), clusterName),
+			AssertClusterLoadBalancerReady(ctx, omniClient.Omni().State(), clusterName),
 		},
 		subTest{
 			"EtcdMembersShouldMatchOmniResources",
-			AssertEtcdMembershipMatchesOmniResources(ctx, rootClient, clusterName),
+			AssertEtcdMembershipMatchesOmniResources(ctx, testOptions, clusterName),
 		},
 	).Append(
 		subTest{
 			"KubernetesAPIShouldBeAccessible",
-			AssertKubernetesAPIAccessViaOmni(ctx, rootClient, clusterName, false, 300*time.Second),
+			AssertKubernetesAPIAccessViaOmni(ctx, omniClient, clusterName, false, 300*time.Second),
 		},
 		subTest{
 			"ClusterNodesShouldBeInDesiredState",
-			AssertKubernetesNodesState(ctx, rootClient, clusterName),
+			AssertKubernetesNodesState(ctx, omniClient, clusterName),
 		},
 		subTest{
 			"KubeletShouldBeRestartedOnWorkers",
-			AssertTalosServiceIsRestarted(ctx, rootClient, clusterName, "kubelet", resource.LabelExists(omni.LabelWorkerRole)),
+			AssertTalosServiceIsRestarted(ctx, testOptions, clusterName, "kubelet", resource.LabelExists(omni.LabelWorkerRole)),
 		},
 		subTest{
 			"KubernetesDeploymentShouldHaveRunningPods",
-			AssertKubernetesDeploymentHasRunningPods(ctx, rootClient.Management(), clusterName, assertDeploymentNS, assertDeploymentName),
+			AssertKubernetesDeploymentHasRunningPods(ctx, omniClient.Management(), clusterName, assertDeploymentNS, assertDeploymentName),
 		},
 	).Append(
-		AssertBlockKubernetesDeploymentCreateAndRunning(ctx, rootClient.Management(), clusterName, assertDeploymentNS, assertDeploymentName+"-after-restore")...,
+		AssertBlockKubernetesDeploymentCreateAndRunning(ctx, omniClient.Management(), clusterName, assertDeploymentNS, assertDeploymentName+"-after-restore")...,
 	)
 }
 
 // AssertBlockCreateClusterFromEtcdBackup is a reusable block of assertions that can be used to verify that a
 // new cluster can be created from another cluster's etcd backup.
-func AssertBlockCreateClusterFromEtcdBackup(ctx context.Context, rootClient *client.Client, options Options,
+func AssertBlockCreateClusterFromEtcdBackup(ctx context.Context, testOptions *TestOptions, options Options,
 	sourceClusterName, newClusterName, assertDeploymentNS, assertDeploymentName string,
 ) subTestList { //nolint:nolintlint,revive
+	omniClient := testOptions.omniClient
+
 	return subTestList{
 		subTest{
 			"ClusterShouldBeCreatedFromEtcdBackup",
-			CreateCluster(ctx, rootClient, ClusterOptions{
+			CreateCluster(ctx, testOptions, ClusterOptions{
 				Name:          newClusterName,
 				ControlPlanes: 1,
 				Workers:       1,
@@ -187,31 +193,31 @@ func AssertBlockCreateClusterFromEtcdBackup(ctx context.Context, rootClient *cli
 	}.Append(
 		subTest{
 			"ClusterShouldHaveStatusReady",
-			AssertClusterStatusReady(ctx, rootClient.Omni().State(), newClusterName),
+			AssertClusterStatusReady(ctx, omniClient.Omni().State(), newClusterName),
 		},
 		subTest{
 			"ClusterLoadBalancerShouldBeReady",
-			AssertClusterLoadBalancerReady(ctx, rootClient.Omni().State(), newClusterName),
+			AssertClusterLoadBalancerReady(ctx, omniClient.Omni().State(), newClusterName),
 		},
 		subTest{
 			"EtcdMembersShouldMatchOmniResources",
-			AssertEtcdMembershipMatchesOmniResources(ctx, rootClient, newClusterName),
+			AssertEtcdMembershipMatchesOmniResources(ctx, testOptions, newClusterName),
 		},
 	).Append(
 		subTest{
 			"KubernetesAPIShouldBeAccessible",
-			AssertKubernetesAPIAccessViaOmni(ctx, rootClient, newClusterName, false, 300*time.Second),
+			AssertKubernetesAPIAccessViaOmni(ctx, omniClient, newClusterName, false, 300*time.Second),
 		},
 		subTest{
 			"ClusterNodesShouldBeInDesiredState",
-			AssertKubernetesNodesState(ctx, rootClient, newClusterName),
+			AssertKubernetesNodesState(ctx, omniClient, newClusterName),
 		},
 		subTest{
 			"KubernetesDeploymentShouldHaveRunningPods",
-			AssertKubernetesDeploymentHasRunningPods(ctx, rootClient.Management(), newClusterName, assertDeploymentNS, assertDeploymentName),
+			AssertKubernetesDeploymentHasRunningPods(ctx, omniClient.Management(), newClusterName, assertDeploymentNS, assertDeploymentName),
 		},
 	).Append(
-		AssertBlockKubernetesDeploymentCreateAndRunning(ctx, rootClient.Management(), newClusterName, assertDeploymentNS, assertDeploymentName+"-after-restore")...,
+		AssertBlockKubernetesDeploymentCreateAndRunning(ctx, omniClient.Management(), newClusterName, assertDeploymentNS, assertDeploymentName+"-after-restore")...,
 	)
 }
 
@@ -231,23 +237,25 @@ func AssertBlockKubernetesDeploymentCreateAndRunning(ctx context.Context, manage
 }
 
 // AssertClusterCreateAndReady is a reusable group of tests that can be used to verify that a cluster is created and ready.
-func AssertClusterCreateAndReady(ctx context.Context, rootClient *client.Client, options ClusterOptions) []subTest { //nolint:nolintlint,revive
+func AssertClusterCreateAndReady(ctx context.Context, testOptions *TestOptions, options ClusterOptions) []subTest { //nolint:nolintlint,revive
+	omniClient := testOptions.omniClient
+
 	return subTests(
 		subTest{
 			"ClusterShouldBeCreated",
-			CreateCluster(ctx, rootClient, options),
+			CreateCluster(ctx, testOptions, options),
 		},
 	).Append(
-		AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(ctx, rootClient, options.Name, options.MachineOptions.TalosVersion, options.MachineOptions.KubernetesVersion)...,
+		AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(ctx, testOptions, options.Name, options.MachineOptions.TalosVersion, options.MachineOptions.KubernetesVersion)...,
 	).Append(
 		subTest{
 			"AssertSupportBundleContents",
-			AssertSupportBundleContents(ctx, rootClient, options.Name),
+			AssertSupportBundleContents(ctx, omniClient, options.Name),
 		},
 	).Append(
 		subTest{
 			"ClusterShouldBeDestroyed",
-			AssertDestroyCluster(ctx, rootClient.Omni().State(), options.Name, options.InfraProvider != "", false),
+			AssertDestroyCluster(ctx, omniClient.Omni().State(), options.Name, options.InfraProvider != "", false),
 		},
 	)
 }
diff --git a/internal/integration/cluster_test.go b/internal/integration/cluster_test.go
index 39a1c529..2f0e1bd1 100644
--- a/internal/integration/cluster_test.go
+++ b/internal/integration/cluster_test.go
@@ -77,7 +77,7 @@ type ClusterOptions struct {
 }
 
 // CreateCluster verifies cluster creation.
-func CreateCluster(testCtx context.Context, cli *client.Client, options ClusterOptions) TestFunc {
+func CreateCluster(testCtx context.Context, testOptions *TestOptions, options ClusterOptions) TestFunc {
 	return func(t *testing.T) {
 		if options.ScalingTimeout == 0 {
 			options.ScalingTimeout = time.Second * 150
@@ -86,16 +86,16 @@ func CreateCluster(testCtx context.Context, cli *client.Client, options ClusterO
 		ctx, cancel := context.WithTimeout(testCtx, options.ScalingTimeout)
 		defer cancel()
 
-		st := cli.Omni().State()
+		st := testOptions.omniClient.Omni().State()
 		require := require.New(t)
 
 		pickUnallocatedMachines(ctx, t, st, options.ControlPlanes+options.Workers, options.PickFilterFunc, func(machineIDs []resource.ID) {
 			if !options.SkipExtensionCheckOnCreate {
-				checkExtensionsWithRetries(ctx, t, cli, []string{HelloWorldServiceExtensionName}, machineIDs)
+				checkExtensionsWithRetries(ctx, t, testOptions, []string{HelloWorldServiceExtensionName}, machineIDs)
 			}
 
 			if options.BeforeClusterCreateFunc != nil {
-				options.BeforeClusterCreateFunc(ctx, t, cli, machineIDs)
+				options.BeforeClusterCreateFunc(ctx, t, testOptions.omniClient, machineIDs)
 			}
 
 			cluster := omni.NewCluster(options.Name)
diff --git a/internal/integration/common_test.go b/internal/integration/common_test.go
index e9cbb006..7168eb0e 100644
--- a/internal/integration/common_test.go
+++ b/internal/integration/common_test.go
@@ -9,11 +9,8 @@ package integration_test
 
 import (
 	"context"
-	"crypto/tls"
-	"errors"
 	"fmt"
 	"net"
-	"net/http"
 	"strings"
 	"testing"
 	"time"
@@ -24,12 +21,11 @@ import (
 	talosclient "github.com/siderolabs/talos/pkg/machinery/client"
 	talosclientconfig "github.com/siderolabs/talos/pkg/machinery/client/config"
 	"github.com/siderolabs/talos/pkg/machinery/resources/cluster"
+	"github.com/stretchr/testify/require"
 	"golang.org/x/sync/semaphore"
 
 	"github.com/siderolabs/omni/client/pkg/client"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
-	"github.com/siderolabs/omni/internal/backend/runtime/talos"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
 )
 
 func resourceDetails(res resource.Resource) string {
@@ -60,15 +56,12 @@ type node struct {
 	talosIP              string
 }
 
-func nodes(ctx context.Context, cli *client.Client, clusterName string, labels ...resource.LabelQueryOption) ([]node, error) {
-	talosCli, err := talosClientForCluster(ctx, cli, clusterName)
-	if err != nil {
-		return nil, err
-	}
+func nodes(ctx context.Context, t *testing.T, options *TestOptions, clusterName string, labels ...resource.LabelQueryOption) ([]node, error) {
+	talosClient := getTalosClientForCluster(ctx, t, options, clusterName)
 
-	st := cli.Omni().State()
+	st := options.omniClient.Omni().State()
 
-	nodeIPs, err := talosNodeIPs(ctx, talosCli.COSI)
+	nodeIPs, err := talosNodeIPs(ctx, talosClient.COSI)
 	if err != nil {
 		return nil, err
 	}
@@ -133,74 +126,31 @@ func nodes(ctx context.Context, cli *client.Client, clusterName string, labels .
 	return nodeList, nil
 }
 
-func talosClientForMachine(ctx context.Context, cli *client.Client, machineID resource.ID) (*talosclient.Client, error) {
-	machineStatus, err := safe.StateGet[*omni.MachineStatus](ctx, cli.Omni().State(), omni.NewMachineStatus(machineID).Metadata())
-	if err != nil {
-		return nil, err
-	}
-
-	if machineStatus.TypedSpec().Value.GetMaintenance() {
-		return talosClientMaintenance(ctx, machineStatus.TypedSpec().Value.GetManagementAddress())
-	}
-
-	cluster, ok := machineStatus.Metadata().Labels().Get(omni.LabelCluster)
-	if !ok {
-		return nil, fmt.Errorf("machine status %q is not in maintenance and has no cluster label", machineID)
-	}
-
-	data, err := cli.Management().Talosconfig(ctx)
-	if err != nil {
-		return nil, err
-	}
+func getTalosClient(ctx context.Context, t *testing.T, options *TestOptions) *talosclient.Client {
+	return getTalosClientForCluster(ctx, t, options, "")
+}
 
-	if len(data) == 0 {
-		return nil, errors.New("empty talosconfig")
-	}
+func getTalosClientForCluster(ctx context.Context, t *testing.T, options *TestOptions, clusterName string) *talosclient.Client {
+	data, err := options.omniClient.Management().Talosconfig(ctx)
+	require.NoError(t, err)
+	require.NotEmpty(t, data, "talosconfig for cluster %q is empty", clusterName)
 
 	config, err := talosclientconfig.FromBytes(data)
-	if err != nil {
-		return nil, err
-	}
+	require.NoError(t, err)
 
-	config.Contexts[config.Context].Nodes = []string{machineID}
-
-	return talosclient.New(
-		ctx,
+	opts := []talosclient.OptionFunc{
 		talosclient.WithConfig(config),
-		talosclient.WithCluster(cluster),
-	)
-}
-
-func talosClientForCluster(ctx context.Context, cli *client.Client, clusterName string) (*talosclient.Client, error) {
-	data, err := cli.Management().Talosconfig(ctx)
-	if err != nil {
-		return nil, err
+		talosclient.WithServiceAccount(options.serviceAccountKey),
 	}
 
-	if len(data) == 0 {
-		return nil, errors.New("empty talosconfig")
+	if clusterName != "" {
+		opts = append(opts, talosclient.WithCluster(clusterName))
 	}
 
-	config, err := talosclientconfig.FromBytes(data)
-	if err != nil {
-		return nil, err
-	}
+	client, err := talosclient.New(ctx, opts...)
+	require.NoError(t, err)
 
-	return talosclient.New(
-		ctx,
-		talosclient.WithConfig(config),
-		talosclient.WithCluster(clusterName),
-	)
-}
-
-func talosClientMaintenance(ctx context.Context, endpoint string) (*talosclient.Client, error) {
-	opts := talos.GetSocketOptions(endpoint)
-
-	opts = append(opts, talosclient.WithTLSConfig(&tls.Config{
-		InsecureSkipVerify: true,
-	}), talosclient.WithEndpoints(endpoint))
-
-	return talosclient.New(ctx, opts...)
+	return client
 }
 
 func talosNodeIPs(ctx context.Context, talosState state.State) ([]string, error) {
@@ -266,9 +216,6 @@ type WipeAMachineFunc func(ctx context.Context, uuid string) error
 // FreezeAMachineFunc is a function to freeze a machine by UUID.
 type FreezeAMachineFunc func(ctx context.Context, uuid string) error
 
-// HTTPRequestSignerFunc is function to sign the HTTP request.
-type HTTPRequestSignerFunc func(ctx context.Context, req *http.Request) error
-
 // Options for the test runner.
 //
 //nolint:govet
@@ -340,8 +287,8 @@ type MachineProviderConfig struct {
 // TestOptions constains all common data that might be required to run the tests.
 type TestOptions struct {
 	Options
-	omniClient   *client.Client
-	clientConfig *clientconfig.ClientConfig
+	omniClient        *client.Client
+	serviceAccountKey string
 
 	machineSemaphore *semaphore.Weighted
 }
diff --git a/internal/integration/config_patch_test.go b/internal/integration/config_patch_test.go
index a3075408..e3b95703 100644
--- a/internal/integration/config_patch_test.go
+++ b/internal/integration/config_patch_test.go
@@ -48,18 +48,17 @@ const (
 //
 // Config patch is generated to be large to test the edge case.
 // The patch is removed on finalize.
-func AssertLargeImmediateConfigApplied(testCtx context.Context, cli *client.Client, clusterName string) TestFunc {
+func AssertLargeImmediateConfigApplied(testCtx context.Context, options *TestOptions, clusterName string) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, 3*time.Minute)
 		defer cancel()
 
-		talosCli, err := talosClientForCluster(ctx, cli, clusterName)
-		require.NoError(t, err)
+		talosClient := getTalosClientForCluster(ctx, t, options, clusterName)
 
-		nodeIPs, err := talosNodeIPs(ctx, talosCli.COSI)
+		nodeIPs, err := talosNodeIPs(ctx, talosClient.COSI)
 		require.NoError(t, err)
 
-		st := cli.Omni().State()
+		st := options.omniClient.Omni().State()
 
 		epochSeconds := time.Now().Unix()
 		id := fmt.Sprintf("000-config-patch-test-dummy-iface-%d", epochSeconds)
@@ -100,7 +99,7 @@ func AssertLargeImmediateConfigApplied(testCtx context.Context, cli *client.Clie
 		linkStatus := network.NewLinkStatus(network.NamespaceName, "")
 
 		containsDummyIface := func(node string) (bool, error) {
-			links, linksErr := talosCli.COSI.List(talosclient.WithNode(ctx, node), linkStatus.Metadata())
+			links, linksErr := talosClient.COSI.List(talosclient.WithNode(ctx, node), linkStatus.Metadata())
 			if linksErr != nil {
 				return false, linksErr
 			}
@@ -145,18 +144,19 @@ func AssertLargeImmediateConfigApplied(testCtx context.Context, cli *client.Clie
 // AssertConfigPatchWithReboot tests that config patch that requires reboot gets applied to a single node, the node reboots and gets back.
 //
 // The patch is NOT removed.
-func AssertConfigPatchWithReboot(testCtx context.Context, cli *client.Client, clusterName string) TestFunc {
+func AssertConfigPatchWithReboot(testCtx context.Context, options *TestOptions, clusterName string) TestFunc {
 	return func(t *testing.T) {
+		omniClient := options.omniClient
+
 		// just a single machine with a reboot, so it should take no more than 3 minutes
 		ctx, cancel := context.WithTimeout(testCtx, 3*time.Minute)
 		defer cancel()
 
-		talosCli, err := talosClientForCluster(ctx, cli, clusterName)
-		require.NoError(t, err)
+		talosClient := getTalosClientForCluster(ctx, t, options, clusterName)
 
-		st := cli.Omni().State()
+		st := omniClient.Omni().State()
 
-		nodeList, err := nodes(ctx, cli, clusterName, resource.LabelExists(omni.LabelWorkerRole))
+		nodeList, err := nodes(ctx, t, options, clusterName, resource.LabelExists(omni.LabelWorkerRole))
 		require.NoError(t, err)
 		require.Greater(t, len(nodeList), 0)
 
@@ -198,7 +198,7 @@ func AssertConfigPatchWithReboot(testCtx context.Context, cli *client.Client, cl
 
 		// assert that the file is created on the node
 		err = retry.Constant(3*time.Minute, retry.WithUnits(1*time.Second)).RetryWithContext(ctx, func(ctx context.Context) error {
-			exists, existsErr := talosFileExists(ctx, talosCli, node.talosIP, file)
+			exists, existsErr := talosFileExists(ctx, talosClient, node.talosIP, file)
 			if existsErr != nil {
 				if strings.Contains(existsErr.Error(), "not reachable") || status.Code(existsErr) == codes.Unavailable {
 					return retry.ExpectedError(existsErr)
diff --git a/internal/integration/extensions_test.go b/internal/integration/extensions_test.go
index 573bea05..30b2d3a5 100644
--- a/internal/integration/extensions_test.go
+++ b/internal/integration/extensions_test.go
@@ -19,6 +19,7 @@ import (
 	"github.com/cosi-project/runtime/pkg/state"
 	"github.com/siderolabs/go-retry/retry"
 	"github.com/siderolabs/image-factory/pkg/constants"
+	talosclient "github.com/siderolabs/talos/pkg/machinery/client"
 	"github.com/siderolabs/talos/pkg/machinery/resources/runtime"
 	"github.com/stretchr/testify/require"
 
@@ -31,9 +32,9 @@ import (
 const HelloWorldServiceExtensionName = extensions.OfficialPrefix + "hello-world-service"
 
 // AssertExtensionsArePresent asserts that the given extensions are all present on all machines of the given cluster.
-func AssertExtensionsArePresent(ctx context.Context, cli *client.Client, cluster string, extensions []string) TestFunc {
+func AssertExtensionsArePresent(ctx context.Context, options *TestOptions, cluster string, extensions []string) TestFunc {
 	return func(t *testing.T) {
-		clusterMachineList, err := safe.StateListAll[*omni.ClusterMachine](ctx, cli.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, cluster)))
+		clusterMachineList, err := safe.StateListAll[*omni.ClusterMachine](ctx, options.omniClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, cluster)))
 		require.NoError(t, err)
 
 		machineIDs := make([]resource.ID, 0, clusterMachineList.Len())
@@ -42,16 +43,19 @@ func AssertExtensionsArePresent(ctx context.Context, cli *client.Client, cluster
 			machineIDs = append(machineIDs, clusterMachine.Metadata().ID())
 		})
 
-		checkExtensionsWithRetries(ctx, t, cli, extensions, machineIDs)
+		checkExtensionsWithRetries(ctx, t, options, extensions, machineIDs)
 	}
 }
 
-func checkExtensionsWithRetries(ctx context.Context, t *testing.T, cli *client.Client, extensions []string, machineIDs []resource.ID) {
+func checkExtensionsWithRetries(ctx context.Context, t *testing.T, options *TestOptions, extensions []string, machineIDs []resource.ID) {
 	for _, machineID := range machineIDs {
 		numErrs := 0
 
+		nodeCtx := talosclient.WithNode(ctx, machineID)
+		talosClient := getTalosClient(nodeCtx, t, options)
+
 		err := retry.Constant(3*time.Minute, retry.WithUnits(time.Second), retry.WithAttemptTimeout(3*time.Second)).RetryWithContext(ctx, func(ctx context.Context) error {
-			if err := checkExtensions(ctx, cli, machineID, extensions); err != nil {
+			if err := checkExtensions(nodeCtx, talosClient, extensions); err != nil {
 				numErrs++
 
 				if numErrs%10 == 0 {
@@ -74,8 +78,8 @@ func checkExtensionsWithRetries(ctx context.Context, t *testing.T, cli *client.C
 // The order of the extensions is also checked.
 //
 // It is assumed that neither of the input slices will contain duplicates.
-func checkExtensions(ctx context.Context, cli *client.Client, machineID string, extensions []string) error {
-	collectedExtensions, err := fetchExtensions(ctx, cli, machineID)
+func checkExtensions(ctx context.Context, talosClient *talosclient.Client, extensions []string) error {
+	collectedExtensions, err := fetchExtensions(ctx, talosClient)
 	if err != nil {
 		return err
 	}
@@ -84,7 +88,7 @@ func checkExtensions(ctx context.Context, cli *client.Client, machineID string,
 	for _, ext := range extensions {
 		i := slices.Index(collectedExtensions[pos:], ext)
 		if i < 0 {
-			return fmt.Errorf("extensions/order mismatch on %q: expected %q to be a subsequence of %q", machineID, extensions, collectedExtensions)
+			return fmt.Errorf("extensions/order mismatch: expected %q to be a subsequence of %q", extensions, collectedExtensions)
 		}
 		pos += i + 1
 	}
@@ -92,13 +96,8 @@ func checkExtensions(ctx context.Context, cli *client.Client, machineID string,
 	return nil
 }
 
-func fetchExtensions(ctx context.Context, cli *client.Client, machineID resource.ID) ([]string, error) {
-	talosCli, err := talosClientForMachine(ctx, cli, machineID)
-	if err != nil {
-		return nil, err
-	}
-
-	list, err := safe.StateListAll[*runtime.ExtensionStatus](ctx, talosCli.COSI)
+func fetchExtensions(ctx context.Context, talosClient *talosclient.Client) ([]string, error) {
+	list, err := safe.StateListAll[*runtime.ExtensionStatus](ctx, talosClient.COSI)
 	if err != nil {
 		return nil, err
 	}
diff --git a/internal/integration/image_test.go b/internal/integration/image_test.go
index 77f3695a..b3a99dab 100644
--- a/internal/integration/image_test.go
+++ b/internal/integration/image_test.go
@@ -16,21 +16,26 @@ import (
 	"time"
 
 	"github.com/cosi-project/runtime/pkg/safe"
+	"github.com/siderolabs/go-api-signature/pkg/message"
+	"github.com/siderolabs/go-api-signature/pkg/serviceaccount"
 	"github.com/stretchr/testify/require"
 
 	"github.com/siderolabs/omni/client/api/omni/management"
-	"github.com/siderolabs/omni/client/pkg/client"
+	"github.com/siderolabs/omni/client/pkg/access"
 	clientconsts "github.com/siderolabs/omni/client/pkg/constants"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 )
 
 // AssertSomeImagesAreDownloadable verifies generated image download.
-func AssertSomeImagesAreDownloadable(testCtx context.Context, client *client.Client, signer HTTPRequestSignerFunc, httpEndpoint string) TestFunc {
-	st := client.Omni().State()
+func AssertSomeImagesAreDownloadable(testCtx context.Context, options *TestOptions) TestFunc {
+	st := options.omniClient.Omni().State()
 
 	return func(t *testing.T) {
 		t.Parallel()
 
+		sa, err := serviceaccount.Decode(options.serviceAccountKey)
+		require.NoError(t, err)
+
 		media, err := safe.StateListAll[*omni.InstallationMedia](testCtx, st)
 		require.NoError(t, err)
 
@@ -60,10 +65,10 @@ func AssertSomeImagesAreDownloadable(testCtx context.Context, client *client.Cli
 				ctx, cancel := context.WithTimeout(testCtx, time.Minute*5)
 				defer cancel()
 
-				u, err := url.Parse(httpEndpoint)
+				u, err := url.Parse(options.HTTPEndpoint)
 				require.NoError(t, err)
 
-				schematic, err := client.Management().CreateSchematic(ctx, &management.CreateSchematicRequest{
+				schematic, err := options.omniClient.Management().CreateSchematic(ctx, &management.CreateSchematicRequest{
 					MediaId:      image.Metadata().ID(),
 					TalosVersion: clientconsts.DefaultTalosVersion,
 				})
@@ -75,7 +80,10 @@ func AssertSomeImagesAreDownloadable(testCtx context.Context, client *client.Cli
 				req, err := http.NewRequestWithContext(ctx, http.MethodGet, u.String(), nil)
 				require.NoError(t, err)
 
-				require.NoError(t, signer(ctx, req))
+				msg, err := message.NewHTTP(req)
+				require.NoError(t, err)
+
+				require.NoError(t, msg.Sign(sa.Name+access.ServiceAccountNameSuffix, sa.Key))
 
 				resp, err := http.DefaultClient.Do(req)
 				require.NoError(t, err)
diff --git a/internal/integration/integration_test.go b/internal/integration/integration_test.go
index b305d009..408ae8fb 100644
--- a/internal/integration/integration_test.go
+++ b/internal/integration/integration_test.go
@@ -16,14 +16,16 @@ import (
 	"net/url"
 	"os"
 	"os/exec"
+	"runtime"
 	"testing"
 	"time"
 
 	"github.com/cosi-project/runtime/pkg/resource/rtestutils"
 	"github.com/cosi-project/runtime/pkg/safe"
-	"github.com/cosi-project/runtime/pkg/state"
+	cosistate "github.com/cosi-project/runtime/pkg/state"
 	"github.com/mattn/go-shellwords"
 	"github.com/prometheus/client_golang/prometheus"
+	"github.com/siderolabs/go-api-signature/pkg/pgp"
 	"github.com/siderolabs/go-api-signature/pkg/serviceaccount"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
@@ -34,14 +36,19 @@ import (
 	"golang.org/x/sync/errgroup"
 	"golang.org/x/sync/semaphore"
 
+	"github.com/siderolabs/omni/client/pkg/access"
+	"github.com/siderolabs/omni/client/pkg/client"
 	clientconsts "github.com/siderolabs/omni/client/pkg/constants"
+	authres "github.com/siderolabs/omni/client/pkg/omni/resources/auth"
 	omnires "github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/siderolink"
 	_ "github.com/siderolabs/omni/cmd/acompat" // this package should always be imported first for init->set env to work
 	"github.com/siderolabs/omni/cmd/omni/pkg/app"
 	"github.com/siderolabs/omni/internal/backend/runtime/omni"
+	"github.com/siderolabs/omni/internal/pkg/auth"
 	"github.com/siderolabs/omni/internal/pkg/auth/actor"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
+	"github.com/siderolabs/omni/internal/pkg/auth/role"
+	omnisa "github.com/siderolabs/omni/internal/pkg/auth/serviceaccount"
 	"github.com/siderolabs/omni/internal/pkg/config"
 	"github.com/siderolabs/omni/internal/pkg/constants"
 )
@@ -194,27 +201,18 @@ func TestIntegration(t *testing.T) {
 		}
 	}
 
-	// Talos API calls try to use user auth if the service account var is not set
-	os.Setenv(serviceaccount.OmniServiceAccountKeyEnvVar, serviceAccount)
-
-	clientConfig := clientconfig.New(omniEndpoint, serviceAccount)
-
-	t.Cleanup(func() {
-		clientConfig.Close() //nolint:errcheck
-	})
-
-	rootClient, err := clientConfig.GetClient(t.Context())
+	omniClient, err := client.New(omniEndpoint, client.WithServiceAccount(serviceAccount))
 	require.NoError(t, err)
 
 	t.Cleanup(func() {
-		require.NoError(t, rootClient.Close())
+		require.NoError(t, omniClient.Close())
 	})
 
 	testOptions := &TestOptions{
-		omniClient:       rootClient,
-		Options:          options,
-		machineSemaphore: semaphore.NewWeighted(int64(options.ExpectedMachines)),
-		clientConfig:     clientConfig,
+		omniClient:        omniClient,
+		Options:           options,
+		machineSemaphore:  semaphore.NewWeighted(int64(options.ExpectedMachines)),
+		serviceAccountKey: serviceAccount,
 	}
 
 	preRunHooks(t, testOptions)
@@ -390,7 +388,7 @@ func postRunHooks(t *testing.T, options *TestOptions) {
 	}
 }
 
-func cleanupLinksFunc(ctx context.Context, st state.State) error {
+func cleanupLinksFunc(ctx context.Context, st cosistate.State) error {
 	links, err := safe.ReaderListAll[*siderolink.Link](ctx, st)
 	if err != nil {
 		return err
@@ -403,7 +401,7 @@ func cleanupLinksFunc(ctx context.Context, st state.State) error {
 
 	return links.ForEachErr(func(r *siderolink.Link) error {
 		err := st.TeardownAndDestroy(ctx, r.Metadata())
-		if err != nil && !state.IsNotFoundError(err) {
+		if err != nil && !cosistate.IsNotFoundError(err) {
 			return err
 		}
 
@@ -503,7 +501,7 @@ func runOmni(t *testing.T) (string, error) {
 
 	rtestutils.AssertResources(ctx, t, state.Default(), []string{talosVersion}, func(*omnires.TalosVersion, *assert.Assertions) {})
 
-	sa, err := clientconfig.CreateServiceAccount(omniCtx, "root", state.Default())
+	sa, err := createBootstrapServiceAccount(omniCtx, "root", state.Default())
 	if err != nil {
 		return "", err
 	}
@@ -513,3 +511,38 @@ func runOmni(t *testing.T) (string, error) {
 
 	return sa, nil
 }
+
+func createBootstrapServiceAccount(ctx context.Context, name string, st cosistate.State) (string, error) {
+	comment := fmt.Sprintf("%s/%s", runtime.GOOS, runtime.GOARCH)
+
+	serviceAccountEmail := name + access.ServiceAccountNameSuffix
+
+	key, err := pgp.GenerateKey(name, comment, serviceAccountEmail, auth.ServiceAccountMaxAllowedLifetime)
+	if err != nil {
+		return "", err
+	}
+
+	armoredPublicKey, err := key.ArmorPublic()
+	if err != nil {
+		return "", err
+	}
+
+	identity, err := safe.ReaderGetByID[*authres.Identity](ctx, st, serviceAccountEmail)
+	if err != nil && !cosistate.IsNotFoundError(err) {
+		return "", err
+	}
+
+	if identity != nil {
+		err = omnisa.Destroy(ctx, st, name)
+		if err != nil {
+			return "", err
+		}
+	}
+
+	_, err = omnisa.Create(ctx, st, name, string(role.Admin), false, []byte(armoredPublicKey))
+	if err != nil {
+		return "", err
+	}
+
+	return serviceaccount.Encode(name, key)
+}
diff --git a/internal/integration/kernelargs_test.go b/internal/integration/kernelargs_test.go
index daa96e5b..1003b9ef 100644
--- a/internal/integration/kernelargs_test.go
+++ b/internal/integration/kernelargs_test.go
@@ -40,7 +40,7 @@ func testKernelArgsUpdate(t *testing.T, options *TestOptions) {
 	// Create a cluster to make sure that we have Talos installed on a machine
 	t.Run(
 		"ClusterShouldBeCreated",
-		CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+		CreateCluster(t.Context(), options, ClusterOptions{
 			Name:          clusterName,
 			ControlPlanes: 1,
 			Workers:       1,
diff --git a/internal/integration/kubernetes/kubernetes.go b/internal/integration/kubernetes/kubernetes.go
index 6b309054..07625f35 100644
--- a/internal/integration/kubernetes/kubernetes.go
+++ b/internal/integration/kubernetes/kubernetes.go
@@ -14,7 +14,6 @@ import (
 
 	"github.com/go-logr/logr"
 	"github.com/go-logr/zapr"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap"
@@ -63,7 +62,7 @@ func ScaleDeployment(ctx context.Context, t *testing.T, kubeClient kubernetes.In
 	require.NoError(t, err, "failed to get deployment %q/%q", namespace, name)
 
 	// scale down the deployment to 0 replicas
-	deployment.Spec.Replicas = pointer.To(int32(numReplicas))
+	deployment.Spec.Replicas = new(int32(numReplicas))
 
 	if _, err := kubeClient.AppsV1().Deployments(deployment.Namespace).Update(ctx, deployment, metav1.UpdateOptions{}); !apierrors.IsNotFound(err) {
 		require.NoError(t, err)
diff --git a/internal/integration/kubernetes_test.go b/internal/integration/kubernetes_test.go
index 22ccb712..2e4a1439 100644
--- a/internal/integration/kubernetes_test.go
+++ b/internal/integration/kubernetes_test.go
@@ -19,7 +19,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
 	"github.com/siderolabs/gen/xslices"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/go-retry/retry"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
@@ -40,13 +39,13 @@ import (
 // AssertKubernetesAPIAccessViaOmni verifies that cluster kubeconfig works.
 //
 //nolint:gocognit
-func AssertKubernetesAPIAccessViaOmni(testCtx context.Context, rootClient *client.Client, clusterName string, assertAllNodesReady bool, timeout time.Duration) TestFunc {
+func AssertKubernetesAPIAccessViaOmni(testCtx context.Context, omniClient *client.Client, clusterName string, assertAllNodesReady bool, timeout time.Duration) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, timeout)
 		defer cancel()
 
 		ctx = kubernetes.WrapContext(ctx, t)
-		k8sClient := kubernetes.GetClient(ctx, t, rootClient.Management(), clusterName)
+		k8sClient := kubernetes.GetClient(ctx, t, omniClient.Management(), clusterName)
 
 		var (
 			k8sNodes *corev1.NodeList
@@ -69,7 +68,7 @@ func AssertKubernetesAPIAccessViaOmni(testCtx context.Context, rootClient *clien
 
 			var identityList safe.List[*omni.ClusterMachineIdentity]
 
-			identityList, err = safe.StateListAll[*omni.ClusterMachineIdentity](ctx, rootClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)))
+			identityList, err = safe.StateListAll[*omni.ClusterMachineIdentity](ctx, omniClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)))
 			require.NoError(collect, err)
 
 			nodeNamesInIdentities := make([]string, 0, identityList.Len())
@@ -383,7 +382,7 @@ func AssertKubernetesDeploymentIsCreated(testCtx context.Context, managementClie
 				Name: name,
 			},
 			Spec: appsv1.DeploymentSpec{
-				Replicas: pointer.To(int32(1)),
+				Replicas: new(int32(1)),
 				Selector: &metav1.LabelSelector{
 					MatchLabels: map[string]string{
 						"app": name,
@@ -396,7 +395,7 @@ func AssertKubernetesDeploymentIsCreated(testCtx context.Context, managementClie
 						},
 					},
 					Spec: corev1.PodSpec{
-						TerminationGracePeriodSeconds: pointer.To(int64(0)),
+						TerminationGracePeriodSeconds: new(int64(0)),
 						Containers: []corev1.Container{{
 							Name:  name,
 							Image: "busybox:1",
@@ -470,11 +469,11 @@ func AssertKubernetesSecretHasValue(testCtx context.Context, managementClient *m
 // 2. All the extra (stale) Kubernetes nodes are in NotReady state
 //
 // This assertion is useful to assert the expected nodes state when a cluster is created from an etcd backup.
-func AssertKubernetesNodesState(testCtx context.Context, rootClient *client.Client, newClusterName string) func(t *testing.T) {
+func AssertKubernetesNodesState(testCtx context.Context, omniClient *client.Client, newClusterName string) func(t *testing.T) {
 	return func(t *testing.T) {
 		ctx := kubernetes.WrapContext(testCtx, t)
 
-		identityList, err := safe.StateListAll[*omni.ClusterMachineIdentity](ctx, rootClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, newClusterName)))
+		identityList, err := safe.StateListAll[*omni.ClusterMachineIdentity](ctx, omniClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, newClusterName)))
 		require.NoError(t, err)
 
 		expectedReadyNodeNames, err := safe.Map(identityList, func(cm *omni.ClusterMachineIdentity) (string, error) {
@@ -494,7 +493,7 @@ func AssertKubernetesNodesState(testCtx context.Context, rootClient *client.Clie
 			return false
 		}
 
-		kubeClient := kubernetes.GetClient(ctx, t, rootClient.Management(), newClusterName)
+		kubeClient := kubernetes.GetClient(ctx, t, omniClient.Management(), newClusterName)
 
 		require.EventuallyWithT(t, func(collect *assert.CollectT) {
 			kubernetesNodes, listErr := kubeClient.CoreV1().Nodes().List(ctx, metav1.ListOptions{})
diff --git a/internal/integration/omni_upgrade_test.go b/internal/integration/omni_upgrade_test.go
index dbe228be..51ec197f 100644
--- a/internal/integration/omni_upgrade_test.go
+++ b/internal/integration/omni_upgrade_test.go
@@ -18,12 +18,10 @@ import (
 	"github.com/cosi-project/runtime/pkg/safe"
 	"github.com/cosi-project/runtime/pkg/state"
 	talosclient "github.com/siderolabs/talos/pkg/machinery/client"
-	clientconfig "github.com/siderolabs/talos/pkg/machinery/client/config"
 	"github.com/siderolabs/talos/pkg/machinery/resources/runtime"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 
-	"github.com/siderolabs/omni/client/pkg/client"
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 )
 
@@ -45,12 +43,13 @@ func (vs clusterSnapshot) getShaSum(res resource.Resource) (string, bool) {
 }
 
 // SaveClusterSnapshot saves resources versions as the annotations for the given cluster.
-func SaveClusterSnapshot(testCtx context.Context, client *client.Client, clusterName string) TestFunc {
+func SaveClusterSnapshot(testCtx context.Context, options *TestOptions, clusterName string) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, time.Minute)
 		defer cancel()
 
-		st := client.Omni().State()
+		omniClient := options.omniClient
+		st := omniClient.Omni().State()
 
 		snapshot := clusterSnapshot{
 			BootTimes: map[string]time.Time{},
@@ -66,23 +65,13 @@ func SaveClusterSnapshot(testCtx context.Context, client *client.Client, cluster
 		})
 
 		require := require.New(t)
-		assert := assert.New(t)
-
-		data, err := client.Management().Talosconfig(ctx)
-		require.NoError(err)
-		assert.NotEmpty(data)
-
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(err)
-
-		c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(clusterName))
-		require.NoError(err)
+		c := getTalosClientForCluster(ctx, t, options, clusterName)
 
 		t.Cleanup(func() {
 			require.NoError(c.Close())
 		})
 
-		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, client.Omni().State(),
+		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, omniClient.Omni().State(),
 			state.WithLabelQuery(
 				resource.LabelEqual(omni.LabelCluster, clusterName),
 				resource.LabelExists(omni.LabelControlPlaneRole),
@@ -92,8 +81,7 @@ func SaveClusterSnapshot(testCtx context.Context, client *client.Client, cluster
 		for _, machineID := range machineIDs {
 			var ms *runtime.MachineStatus
 
-			ms, err = safe.ReaderGetByID[*runtime.MachineStatus](talosclient.WithNode(ctx, machineID), c.COSI, runtime.MachineStatusID)
-
+			ms, err := safe.ReaderGetByID[*runtime.MachineStatus](talosclient.WithNode(ctx, machineID), c.COSI, runtime.MachineStatusID)
 			require.NoError(err)
 
 			snapshot.BootTimes[machineID] = ms.Metadata().Created()
@@ -104,7 +92,7 @@ func SaveClusterSnapshot(testCtx context.Context, client *client.Client, cluster
 		require.NoError(err)
 
 		_, err = safe.StateUpdateWithConflicts(ctx,
-			client.Omni().State(),
+			omniClient.Omni().State(),
 			omni.NewCluster(clusterName).Metadata(),
 			func(res *omni.Cluster) error {
 				res.Metadata().Annotations().Set(annotationSnapshot, string(snapshotData))
@@ -119,18 +107,19 @@ func SaveClusterSnapshot(testCtx context.Context, client *client.Client, cluster
 
 // AssertClusterSnapshot reads the snapshot from the cluster resource and asserts that versions did not change
 // and the last events still can be found in the node events.
-func AssertClusterSnapshot(testCtx context.Context, client *client.Client, clusterName string) TestFunc {
+func AssertClusterSnapshot(testCtx context.Context, options *TestOptions, clusterName string) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, time.Minute)
 		defer cancel()
 
-		st := client.Omni().State()
+		omniClient := options.omniClient
+		omniState := omniClient.Omni().State()
 
 		require := require.New(t)
 
 		var snapshot clusterSnapshot
 
-		cluster, err := safe.ReaderGetByID[*omni.Cluster](ctx, st, clusterName)
+		cluster, err := safe.ReaderGetByID[*omni.Cluster](ctx, omniState, clusterName)
 		require.NoError(err)
 
 		snapshotData, ok := cluster.Metadata().Annotations().Get(annotationSnapshot)
@@ -139,26 +128,18 @@ func AssertClusterSnapshot(testCtx context.Context, client *client.Client, clust
 
 		require.NoError(json.Unmarshal([]byte(snapshotData), &snapshot))
 
-		ids := rtestutils.ResourceIDs[*omni.ClusterMachineConfigStatus](ctx, t, st,
+		ids := rtestutils.ResourceIDs[*omni.ClusterMachineConfigStatus](ctx, t, omniState,
 			state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)),
 		)
 
-		rtestutils.AssertResources(ctx, t, st, ids, func(res *omni.ClusterMachineConfigStatus, assert *assert.Assertions) {
+		rtestutils.AssertResources(ctx, t, omniState, ids, func(res *omni.ClusterMachineConfigStatus, assert *assert.Assertions) {
 			shaSum, ok := snapshot.getShaSum(res)
 
 			assert.True(ok)
 			require.Equal(shaSum, res.TypedSpec().Value.ClusterMachineConfigSha256, "ClusterMachineConfigStatus sha sums do not match")
 		})
 
-		data, err := client.Management().Talosconfig(ctx)
-		require.NoError(err)
-		assert.NotEmpty(t, data)
-
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(err)
-
-		c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(clusterName))
-		require.NoError(err)
+		c := getTalosClientForCluster(ctx, t, options, clusterName)
 
 		t.Cleanup(func() {
 			require.NoError(c.Close())
diff --git a/internal/integration/rotate_ca_test.go b/internal/integration/rotate_ca_test.go
index 4abceb37..2df6f861 100644
--- a/internal/integration/rotate_ca_test.go
+++ b/internal/integration/rotate_ca_test.go
@@ -27,14 +27,13 @@ func testRotateCA(t *testing.T, options *TestOptions) {
 	defer cancel()
 
 	options.claimMachines(t, 5)
-	omniClient := options.omniClient
 
 	clusterName := "integration-rotate-ca"
 
 	// Create a cluster to make sure that we have Talos installed on a machine
 	t.Run(
 		"ClusterShouldBeCreated",
-		CreateCluster(t.Context(), omniClient, ClusterOptions{
+		CreateCluster(t.Context(), options, ClusterOptions{
 			Name:          clusterName,
 			ControlPlanes: 3,
 			Workers:       2,
@@ -93,7 +92,7 @@ func testRotateCA(t *testing.T, options *TestOptions) {
 		require.NoError(t, err)
 	})
 
-	runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, clusterName, options.MachineOptions.TalosVersion, options.MachineOptions.KubernetesVersion))
+	runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, clusterName, options.MachineOptions.TalosVersion, options.MachineOptions.KubernetesVersion))
 
 	t.Run("ClusterShouldBeDestroyed", AssertDestroyCluster(t.Context(), options.omniClient.Omni().State(), clusterName, false, false))
 }
diff --git a/internal/integration/suites_test.go b/internal/integration/suites_test.go
index 6a234367..dafc1f17 100644
--- a/internal/integration/suites_test.go
+++ b/internal/integration/suites_test.go
@@ -8,8 +8,6 @@
 package integration_test
 
 import (
-	"context"
-	"net/http"
 	"testing"
 	"time"
 
@@ -19,7 +17,6 @@ import (
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 	"github.com/siderolabs/omni/internal/backend/extensions"
 	"github.com/siderolabs/omni/internal/integration/workloadproxy"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
 )
 
 type assertClusterReadyOptions struct {
@@ -53,7 +50,7 @@ func assertClusterAndAPIReady(t *testing.T, clusterName string, options *TestOpt
 
 	runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(
 		t.Context(),
-		options.omniClient,
+		options,
 		clusterName,
 		optionsStruct.talosVersion,
 		optionsStruct.kubernetesVersion,
@@ -96,7 +93,7 @@ Wait for all expected machines to join and be in maintenance mode.`)
 
 		t.Run(
 			"MachinesShouldBeReachableInMaintenanceMode",
-			AssertTalosMaintenanceAPIAccessViaOmni(ctx, options.omniClient),
+			AssertTalosMaintenanceAPIAccessViaOmni(ctx, options),
 		)
 
 		t.Run(
@@ -128,9 +125,7 @@ Generate various Talos images with Omni and try to download them.`)
 
 		t.Run(
 			"TalosImagesShouldBeDownloadable",
-			AssertSomeImagesAreDownloadable(t.Context(), options.omniClient, func(ctx context.Context, req *http.Request) error {
-				return clientconfig.SignHTTPRequest(ctx, options.omniClient, req)
-			}, options.HTTPEndpoint),
+			AssertSomeImagesAreDownloadable(t.Context(), options),
 		)
 	}
 }
@@ -162,7 +157,7 @@ Test the auditing of the Kubernetes nodes, i.e. when a node is gone from the Omn
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       1,
@@ -178,7 +173,7 @@ Test the auditing of the Kubernetes nodes, i.e. when a node is gone from the Omn
 			t,
 			AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(
 				t.Context(),
-				options.omniClient,
+				options,
 				clusterName,
 				options.MachineOptions.TalosVersion,
 				options.MachineOptions.KubernetesVersion,
@@ -223,7 +218,7 @@ In the tests, we wipe and reboot the VMs to bring them back as available for the
 		assertClusterReady := func() {
 			runTests(t, AssertBlockClusterShouldBeReady(
 				t.Context(),
-				options.omniClient,
+				options,
 				clusterName,
 				options.MachineOptions.TalosVersion,
 			))
@@ -236,7 +231,7 @@ In the tests, we wipe and reboot the VMs to bring them back as available for the
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       1,
@@ -289,7 +284,7 @@ Regression test: create a cluster and destroy it without waiting for the cluster
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       2,
@@ -326,7 +321,7 @@ Don't do any changes to the cluster.`)
 
 		options.claimMachines(t, clusterOptions.ControlPlanes+clusterOptions.Workers)
 
-		runTests(t, AssertClusterCreateAndReady(t.Context(), options.omniClient, clusterOptions))
+		runTests(t, AssertClusterCreateAndReady(t.Context(), options, clusterOptions))
 	}
 }
 
@@ -351,7 +346,7 @@ Don't do any changes to the cluster.`)
 
 		options.claimMachines(t, clusterOptions.ControlPlanes+clusterOptions.Workers)
 
-		runTests(t, AssertClusterCreateAndReady(t.Context(), options.omniClient, clusterOptions))
+		runTests(t, AssertClusterCreateAndReady(t.Context(), options, clusterOptions))
 	}
 }
 
@@ -373,7 +368,7 @@ Don't do any changes to the cluster.`)
 
 		options.claimMachines(t, clusterOptions.ControlPlanes+clusterOptions.Workers)
 
-		runTests(t, AssertClusterCreateAndReady(t.Context(), options.omniClient, clusterOptions))
+		runTests(t, AssertClusterCreateAndReady(t.Context(), options, clusterOptions))
 	}
 }
 
@@ -398,7 +393,7 @@ In between the scaling operations, assert that the cluster is ready and accessib
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       0,
@@ -685,7 +680,7 @@ Tests rolling update & scale down strategies for concurrency control for worker
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       3,
@@ -733,7 +728,7 @@ In between the scaling operations, assert that the cluster is ready and accessib
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       0,
@@ -778,7 +773,7 @@ Tests applying various config patching, including "broken" config patches which
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       1,
@@ -794,7 +789,7 @@ Tests applying various config patching, including "broken" config patches which
 
 		t.Run(
 			"LargeImmediateConfigPatchShouldBeAppliedAndRemoved",
-			AssertLargeImmediateConfigApplied(t.Context(), options.omniClient, clusterName),
+			AssertLargeImmediateConfigApplied(t.Context(), options, clusterName),
 		)
 
 		assertClusterAndAPIReady(t, clusterName, options)
@@ -813,7 +808,7 @@ Tests applying various config patching, including "broken" config patches which
 
 		t.Run(
 			"ConfigPatchWithRebootShouldBeApplied",
-			AssertConfigPatchWithReboot(t.Context(), options.omniClient, clusterName),
+			AssertConfigPatchWithReboot(t.Context(), options, clusterName),
 		)
 
 		assertClusterAndAPIReady(t, clusterName, options)
@@ -850,7 +845,7 @@ Tests upgrading Talos version, including reverting a failed upgrade.`)
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       1,
@@ -867,7 +862,7 @@ Tests upgrading Talos version, including reverting a failed upgrade.`)
 		if !options.SkipExtensionsCheckOnCreate {
 			t.Run(
 				"HelloWorldServiceExtensionShouldBePresent",
-				AssertExtensionsArePresent(t.Context(), options.omniClient, clusterName, []string{HelloWorldServiceExtensionName}),
+				AssertExtensionsArePresent(t.Context(), options, clusterName, []string{HelloWorldServiceExtensionName}),
 			)
 		}
 
@@ -880,7 +875,7 @@ Tests upgrading Talos version, including reverting a failed upgrade.`)
 
 		t.Run(
 			"UpdatedExtensionsShouldBePresent",
-			AssertExtensionsArePresent(t.Context(), options.omniClient, clusterName, extensions),
+			AssertExtensionsArePresent(t.Context(), options, clusterName, extensions),
 		)
 
 		t.Run(
@@ -901,7 +896,7 @@ Tests upgrading Talos version, including reverting a failed upgrade.`)
 		if !options.SkipExtensionsCheckOnCreate {
 			t.Run(
 				"HelloWorldServiceExtensionShouldBePresent",
-				AssertExtensionsArePresent(t.Context(), options.omniClient, clusterName, []string{HelloWorldServiceExtensionName}),
+				AssertExtensionsArePresent(t.Context(), options, clusterName, []string{HelloWorldServiceExtensionName}),
 			)
 		}
 
@@ -944,7 +939,7 @@ Tests upgrading Kubernetes version, including reverting a failed upgrade.`)
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       2,
@@ -1004,7 +999,7 @@ Finally, a completely new cluster is created using the same backup to test the "
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       1,
@@ -1050,7 +1045,7 @@ Finally, a completely new cluster is created using the same backup to test the "
 
 		runTests(
 			t,
-			AssertBlockCreateClusterFromEtcdBackup(t.Context(), options.omniClient, options.Options,
+			AssertBlockCreateClusterFromEtcdBackup(t.Context(), options, options.Options,
 				clusterName,
 				secondClusterName,
 				"default",
@@ -1070,7 +1065,7 @@ Finally, a completely new cluster is created using the same backup to test the "
 
 		runTests(
 			t,
-			AssertBlockRestoreEtcdFromLatestBackup(t.Context(), options.omniClient, options.Options,
+			AssertBlockRestoreEtcdFromLatestBackup(t.Context(), options, options.Options,
 				3,
 				clusterName,
 				"default",
@@ -1100,7 +1095,7 @@ Create a cluster out of the same machine on version2, Omni should upgrade the ma
 		t.Run(
 			"MachineShouldBeUpgradedInMaintenanceMode",
 			AssertMachineShouldBeUpgradedInMaintenanceMode(
-				t.Context(), options.omniClient,
+				t.Context(), options,
 				"integration-maintenance-upgrade",
 				options.AnotherKubernetesVersion,
 				options.MachineOptions.TalosVersion,
@@ -1159,9 +1154,14 @@ Test authorization on accessing Omni API, some tests run without a cluster, some
 			AssertServiceAccountAPIFlow(t.Context(), options.omniClient),
 		)
 
+		clientFactory := newTestClientFactory(omniEndpoint, options.omniClient)
+		t.Cleanup(func() {
+			clientFactory.close() //nolint:errcheck
+		})
+
 		t.Run(
 			"ResourceAuthzShouldWork",
-			AssertResourceAuthz(t.Context(), options.omniClient, options.clientConfig),
+			AssertResourceAuthz(t.Context(), options.omniClient, clientFactory),
 		)
 
 		t.Run(
@@ -1173,7 +1173,7 @@ Test authorization on accessing Omni API, some tests run without a cluster, some
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       0,
@@ -1193,12 +1193,12 @@ Test authorization on accessing Omni API, some tests run without a cluster, some
 
 		t.Run(
 			"APIAuthorizationShouldBeTested",
-			AssertAPIAuthz(t.Context(), options.omniClient, options.clientConfig, clusterName),
+			AssertAPIAuthz(t.Context(), options.omniClient, clientFactory, clusterName),
 		)
 
 		t.Run(
 			"FrontendAPIShouldBeTested",
-			AssertFrontendResourceAPI(t.Context(), options.omniClient, options.clientConfig, options.HTTPEndpoint, clusterName),
+			AssertFrontendResourceAPI(t.Context(), options.omniClient, options.serviceAccountKey, options.HTTPEndpoint, clusterName),
 		)
 
 		t.Run(
@@ -1237,7 +1237,7 @@ Test workload service proxying feature`)
 		cluster1 := "integration-workload-proxy-1"
 		cluster2 := "integration-workload-proxy-2"
 
-		t.Run("ClusterShouldBeCreated-"+cluster1, CreateCluster(t.Context(), omniClient, ClusterOptions{
+		t.Run("ClusterShouldBeCreated-"+cluster1, CreateCluster(t.Context(), options, ClusterOptions{
 			Name:          cluster1,
 			ControlPlanes: 1,
 			Workers:       1,
@@ -1253,7 +1253,7 @@ Test workload service proxying feature`)
 
 			AllowSchedulingOnControlPlanes: true,
 		}))
-		t.Run("ClusterShouldBeCreated-"+cluster2, CreateCluster(t.Context(), omniClient, ClusterOptions{
+		t.Run("ClusterShouldBeCreated-"+cluster2, CreateCluster(t.Context(), options, ClusterOptions{
 			Name:          cluster2,
 			ControlPlanes: 1,
 			Workers:       2,
@@ -1270,15 +1270,15 @@ Test workload service proxying feature`)
 			AllowSchedulingOnControlPlanes: true,
 		}))
 
-		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, cluster1, options.MachineOptions.TalosVersion,
+		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, cluster1, options.MachineOptions.TalosVersion,
 			options.MachineOptions.KubernetesVersion))
-		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, cluster2, options.MachineOptions.TalosVersion,
+		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, cluster2, options.MachineOptions.TalosVersion,
 			options.MachineOptions.KubernetesVersion))
 
 		parentCtx := t.Context()
 
 		t.Run("WorkloadProxyShouldBeTested", func(t *testing.T) {
-			workloadproxy.Test(parentCtx, t, omniClient, cluster1, cluster2)
+			workloadproxy.Test(parentCtx, t, omniClient, options.serviceAccountKey, cluster1, cluster2)
 		})
 
 		t.Run("ClusterShouldBeDestroyed-"+cluster1, AssertDestroyCluster(t.Context(), options.omniClient.Omni().State(), cluster1, false, false))
@@ -1309,7 +1309,7 @@ Note: this test expects all machines to be provisioned by the bare-metal infra p
 
 		t.Run(
 			"ClusterShouldBeCreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 1,
 				Workers:       0,
@@ -1367,7 +1367,7 @@ Note: this test expects all machines to be provisioned by the bare-metal infra p
 
 		t.Run(
 			"ClusterShouldBeRecreated",
-			CreateCluster(t.Context(), options.omniClient, ClusterOptions{
+			CreateCluster(t.Context(), options, ClusterOptions{
 				Name:          clusterName,
 				ControlPlanes: 3,
 				Workers:       1,
@@ -1409,7 +1409,7 @@ Test Omni upgrades, the first half that runs on the previous Omni version
 			KubernetesVersion: options.AnotherKubernetesVersion,
 		}
 
-		t.Run("ClusterShouldBeCreated", CreateCluster(t.Context(), omniClient, ClusterOptions{
+		t.Run("ClusterShouldBeCreated", CreateCluster(t.Context(), options, ClusterOptions{
 			Name:          clusterName,
 			ControlPlanes: 3,
 			Workers:       1,
@@ -1451,16 +1451,16 @@ Test Omni upgrades, the first half that runs on the previous Omni version
 			},
 		}))
 
-		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, clusterName, machineOptions.TalosVersion,
+		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, clusterName, machineOptions.TalosVersion,
 			machineOptions.KubernetesVersion))
 
 		parentCtx := t.Context()
 
 		t.Run("WorkloadProxyShouldBeTested", func(t *testing.T) {
-			workloadproxy.Test(parentCtx, t, omniClient, clusterName)
+			workloadproxy.Test(parentCtx, t, omniClient, options.serviceAccountKey, clusterName)
 		})
 
-		t.Run("SaveClusterSnapshot", SaveClusterSnapshot(t.Context(), omniClient, clusterName))
+		t.Run("SaveClusterSnapshot", SaveClusterSnapshot(t.Context(), options, clusterName))
 	}
 }
 
@@ -1486,15 +1486,15 @@ Test Omni upgrades, the second half that runs on the current Omni version
 			KubernetesVersion: options.AnotherKubernetesVersion,
 		}
 
-		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, clusterName, machineOptions.TalosVersion,
+		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, clusterName, machineOptions.TalosVersion,
 			machineOptions.KubernetesVersion))
 
 		parentCtx := t.Context()
 
-		t.Run("AssertMachinesNotRebootedConfigUnchanged", AssertClusterSnapshot(t.Context(), omniClient, clusterName))
+		t.Run("AssertMachinesNotRebootedConfigUnchanged", AssertClusterSnapshot(t.Context(), options, clusterName))
 
 		t.Run("WorkloadProxyShouldBeTested", func(t *testing.T) {
-			workloadproxy.Test(parentCtx, t, omniClient, clusterName)
+			workloadproxy.Test(parentCtx, t, omniClient, options.serviceAccountKey, clusterName)
 		})
 
 		t.Run(
@@ -1508,7 +1508,7 @@ Test Omni upgrades, the second half that runs on the current Omni version
 			}),
 		)
 
-		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), omniClient, clusterName, machineOptions.TalosVersion,
+		runTests(t, AssertBlockClusterAndTalosAPIAndKubernetesShouldBeReady(t.Context(), options, clusterName, machineOptions.TalosVersion,
 			machineOptions.KubernetesVersion))
 
 		t.Run(
diff --git a/internal/integration/talos_test.go b/internal/integration/talos_test.go
index db03f83a..ad0522d6 100644
--- a/internal/integration/talos_test.go
+++ b/internal/integration/talos_test.go
@@ -28,7 +28,6 @@ import (
 	"github.com/siderolabs/go-retry/retry"
 	"github.com/siderolabs/talos/pkg/machinery/api/machine"
 	talosclient "github.com/siderolabs/talos/pkg/machinery/client"
-	clientconfig "github.com/siderolabs/talos/pkg/machinery/client/config"
 	talosconstants "github.com/siderolabs/talos/pkg/machinery/constants"
 	"github.com/siderolabs/talos/pkg/machinery/resources/cluster"
 	"github.com/siderolabs/talos/pkg/machinery/resources/etcd"
@@ -107,20 +106,13 @@ func clearConnectionRefused(ctx context.Context, t *testing.T, c *talosclient.Cl
 }
 
 // AssertTalosMaintenanceAPIAccessViaOmni verifies that cluster-wide `talosconfig` gives access to Talos nodes running in maintenance mode.
-func AssertTalosMaintenanceAPIAccessViaOmni(testCtx context.Context, omniClient *client.Client) TestFunc {
+func AssertTalosMaintenanceAPIAccessViaOmni(testCtx context.Context, options *TestOptions) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, backoff.DefaultConfig.MaxDelay+10*time.Second)
 		t.Cleanup(cancel)
 
-		data, err := omniClient.Management().Talosconfig(ctx)
-		require.NoError(t, err)
-		assert.NotEmpty(t, data)
-
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(t, err)
-
-		maintenanceClient, err := talosclient.New(ctx, talosclient.WithConfig(config))
-		require.NoError(t, err)
+		omniClient := options.omniClient
+		maintenanceClient := getTalosClient(ctx, t, options)
 
 		t.Cleanup(func() {
 			require.NoError(t, maintenanceClient.Close())
@@ -138,8 +130,10 @@ func AssertTalosMaintenanceAPIAccessViaOmni(testCtx context.Context, omniClient
 }
 
 // AssertTalosAPIAccessViaOmni verifies that both instance-wide and cluster-wide `talosconfig`s work with Omni Talos API proxy.
-func AssertTalosAPIAccessViaOmni(testCtx context.Context, omniClient *client.Client, cluster string) TestFunc {
+func AssertTalosAPIAccessViaOmni(testCtx context.Context, options *TestOptions, cluster string) TestFunc {
 	return func(t *testing.T) {
+		omniClient := options.omniClient
+
 		ms, err := safe.ReaderListAll[*omni.MachineStatus](
 			testCtx,
 			omniClient.Omni().State(),
@@ -226,11 +220,7 @@ func AssertTalosAPIAccessViaOmni(testCtx context.Context, omniClient *client.Cli
 			require.NoError(t, err)
 			assert.NotEmpty(t, data)
 
-			config, err := clientconfig.FromBytes(data)
-			require.NoError(t, err)
-
-			c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(cluster))
-			require.NoError(t, err)
+			c := getTalosClientForCluster(ctx, t, options, cluster)
 
 			t.Cleanup(func() {
 				require.NoError(t, c.Close())
@@ -247,75 +237,56 @@ func AssertTalosAPIAccessViaOmni(testCtx context.Context, omniClient *client.Cli
 			require.NoError(t, err)
 			assert.NotEmpty(t, data)
 
-			config, err := clientconfig.FromBytes(data)
-			require.NoError(t, err)
-
-			c, err := talosclient.New(ctx, talosclient.WithConfig(config))
-			require.NoError(t, err)
+			talosClient := getTalosClient(ctx, t, options)
 
 			t.Cleanup(func() {
-				require.NoError(t, c.Close())
+				require.NoError(t, talosClient.Close())
 			})
 
-			assertTalosAPI(ctx, t, c)
+			assertTalosAPI(ctx, t, talosClient)
 		})
 
 		t.Run("ClusterWideTalosconfig", func(t *testing.T) {
 			ctx, cancel := context.WithTimeout(testCtx, backoff.DefaultConfig.MaxDelay+10*time.Second)
 			t.Cleanup(cancel)
 
-			data, err := omniClient.Management().WithCluster(cluster).Talosconfig(ctx)
-			require.NoError(t, err)
-			assert.NotEmpty(t, data)
-
-			config, err := clientconfig.FromBytes(data)
-			require.NoError(t, err)
-
-			c, err := talosclient.New(ctx, talosclient.WithConfig(config))
-			require.NoError(t, err)
+			talosClient := getTalosClient(ctx, t, options)
 
 			t.Cleanup(func() {
-				require.NoError(t, c.Close())
+				require.NoError(t, talosClient.Close())
 			})
 
-			assertTalosAPI(ctx, t, c)
+			assertTalosAPI(ctx, t, talosClient)
 		})
 	}
 }
 
 // AssertEtcdMembershipMatchesOmniResources checks that etcd members are in sync with the Omni MachineStatus information.
-func AssertEtcdMembershipMatchesOmniResources(testCtx context.Context, client *client.Client, cluster string) TestFunc {
+func AssertEtcdMembershipMatchesOmniResources(testCtx context.Context, options *TestOptions, cluster string) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, 5*time.Minute)
 		defer cancel()
 
-		data, err := client.Management().Talosconfig(ctx)
-		require.NoError(t, err)
-		assert.NotEmpty(t, data)
-
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(t, err)
-
-		c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(cluster))
-		require.NoError(t, err)
+		omniClient := options.omniClient
+		talosClient := getTalosClientForCluster(ctx, t, options, cluster)
 
 		t.Cleanup(func() {
-			require.NoError(t, c.Close())
+			require.NoError(t, talosClient.Close())
 		})
 
-		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, client.Omni().State(),
+		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, omniClient.Omni().State(),
 			state.WithLabelQuery(
 				resource.LabelEqual(omni.LabelCluster, cluster),
 				resource.LabelExists(omni.LabelControlPlaneRole),
 			),
 		)
 
-		clearConnectionRefused(ctx, t, c, len(machineIDs), machineIDs...)
+		clearConnectionRefused(ctx, t, talosClient, len(machineIDs), machineIDs...)
 
 		require.EventuallyWithT(t, func(collect *assert.CollectT) {
 			require.NoError(t, ctx.Err())
 
-			resp, err := c.EtcdMemberList(ctx, &machine.EtcdMemberListRequest{})
+			resp, err := talosClient.EtcdMemberList(ctx, &machine.EtcdMemberListRequest{})
 			require.NoError(collect, err)
 
 			clusterMachines := map[string]any{}
@@ -323,7 +294,7 @@ func AssertEtcdMembershipMatchesOmniResources(testCtx context.Context, client *c
 			for _, machineID := range machineIDs {
 				var machineStatus *omni.MachineStatus
 
-				machineStatus, err = safe.StateGet[*omni.MachineStatus](ctx, client.Omni().State(), omni.NewMachineStatus(machineID).Metadata())
+				machineStatus, err = safe.StateGet[*omni.MachineStatus](ctx, omniClient.Omni().State(), omni.NewMachineStatus(machineID).Metadata())
 				require.NoError(collect, err)
 
 				clusterMachines[machineStatus.TypedSpec().Value.Network.Hostname] = struct{}{}
@@ -351,27 +322,21 @@ func AssertEtcdMembershipMatchesOmniResources(testCtx context.Context, client *c
 }
 
 // AssertTalosMembersMatchOmni checks that Talos discovery service members are in sync with the machines attached to the cluster.
-func AssertTalosMembersMatchOmni(testCtx context.Context, client *client.Client, clusterName string) TestFunc {
+func AssertTalosMembersMatchOmni(testCtx context.Context, options *TestOptions, clusterName string) TestFunc {
 	return func(t *testing.T) {
 		require := require.New(t)
 
 		ctx, cancel := context.WithTimeout(testCtx, backoff.DefaultConfig.BaseDelay+120*time.Second)
 		defer cancel()
 
-		data, err := client.Management().Talosconfig(ctx)
-		require.NoError(err)
-
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(err)
-
-		c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(clusterName))
-		require.NoError(err)
+		omniClient := options.omniClient
+		talosClient := getTalosClientForCluster(ctx, t, options, clusterName)
 
 		t.Cleanup(func() {
-			require.NoError(c.Close())
+			require.NoError(talosClient.Close())
 		})
 
-		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, client.Omni().State(),
+		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, omniClient.Omni().State(),
 			state.WithLabelQuery(
 				resource.LabelEqual(omni.LabelCluster, clusterName),
 			),
@@ -383,7 +348,7 @@ func AssertTalosMembersMatchOmni(testCtx context.Context, client *client.Client,
 		for _, machineID := range machineIDs {
 			var clusterMachineIdentity *omni.ClusterMachineIdentity
 
-			clusterMachineIdentity, err = safe.StateGet[*omni.ClusterMachineIdentity](ctx, client.Omni().State(),
+			clusterMachineIdentity, err := safe.StateGet[*omni.ClusterMachineIdentity](ctx, omniClient.Omni().State(),
 				omni.NewClusterMachineIdentity(machineID).Metadata(),
 			)
 
@@ -395,28 +360,29 @@ func AssertTalosMembersMatchOmni(testCtx context.Context, client *client.Client,
 		}
 
 		// check that every Omni machine is in Talos as a member
-		rtestutils.AssertResources(ctx, t, c.COSI, maps.Keys(clusterMachines), func(member *cluster.Member, asrt *assert.Assertions) {
+		rtestutils.AssertResources(ctx, t, talosClient.COSI, maps.Keys(clusterMachines), func(member *cluster.Member, asrt *assert.Assertions) {
 			asrt.Equal(clusterMachines[member.Metadata().ID()], member.TypedSpec().NodeID, resourceDetails(member))
 		})
 
 		// check that length of resources matches expectations (i.e. there are no extra members)
-		rtestutils.AssertLength[*cluster.Member](ctx, t, c.COSI, len(clusterMachines))
+		rtestutils.AssertLength[*cluster.Member](ctx, t, talosClient.COSI, len(clusterMachines))
 	}
 }
 
 // AssertTalosVersion verifies Talos version on the nodes.
-func AssertTalosVersion(testCtx context.Context, client *client.Client, clusterName, expectedVersion string) TestFunc {
+func AssertTalosVersion(testCtx context.Context, options *TestOptions, clusterName, expectedVersion string) TestFunc {
 	return func(t *testing.T) {
 		require := require.New(t)
+		omniClient := options.omniClient
 
 		ctx, cancel := context.WithTimeout(testCtx, backoff.DefaultConfig.BaseDelay+90*time.Second)
 		defer cancel()
 
-		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, client.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)))
+		machineIDs := rtestutils.ResourceIDs[*omni.ClusterMachine](ctx, t, omniClient.Omni().State(), state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)))
 
 		cms, err := safe.StateListAll[*omni.ClusterMachineIdentity](
 			testCtx,
-			client.Omni().State(),
+			omniClient.Omni().State(),
 			state.WithLabelQuery(resource.LabelEqual(omni.LabelCluster, clusterName)),
 		)
 		require.NoError(err)
@@ -431,23 +397,15 @@ func AssertTalosVersion(testCtx context.Context, client *client.Client, clusterN
 		require.NoError(err)
 
 		// assert using Omni MachineStatus resource
-		rtestutils.AssertResources(ctx, t, client.Omni().State(), machineIDs, func(r *omni.MachineStatus, asrt *assert.Assertions) {
+		rtestutils.AssertResources(ctx, t, omniClient.Omni().State(), machineIDs, func(r *omni.MachineStatus, asrt *assert.Assertions) {
 			asrt.Equal(expectedVersion, strings.TrimLeft(r.TypedSpec().Value.TalosVersion, "v"), resourceDetails(r))
 		})
 
-		data, err := client.Management().Talosconfig(ctx)
-		require.NoError(err)
-		require.NotEmpty(data)
-
-		data, err = client.Management().WithCluster(clusterName).Talosconfig(ctx)
+		data, err := omniClient.Management().Talosconfig(ctx)
 		require.NoError(err)
 		require.NotEmpty(data)
 
-		config, err := clientconfig.FromBytes(data)
-		require.NoError(err)
-
-		c, err := talosclient.New(ctx, talosclient.WithConfig(config), talosclient.WithCluster(clusterName))
-		require.NoError(err)
+		c := getTalosClientForCluster(ctx, t, options, clusterName)
 
 		t.Cleanup(func() {
 			require.NoError(c.Close())
@@ -473,7 +431,7 @@ func AssertTalosVersion(testCtx context.Context, client *client.Client, clusterN
 		}))
 
 		// assert using Talos upgrade controller status
-		rtestutils.AssertResources(ctx, t, client.Omni().State(), []resource.ID{clusterName}, func(r *omni.TalosUpgradeStatus, asrt *assert.Assertions) {
+		rtestutils.AssertResources(ctx, t, omniClient.Omni().State(), []resource.ID{clusterName}, func(r *omni.TalosUpgradeStatus, asrt *assert.Assertions) {
 			asrt.Equal(specs.TalosUpgradeStatusSpec_Done, r.TypedSpec().Value.Phase, resourceDetails(r))
 			asrt.Equal(expectedVersion, r.TypedSpec().Value.LastUpgradeVersion, resourceDetails(r))
 		})
@@ -766,7 +724,7 @@ func AssertTalosUpgradeIsCancelable(testCtx context.Context, st state.State, clu
 // AssertMachineShouldBeUpgradedInMaintenanceMode verifies machine upgrade in maintenance mode.
 func AssertMachineShouldBeUpgradedInMaintenanceMode(
 	testCtx context.Context,
-	rootClient *client.Client,
+	options *TestOptions,
 	clusterName, kubernetesVersion, talosVersion1, talosVersion2 string,
 ) TestFunc {
 	return func(t *testing.T) {
@@ -779,23 +737,24 @@ func AssertMachineShouldBeUpgradedInMaintenanceMode(
 
 		t.Logf("test maintenance upgrade flow from version %q to %q", talosVersion1, talosVersion2)
 
-		st := rootClient.Omni().State()
+		omniClient := options.omniClient
+		omniState := omniClient.Omni().State()
 
 		var allocatedMachineIDs []resource.ID
 
 		t.Logf("creating a cluster on version %q", talosVersion1)
 
-		pickUnallocatedMachines(ctx, t, st, 1, nil, func(machineIDs []resource.ID) {
+		pickUnallocatedMachines(ctx, t, omniState, 1, nil, func(machineIDs []resource.ID) {
 			allocatedMachineIDs = machineIDs
 
 			cluster := omni.NewCluster(clusterName)
 			cluster.TypedSpec().Value.TalosVersion = talosVersion1
 			cluster.TypedSpec().Value.KubernetesVersion = kubernetesVersion
 
-			require.NoError(st.Create(ctx, cluster))
+			require.NoError(omniState.Create(ctx, cluster))
 
 			t.Logf("Adding machine %q to control plane (cluster %q, version %q)", machineIDs[0], clusterName, talosVersion1)
-			bindMachine(ctx, t, st, bindMachineOptions{
+			bindMachine(ctx, t, omniState, bindMachineOptions{
 				clusterName:  clusterName,
 				role:         omni.LabelControlPlaneRole,
 				machineID:    machineIDs[0],
@@ -803,7 +762,7 @@ func AssertMachineShouldBeUpgradedInMaintenanceMode(
 			})
 
 			// assert that machines got allocated (label available is removed)
-			rtestutils.AssertResources(ctx, t, st, machineIDs, func(machineStatus *omni.MachineStatus, assert *assert.Assertions) {
+			rtestutils.AssertResources(ctx, t, omniState, machineIDs, func(machineStatus *omni.MachineStatus, assert *assert.Assertions) {
 				assert.True(machineStatus.Metadata().Labels().Matches(
 					resource.LabelTerm{
 						Key:    omni.MachineStatusLabelAvailable,
@@ -815,17 +774,17 @@ func AssertMachineShouldBeUpgradedInMaintenanceMode(
 		})
 
 		assertClusterReady := func(expectedVersion string) {
-			AssertClusterMachinesStage(ctx, rootClient.Omni().State(), clusterName, specs.ClusterMachineStatusSpec_RUNNING)(t)
-			AssertClusterMachinesReady(ctx, rootClient.Omni().State(), clusterName)(t)
-			AssertClusterStatusReady(ctx, st, clusterName)(t)
-			AssertTalosVersion(ctx, rootClient, clusterName, expectedVersion)
+			AssertClusterMachinesStage(ctx, omniClient.Omni().State(), clusterName, specs.ClusterMachineStatusSpec_RUNNING)(t)
+			AssertClusterMachinesReady(ctx, omniClient.Omni().State(), clusterName)(t)
+			AssertClusterStatusReady(ctx, omniState, clusterName)(t)
+			AssertTalosVersion(ctx, options, clusterName, expectedVersion)
 		}
 
 		// wait for the initial cluster on talosVersion1 to be ready
 		assertClusterReady(talosVersion1)
 
 		// destroy the cluster
-		AssertDestroyCluster(ctx, rootClient.Omni().State(), clusterName, false, false)(t)
+		AssertDestroyCluster(ctx, omniClient.Omni().State(), clusterName, false, false)(t)
 
 		t.Logf("creating a cluster on version %q using same machines", talosVersion2)
 
@@ -834,10 +793,10 @@ func AssertMachineShouldBeUpgradedInMaintenanceMode(
 		cluster.TypedSpec().Value.TalosVersion = talosVersion2
 		cluster.TypedSpec().Value.KubernetesVersion = kubernetesVersion
 
-		require.NoError(st.Create(ctx, cluster))
+		require.NoError(omniState.Create(ctx, cluster))
 
 		t.Logf("Adding machine %q to control plane (cluster %q, version %q)", allocatedMachineIDs[0], clusterName, talosVersion2)
-		bindMachine(ctx, t, st, bindMachineOptions{
+		bindMachine(ctx, t, omniState, bindMachineOptions{
 			clusterName:  clusterName,
 			role:         omni.LabelControlPlaneRole,
 			machineID:    allocatedMachineIDs[0],
@@ -847,24 +806,24 @@ func AssertMachineShouldBeUpgradedInMaintenanceMode(
 		// wait for cluster on talosVersion2 to be ready
 		assertClusterReady(talosVersion2)
 
-		AssertDestroyCluster(ctx, rootClient.Omni().State(), clusterName, false, false)(t)
+		AssertDestroyCluster(ctx, omniClient.Omni().State(), clusterName, false, false)(t)
 	}
 }
 
 // AssertTalosServiceIsRestarted verifies that Talos service is restarted on the nodes that match given cluster machine label query options.
-func AssertTalosServiceIsRestarted(testCtx context.Context, cli *client.Client, clusterName string,
+func AssertTalosServiceIsRestarted(testCtx context.Context, options *TestOptions, clusterName string,
 	service string, labelQueryOpts ...resource.LabelQueryOption,
 ) TestFunc {
 	return func(t *testing.T) {
 		ctx, cancel := context.WithTimeout(testCtx, 1*time.Minute)
 		defer cancel()
 
-		talosCli, err := talosClientForCluster(ctx, cli, clusterName)
-		require.NoError(t, err)
+		omniClient := options.omniClient
+		talosClient := getTalosClientForCluster(ctx, t, options, clusterName)
 
 		labelQueryOpts = append(labelQueryOpts, resource.LabelEqual(omni.LabelCluster, clusterName))
 
-		clusterMachineList, err := safe.StateListAll[*omni.ClusterMachine](ctx, cli.Omni().State(), state.WithLabelQuery(labelQueryOpts...))
+		clusterMachineList, err := safe.StateListAll[*omni.ClusterMachine](ctx, omniClient.Omni().State(), state.WithLabelQuery(labelQueryOpts...))
 		require.NoError(t, err)
 
 		for clusterMachine := range clusterMachineList.All() {
@@ -872,7 +831,7 @@ func AssertTalosServiceIsRestarted(testCtx context.Context, cli *client.Client,
 
 			t.Logf("Restarting service %q on node %q", service, nodeID)
 
-			_, err = talosCli.MachineClient.ServiceRestart(talosclient.WithNode(ctx, nodeID), &machine.ServiceRestartRequest{
+			_, err = talosClient.MachineClient.ServiceRestart(talosclient.WithNode(ctx, nodeID), &machine.ServiceRestartRequest{
 				Id: service,
 			})
 			require.NoError(t, err)
diff --git a/internal/integration/workloadproxy/workloadproxy.go b/internal/integration/workloadproxy/workloadproxy.go
index 5c9ffb66..f04fda01 100644
--- a/internal/integration/workloadproxy/workloadproxy.go
+++ b/internal/integration/workloadproxy/workloadproxy.go
@@ -31,7 +31,8 @@ import (
 	"github.com/hashicorp/go-cleanhttp"
 	"github.com/siderolabs/gen/maps"
 	"github.com/siderolabs/gen/xslices"
-	"github.com/siderolabs/go-pointer"
+	"github.com/siderolabs/go-api-signature/pkg/pgp"
+	"github.com/siderolabs/go-api-signature/pkg/serviceaccount"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap"
@@ -48,7 +49,6 @@ import (
 	"github.com/siderolabs/omni/client/pkg/omni/resources/omni"
 	"github.com/siderolabs/omni/internal/backend/services/workloadproxy"
 	"github.com/siderolabs/omni/internal/integration/kubernetes"
-	"github.com/siderolabs/omni/internal/pkg/clientconfig"
 )
 
 type serviceContext struct {
@@ -75,7 +75,7 @@ var sideroLabsIconSVG []byte
 // Test tests the exposed services functionality in Omni.
 //
 //nolint:prealloc
-func Test(ctx context.Context, t *testing.T, omniClient *client.Client, clusterIDs ...string) {
+func Test(ctx context.Context, t *testing.T, omniClient *client.Client, serviceAccountKey string, clusterIDs ...string) {
 	ctx, cancel := context.WithTimeout(ctx, 20*time.Minute)
 	t.Cleanup(cancel)
 
@@ -83,6 +83,9 @@ func Test(ctx context.Context, t *testing.T, omniClient *client.Client, clusterI
 		require.Fail(t, "no cluster IDs provided for the test, please provide at least one cluster ID")
 	}
 
+	sa, err := serviceaccount.Decode(serviceAccountKey)
+	require.NoError(t, err)
+
 	ctx = kubernetes.WrapContext(ctx, t)
 	logger := zaptest.NewLogger(t)
 
@@ -118,7 +121,7 @@ func Test(ctx context.Context, t *testing.T, omniClient *client.Client, clusterI
 		allExposedServices[i], allExposedServices[j] = allExposedServices[j], allExposedServices[i]
 	})
 
-	testAccess(ctx, t, logger, omniClient, allExposedServices, http.StatusOK)
+	testAccess(ctx, t, logger, sa.Key, allExposedServices, http.StatusOK)
 
 	inaccessibleExposedServices := make([]*omni.ExposedService, 0, len(allExposedServices))
 
@@ -132,7 +135,7 @@ func Test(ctx context.Context, t *testing.T, omniClient *client.Client, clusterI
 		}
 	}
 
-	testAccess(ctx, t, logger, omniClient, inaccessibleExposedServices, http.StatusBadGateway)
+	testAccess(ctx, t, logger, sa.Key, inaccessibleExposedServices, http.StatusBadGateway)
 
 	for _, deployment := range deploymentsToScaleDown {
 		logger.Info("scale deployment back up", zap.String("deployment", deployment.deployment.Name), zap.String("clusterID", deployment.cluster.clusterID))
@@ -140,13 +143,13 @@ func Test(ctx context.Context, t *testing.T, omniClient *client.Client, clusterI
 		kubernetes.ScaleDeployment(ctx, t, deployment.cluster.kubeClient, deployment.deployment.Namespace, deployment.deployment.Name, 1)
 	}
 
-	testAccess(ctx, t, logger, omniClient, allExposedServices, http.StatusOK)
-	testToggleFeature(ctx, t, logger, omniClient, clusters[0])
-	testToggleKubernetesServiceAnnotation(ctx, t, logger, omniClient, allServices[:len(allServices)/2])
+	testAccess(ctx, t, logger, sa.Key, allExposedServices, http.StatusOK)
+	testToggleFeature(ctx, t, logger, omniClient, sa.Key, clusters[0])
+	testToggleKubernetesServiceAnnotation(ctx, t, logger, omniClient, sa.Key, allServices[:len(allServices)/2])
 }
 
 // testToggleFeature tests toggling off/on the workload proxy feature for a cluster.
-func testToggleFeature(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, cluster clusterContext) {
+func testToggleFeature(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, saKey *pgp.Key, cluster clusterContext) {
 	logger.Info("test turning off and on the feature for the cluster", zap.String("clusterID", cluster.clusterID))
 
 	setFeatureToggle := func(enabled bool) {
@@ -172,14 +175,14 @@ func testToggleFeature(ctx context.Context, t *testing.T, logger *zap.Logger, om
 		services = services[:4]
 	}
 
-	testAccess(ctx, t, logger, omniClient, services[:4], http.StatusNotFound)
+	testAccess(ctx, t, logger, saKey, services[:4], http.StatusNotFound)
 
 	setFeatureToggle(true)
 
-	testAccess(ctx, t, logger, omniClient, services[:4], http.StatusOK)
+	testAccess(ctx, t, logger, saKey, services[:4], http.StatusOK)
 }
 
-func testToggleKubernetesServiceAnnotation(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, services []serviceContext) {
+func testToggleKubernetesServiceAnnotation(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, saKey *pgp.Key, services []serviceContext) {
 	logger.Info("test toggling Kubernetes service annotation for exposed services", zap.Int("numServices", len(services)))
 
 	for _, service := range services {
@@ -195,7 +198,7 @@ func testToggleKubernetesServiceAnnotation(ctx context.Context, t *testing.T, lo
 
 	exposedServices := xslices.Map(services, func(svc serviceContext) *omni.ExposedService { return svc.res })
 
-	testAccess(ctx, t, logger, omniClient, exposedServices, http.StatusNotFound)
+	testAccess(ctx, t, logger, saKey, exposedServices, http.StatusNotFound)
 
 	for _, service := range services {
 		kubernetes.UpdateService(ctx, t, service.deployment.cluster.kubeClient, service.svc.Namespace, service.svc.Name, func(svc *corev1.Service) {
@@ -223,7 +226,7 @@ func testToggleKubernetesServiceAnnotation(ctx context.Context, t *testing.T, lo
 
 	updatedServices := maps.Values(updatedServicesMap)
 
-	testAccess(ctx, t, logger, omniClient, updatedServices, http.StatusOK)
+	testAccess(ctx, t, logger, saKey, updatedServices, http.StatusOK)
 }
 
 func prepareServices(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, clusterID string) clusterContext {
@@ -299,11 +302,15 @@ func prepareServices(ctx context.Context, t *testing.T, logger *zap.Logger, omni
 	return cluster
 }
 
-func testAccess(ctx context.Context, t *testing.T, logger *zap.Logger, omniClient *client.Client, exposedServices []*omni.ExposedService, expectedStatusCode int) {
-	keyID, keyIDSignatureBase64, err := clientconfig.RegisterKeyGetIDSignatureBase64(ctx, omniClient)
+func testAccess(ctx context.Context, t *testing.T, logger *zap.Logger, saKey *pgp.Key, exposedServices []*omni.ExposedService, expectedStatusCode int) {
+	keyID := saKey.Fingerprint()
+
+	signedIDBytes, err := saKey.Sign([]byte(keyID))
 	require.NoError(t, err)
 
-	logger.Debug("registered public key for workload proxy", zap.String("keyID", keyID), zap.String("keyIDSignatureBase64", keyIDSignatureBase64))
+	keyIDSignatureBase64 := base64.StdEncoding.EncodeToString(signedIDBytes)
+
+	logger.Debug("using SA key for workload proxy", zap.String("keyID", keyID), zap.String("keyIDSignatureBase64", keyIDSignatureBase64))
 
 	cookies := []*http.Cookie{
 		{Name: workloadproxy.PublicKeyIDCookie, Value: keyID},
@@ -519,7 +526,7 @@ func createKubernetesResources(ctx context.Context, t *testing.T, logger *zap.Lo
 			Namespace: namespace,
 		},
 		Spec: appsv1.DeploymentSpec{
-			Replicas: pointer.To(int32(numReplicas)),
+			Replicas: new(int32(numReplicas)),
 			Selector: &metav1.LabelSelector{
 				MatchLabels: map[string]string{
 					"app": identifier,
diff --git a/internal/pkg/clientconfig/clientconfig.go b/internal/pkg/clientconfig/clientconfig.go
deleted file mode 100644
index 57b7dec6..00000000
--- a/internal/pkg/clientconfig/clientconfig.go
+++ /dev/null
@@ -1,302 +0,0 @@
-// Copyright (c) 2026 Sidero Labs, Inc.
-//
-// Use of this software is governed by the Business Source License
-// included in the LICENSE file.
-
-// Package clientconfig holds the configuration for the test client for Omni API.
-package clientconfig
-
-import (
-	"context"
-	"crypto/md5"
-	"encoding/base64"
-	"fmt"
-	"net/http"
-	"runtime"
-	"slices"
-	"time"
-
-	"github.com/cosi-project/runtime/pkg/safe"
-	"github.com/cosi-project/runtime/pkg/state"
-	"github.com/hashicorp/go-multierror"
-	"github.com/siderolabs/gen/containers"
-	authpb "github.com/siderolabs/go-api-signature/api/auth"
-	authcli "github.com/siderolabs/go-api-signature/pkg/client/auth"
-	"github.com/siderolabs/go-api-signature/pkg/message"
-	"github.com/siderolabs/go-api-signature/pkg/pgp"
-	"github.com/siderolabs/go-api-signature/pkg/serviceaccount"
-
-	"github.com/siderolabs/omni/client/api/omni/management"
-	"github.com/siderolabs/omni/client/pkg/access"
-	"github.com/siderolabs/omni/client/pkg/client"
-	authres "github.com/siderolabs/omni/client/pkg/omni/resources/auth"
-	"github.com/siderolabs/omni/internal/pkg/auth"
-	"github.com/siderolabs/omni/internal/pkg/auth/role"
-	omnisa "github.com/siderolabs/omni/internal/pkg/auth/serviceaccount"
-)
-
-const (
-	DefaultServiceAccount = "integration" + access.ServiceAccountNameSuffix
-	defaultEmail          = "test-user@siderolabs.com"
-)
-
-type clientCacheKey struct {
-	role         string
-	email        string
-	skipUserRole bool
-}
-
-type clientCacheValue struct {
-	client *client.Client
-	key    *pgp.Key
-	err    error
-}
-
-// ClientConfig is a test client.
-type ClientConfig struct {
-	endpoint          string
-	serviceAccountKey string
-	clientCache       containers.ConcurrentMap[clientCacheKey, clientCacheValue]
-}
-
-// New creates a new test client config.
-func New(endpoint, serviceAccountKey string) *ClientConfig {
-	return &ClientConfig{
-		endpoint:          endpoint,
-		serviceAccountKey: serviceAccountKey,
-	}
-}
-
-// GetClient returns a test client for the default test email.
-//
-// Clients are cached by their configuration, so if a client with the
-// given configuration was created before, the cached one will be returned.
-func (t *ClientConfig) GetClient(ctx context.Context, publicKeyOpts ...authcli.RegisterPGPPublicKeyOption) (*client.Client, error) {
-	return t.GetClientForEmail(ctx, DefaultServiceAccount, publicKeyOpts...)
-}
-
-// GetClientForEmail returns a test client for the given email.
-//
-// Clients are cached by their configuration, so if a client with the
-// given configuration was created before, the cached one will be returned.
-func (t *ClientConfig) GetClientForEmail(ctx context.Context, email string, publicKeyOpts ...authcli.RegisterPGPPublicKeyOption) (*client.Client, error) {
-	cacheKey := t.buildCacheKey(email, publicKeyOpts)
-
-	// The client is created by the cache callback, and will be closed by the cache on [ClientConfig.Close].
-	cliValue, _ := t.clientCache.GetOrCall(cacheKey, func() clientCacheValue {
-		cli, key, err := createServiceAccountClient(ctx, t.endpoint, t.serviceAccountKey, cacheKey)
-
-		return clientCacheValue{
-			client: cli,
-			key:    key,
-			err:    err,
-		}
-	})
-
-	return cliValue.client, cliValue.err
-}
-
-// GetKey fetches service account key for the default email.
-func (t *ClientConfig) GetKey(ctx context.Context, publicKeyOpts ...authcli.RegisterPGPPublicKeyOption) (*pgp.Key, error) {
-	return t.GetKeyForEmail(ctx, DefaultServiceAccount, publicKeyOpts...)
-}
-
-// GetKeyForEmail fetches service account key for the specified email.
-func (t *ClientConfig) GetKeyForEmail(ctx context.Context, email string, publicKeyOpts ...authcli.RegisterPGPPublicKeyOption) (*pgp.Key, error) {
-	cacheKey := t.buildCacheKey(email, publicKeyOpts)
-
-	// The client is created by the cache callback, and will be closed by the cache on [ClientConfig.Close].
-	cliOrErr, _ := t.clientCache.GetOrCall(cacheKey, func() clientCacheValue {
-		cli, key, err := createServiceAccountClient(ctx, t.endpoint, t.serviceAccountKey, cacheKey)
-
-		return clientCacheValue{
-			client: cli,
-			key:    key,
-			err:    err,
-		}
-	})
-
-	return cliOrErr.key, cliOrErr.err
-}
-
-// Close closes all the clients created by this config.
-func (t *ClientConfig) Close() error {
-	var multiErr error
-
-	t.clientCache.ForEach(func(_ clientCacheKey, cliOrErr clientCacheValue) {
-		if cliOrErr.client != nil {
-			if err := cliOrErr.client.Close(); err != nil {
-				multiErr = multierror.Append(multiErr, err)
-			}
-		}
-	})
-
-	return multiErr
-}
-
-func (t *ClientConfig) buildCacheKey(email string, publicKeyOpts []authcli.RegisterPGPPublicKeyOption) clientCacheKey {
-	var req authpb.RegisterPublicKeyRequest
-
-	for _, o := range publicKeyOpts {
-		o(&req)
-	}
-
-	return clientCacheKey{
-		role:         req.Role,
-		email:        email,
-		skipUserRole: req.SkipUserRole,
-	}
-}
-
-// SignHTTPRequest signs the regular HTTP request using the default test email.
-func SignHTTPRequest(ctx context.Context, client *client.Client, req *http.Request) error {
-	return SignHTTPRequestWithEmail(ctx, client, req, defaultEmail)
-}
-
-// SignHTTPRequestWithEmail signs the regular HTTP request using the given email.
-func SignHTTPRequestWithEmail(ctx context.Context, client *client.Client, req *http.Request, email string) error {
-	newKey, err := pgp.GenerateKey("", "", email, 4*time.Hour)
-	if err != nil {
-		return err
-	}
-
-	err = registerKey(ctx, client.Auth(), newKey, email)
-	if err != nil {
-		return err
-	}
-
-	msg, err := message.NewHTTP(req)
-	if err != nil {
-		return err
-	}
-
-	return msg.Sign(email, newKey)
-}
-
-// RegisterKeyGetIDSignatureBase64 registers a new public key with the default test email and returns its ID and the base-64 encoded signature of the same ID.
-func RegisterKeyGetIDSignatureBase64(ctx context.Context, client *client.Client) (id, idSignatureBase66 string, err error) {
-	newKey, err := pgp.GenerateKey("", "", defaultEmail, 4*time.Hour)
-	if err != nil {
-		return "", "", err
-	}
-
-	err = registerKey(ctx, client.Auth(), newKey, defaultEmail)
-	if err != nil {
-		return "", "", err
-	}
-
-	id = newKey.Fingerprint()
-
-	signedIDBytes, err := newKey.Sign([]byte(id))
-	if err != nil {
-		return "", "", err
-	}
-
-	idSignatureBase66 = base64.StdEncoding.EncodeToString(signedIDBytes)
-
-	return id, idSignatureBase66, nil
-}
-
-// CreateServiceAccount using the direct access to the Omni state.
-func CreateServiceAccount(ctx context.Context, name string, st state.State) (string, error) {
-	// generate a new PGP key with long lifetime
-	comment := fmt.Sprintf("%s/%s", runtime.GOOS, runtime.GOARCH)
-
-	serviceAccountEmail := name + access.ServiceAccountNameSuffix
-
-	key, err := pgp.GenerateKey(name, comment, serviceAccountEmail, auth.ServiceAccountMaxAllowedLifetime)
-	if err != nil {
-		return "", err
-	}
-
-	armoredPublicKey, err := key.ArmorPublic()
-	if err != nil {
-		return "", err
-	}
-
-	identity, err := safe.ReaderGetByID[*authres.Identity](ctx, st, serviceAccountEmail)
-	if err != nil && !state.IsNotFoundError(err) {
-		return "", err
-	}
-
-	if identity != nil {
-		err = omnisa.Destroy(ctx, st, name)
-		if err != nil {
-			return "", err
-		}
-	}
-
-	_, err = omnisa.Create(ctx, st, name, string(role.Admin), false, []byte(armoredPublicKey))
-	if err != nil {
-		return "", err
-	}
-
-	return serviceaccount.Encode(name, key)
-}
-
-func createServiceAccountClient(ctx context.Context, endpoint, serviceAccountKey string, cacheKey clientCacheKey) (*client.Client, *pgp.Key, error) {
-	rootClient, err := client.New(endpoint, client.WithServiceAccount(serviceAccountKey))
-	if err != nil {
-		return nil, nil, err
-	}
-
-	defer rootClient.Close() //nolint:errcheck
-
-	name := fmt.Sprintf("%x", md5.Sum([]byte(cacheKey.email+cacheKey.role)))
-
-	// generate a new PGP key with long lifetime
-	comment := fmt.Sprintf("%s/%s", runtime.GOOS, runtime.GOARCH)
-
-	suffix := access.ServiceAccountNameSuffix
-
-	if cacheKey.role == string(role.InfraProvider) {
-		suffix = access.InfraProviderServiceAccountNameSuffix
-	}
-
-	serviceAccountEmail := name + suffix
-
-	key, err := pgp.GenerateKey(name, comment, serviceAccountEmail, auth.ServiceAccountMaxAllowedLifetime)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	if cacheKey.role == string(role.InfraProvider) {
-		name = access.InfraProviderServiceAccountPrefix + name
-	}
-
-	armoredPublicKey, err := key.ArmorPublic()
-	if err != nil {
-		return nil, nil, err
-	}
-
-	serviceAccounts, err := rootClient.Management().ListServiceAccounts(ctx)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	if slices.IndexFunc(serviceAccounts, func(account *management.ListServiceAccountsResponse_ServiceAccount) bool {
-		return account.Name == name
-	}) != -1 {
-		if err = rootClient.Management().DestroyServiceAccount(ctx, name); err != nil {
-			return nil, nil, err
-		}
-	}
-
-	// create service account with the generated key
-	_, err = rootClient.Management().CreateServiceAccount(ctx, name, armoredPublicKey, cacheKey.role, cacheKey.role == "")
-	if err != nil {
-		return nil, nil, err
-	}
-
-	encodedKey, err := serviceaccount.Encode(name, key)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	cli, err := client.New(endpoint, client.WithServiceAccount(encodedKey))
-	if err != nil {
-		return nil, nil, err
-	}
-
-	return cli, key, nil
-}
diff --git a/internal/pkg/clientconfig/register_key_debug.go b/internal/pkg/clientconfig/register_key_debug.go
deleted file mode 100644
index 7583c741..00000000
--- a/internal/pkg/clientconfig/register_key_debug.go
+++ /dev/null
@@ -1,43 +0,0 @@
-// Copyright (c) 2026 Sidero Labs, Inc.
-//
-// Use of this software is governed by the Business Source License
-// included in the LICENSE file.
-
-//go:build sidero.debug
-
-package clientconfig
-
-import (
-	"context"
-	"time"
-
-	"github.com/siderolabs/go-api-signature/pkg/client/auth"
-	"github.com/siderolabs/go-api-signature/pkg/pgp"
-	"google.golang.org/grpc/metadata"
-
-	grpcomni "github.com/siderolabs/omni/internal/backend/grpc"
-)
-
-func registerKey(ctx context.Context, cli *auth.Client, key *pgp.Key, email string, opts ...auth.RegisterPGPPublicKeyOption) error {
-	armoredPublicKey, err := key.ArmorPublic()
-	if err != nil {
-		return err
-	}
-
-	_, err = cli.RegisterPGPPublicKey(ctx, email, []byte(armoredPublicKey), opts...)
-	if err != nil {
-		return err
-	}
-
-	debugCtx := metadata.AppendToOutgoingContext(ctx, grpcomni.DebugVerifiedEmailHeaderKey, email)
-
-	err = cli.ConfirmPublicKey(debugCtx, key.Fingerprint())
-	if err != nil {
-		return err
-	}
-
-	timeoutCtx, timeoutCtxCancel := context.WithTimeout(ctx, 10*time.Second)
-	defer timeoutCtxCancel()
-
-	return cli.AwaitPublicKeyConfirmation(timeoutCtx, key.Fingerprint())
-}
diff --git a/internal/pkg/clientconfig/register_key_no_debug.go b/internal/pkg/clientconfig/register_key_no_debug.go
deleted file mode 100644
index c55266e5..00000000
--- a/internal/pkg/clientconfig/register_key_no_debug.go
+++ /dev/null
@@ -1,20 +0,0 @@
-// Copyright (c) 2026 Sidero Labs, Inc.
-//
-// Use of this software is governed by the Business Source License
-// included in the LICENSE file.
-
-//go:build !sidero.debug
-
-package clientconfig
-
-import (
-	"context"
-	"errors"
-
-	"github.com/siderolabs/go-api-signature/pkg/client/auth"
-	"github.com/siderolabs/go-api-signature/pkg/pgp"
-)
-
-func registerKey(context.Context, *auth.Client, *pgp.Key, string, ...auth.RegisterPGPPublicKeyOption) error {
-	return errors.New("registerKey is not implemented in non-debug builds")
-}
diff --git a/internal/pkg/config/accessors.generated.go b/internal/pkg/config/accessors.generated.go
index 346d56d3..1449aebd 100644
--- a/internal/pkg/config/accessors.generated.go
+++ b/internal/pkg/config/accessors.generated.go
@@ -1293,6 +1293,17 @@ func (s *UserPilot) SetAppToken(v string) {
 	s.AppToken = &v
 }
 
+func (s *Vault) GetK8SAuthMountPath() string {
+	if s == nil || s.K8SAuthMountPath == nil {
+		return *new(string)
+	}
+	return *s.K8SAuthMountPath
+}
+
+func (s *Vault) SetK8SAuthMountPath(v string) {
+	s.K8SAuthMountPath = &v
+}
+
 func (s *Vault) GetToken() string {
 	if s == nil || s.Token == nil {
 		return *new(string)
diff --git a/internal/pkg/config/config_test.go b/internal/pkg/config/config_test.go
index eb3e9afc..617aa5f9 100644
--- a/internal/pkg/config/config_test.go
+++ b/internal/pkg/config/config_test.go
@@ -16,7 +16,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/inmem"
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	"github.com/santhosh-tekuri/jsonschema/v6"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/assert"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
@@ -218,8 +217,8 @@ func TestServiceURL(t *testing.T) {
 		t.Parallel()
 
 		conf := &config.DevServerProxyService{
-			Endpoint:      pointer.To("1.1.1.1:1111"),
-			AdvertisedURL: pointer.To("https://2.2.2.2:2222"),
+			Endpoint:      new("1.1.1.1:1111"),
+			AdvertisedURL: new("https://2.2.2.2:2222"),
 		}
 
 		url := conf.URL()
@@ -230,9 +229,9 @@ func TestServiceURL(t *testing.T) {
 		t.Parallel()
 
 		conf := &config.Service{
-			Endpoint: pointer.To("1.1.1.1:1111"),
-			CertFile: pointer.To("/path/to/cert"),
-			KeyFile:  pointer.To("/path/to/key"),
+			Endpoint: new("1.1.1.1:1111"),
+			CertFile: new("/path/to/cert"),
+			KeyFile:  new("/path/to/key"),
 		}
 
 		url := conf.URL()
@@ -243,7 +242,7 @@ func TestServiceURL(t *testing.T) {
 		t.Parallel()
 
 		conf := &config.MachineAPI{
-			Endpoint: pointer.To("1.1.1.1:1111"),
+			Endpoint: new("1.1.1.1:1111"),
 		}
 
 		url := conf.URL()
@@ -254,7 +253,7 @@ func TestServiceURL(t *testing.T) {
 		t.Parallel()
 
 		conf := &config.KubernetesProxyService{
-			Endpoint: pointer.To("1.1.1.1:1111"),
+			Endpoint: new("1.1.1.1:1111"),
 		}
 
 		url := conf.URL()
diff --git a/internal/pkg/config/schema.json b/internal/pkg/config/schema.json
index edf8146e..c2582af8 100644
--- a/internal/pkg/config/schema.json
+++ b/internal/pkg/config/schema.json
@@ -1020,6 +1020,10 @@
         "token": {
           "description": "Token is the authentication token for the Vault server. It is read from VAULT_TOKEN env var when not set. It is recommended to be passed as env var instead of being stored in the config file.",
           "type": "string"
+        },
+        "k8sAuthMountPath": {
+          "description": "K8sAuthMountPath is the mount path of the Kubernetes auth method in Vault. When not set, it defaults to \"kubernetes\". This is useful when Vault is running on a different cluster and has multiple Kubernetes auth mounts.",
+          "type": "string"
         }
       }
     },
diff --git a/internal/pkg/config/types.generated.go b/internal/pkg/config/types.generated.go
index 71be42b1..c599b4af 100644
--- a/internal/pkg/config/types.generated.go
+++ b/internal/pkg/config/types.generated.go
@@ -728,6 +728,11 @@ type UserPilot struct {
 }
 
 type Vault struct {
+	// K8sAuthMountPath is the mount path of the Kubernetes auth method in Vault. When
+	// not set, it defaults to "kubernetes". This is useful when Vault is running on a
+	// different cluster and has multiple Kubernetes auth mounts.
+	K8SAuthMountPath *string `json:"k8sAuthMountPath,omitempty" yaml:"k8sAuthMountPath,omitempty"`
+
 	// Token is the authentication token for the Vault server. It is read from
 	// VAULT_TOKEN env var when not set. It is recommended to be passed as env var
 	// instead of being stored in the config file.
diff --git a/internal/pkg/constants/versions.go b/internal/pkg/constants/versions.go
index 512a57a6..9bfe0fc7 100644
--- a/internal/pkg/constants/versions.go
+++ b/internal/pkg/constants/versions.go
@@ -14,7 +14,7 @@ import (
 )
 
 // AnotherTalosVersion is used in the integration tests for Talos upgrade.
-const AnotherTalosVersion = "1.12.0"
+const AnotherTalosVersion = "1.12.2"
 
 // StableTalosVersion is used in the integration tests for Talos upgrade between minor versions.
 const StableTalosVersion = "1.11.6"
@@ -25,7 +25,7 @@ const MinDiscoveredTalosVersion = "1.3.0"
 // DefaultKubernetesVersion is pre-selected in the UI and used in the integration tests.
 //
 // tsgen:DefaultKubernetesVersion
-const DefaultKubernetesVersion = "1.35.0"
+const DefaultKubernetesVersion = "1.35.1"
 
 // DefaultTalosVersion to be used in the tests.
 const DefaultTalosVersion = constants.DefaultTalosVersion
diff --git a/internal/pkg/grpcutil/server.go b/internal/pkg/grpcutil/server.go
index 58917588..84d66aff 100644
--- a/internal/pkg/grpcutil/server.go
+++ b/internal/pkg/grpcutil/server.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package grpcutil provides utility functions for gRPC servers and clients.
 package grpcutil
 
 import (
diff --git a/internal/pkg/kms/kms.go b/internal/pkg/kms/kms.go
index 6905cff5..1ff0de00 100644
--- a/internal/pkg/kms/kms.go
+++ b/internal/pkg/kms/kms.go
@@ -36,7 +36,7 @@ func NewManager(state state.State, logger *zap.Logger) *Manager {
 
 // Register manager to handle gRPC requests for seal and unseal.
 func (m *Manager) Register(srv *grpc.Server) {
-	grpcServer := server.NewServer(func(ctx context.Context, nodeUUID string) ([]byte, error) {
+	grpcServer := server.NewServer(m.logger, func(ctx context.Context, nodeUUID string) ([]byte, error) {
 		ctx = actor.MarkContextAsInternalActor(ctx)
 
 		res, err := safe.StateGet[*omni.ClusterMachineEncryptionKey](ctx, m.state, omni.NewClusterMachineEncryptionKey(nodeUUID).Metadata())
diff --git a/internal/pkg/siderolink/loghandler.go b/internal/pkg/siderolink/loghandler.go
index 45479d42..299d1f5e 100644
--- a/internal/pkg/siderolink/loghandler.go
+++ b/internal/pkg/siderolink/loghandler.go
@@ -28,9 +28,35 @@ type LogStoreManager interface {
 	Remove(ctx context.Context, id string) error
 }
 
+// LogHandlerOption configures optional LogHandler behavior.
+type LogHandlerOption func(*logHandlerOptions)
+
+type logHandlerOptions struct {
+	onCleanup func(int)
+}
+
+// WithLogHandlerCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithLogHandlerCleanupCallback(cb func(int)) LogHandlerOption {
+	return func(o *logHandlerOptions) {
+		o.onCleanup = cb
+	}
+}
+
 // NewLogHandler returns a new LogHandler.
-func NewLogHandler(secondaryStorageDB *sqlitex.Pool, machineMap *MachineMap, omniState state.State, storageConfig *config.LogsMachine, logger *zap.Logger) (*LogHandler, error) {
-	cache, err := NewMachineCache(secondaryStorageDB, storageConfig, omniState, logger)
+func NewLogHandler(secondaryStorageDB *sqlitex.Pool, machineMap *MachineMap, omniState state.State, storageConfig *config.LogsMachine, logger *zap.Logger,
+	opts ...LogHandlerOption,
+) (*LogHandler, error) {
+	var options logHandlerOptions
+	for _, opt := range opts {
+		opt(&options)
+	}
+
+	var cacheOpts []MachineCacheOption
+	if options.onCleanup != nil {
+		cacheOpts = append(cacheOpts, WithMachineCacheCleanupCallback(options.onCleanup))
+	}
+
+	cache, err := NewMachineCache(secondaryStorageDB, storageConfig, omniState, logger, cacheOpts...)
 	if err != nil {
 		return nil, fmt.Errorf("failed to create machine cache: %w", err)
 	}
diff --git a/internal/pkg/siderolink/loghandler_test.go b/internal/pkg/siderolink/loghandler_test.go
index a87ab48e..e0aa4966 100644
--- a/internal/pkg/siderolink/loghandler_test.go
+++ b/internal/pkg/siderolink/loghandler_test.go
@@ -16,7 +16,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/inmem"
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	"github.com/siderolabs/gen/optional"
-	"github.com/siderolabs/go-pointer"
 	"github.com/stretchr/testify/require"
 	"go.uber.org/zap/zaptest"
 	"zombiezen.com/go/sqlite/sqlitex"
@@ -28,13 +27,13 @@ import (
 
 func TestLogHandler_HandleMessage(t *testing.T) {
 	storageConfig := config.LogsMachine{
-		BufferInitialCapacity: pointer.To(6),
-		BufferMaxCapacity:     pointer.To(28),
-		BufferSafetyGap:       pointer.To(6),
+		BufferInitialCapacity: new(6),
+		BufferMaxCapacity:     new(28),
+		BufferSafetyGap:       new(6),
 		Storage: config.LogsMachineStorage{
-			NumCompressedChunks: pointer.To(5),
-			FlushPeriod:         pointer.To(time.Second),
-			Enabled:             pointer.To(false),
+			NumCompressedChunks: new(5),
+			FlushPeriod:         new(time.Second),
+			Enabled:             new(false),
 		},
 	}
 
diff --git a/internal/pkg/siderolink/logstore/logstore.go b/internal/pkg/siderolink/logstore/logstore.go
index 06e40cb7..0de42653 100644
--- a/internal/pkg/siderolink/logstore/logstore.go
+++ b/internal/pkg/siderolink/logstore/logstore.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package logstore provides an interface for writing logs and getting readers to read them.
 package logstore
 
 import (
diff --git a/internal/pkg/siderolink/logstore/sqlitelog/manager.go b/internal/pkg/siderolink/logstore/sqlitelog/manager.go
index eb1f7f4e..f6dbc511 100644
--- a/internal/pkg/siderolink/logstore/sqlitelog/manager.go
+++ b/internal/pkg/siderolink/logstore/sqlitelog/manager.go
@@ -25,19 +25,31 @@ import (
 )
 
 const (
-	tableName       = "machine_logs"
+	// TableName is the SQLite table name used by the machine log store.
+	TableName       = "machine_logs"
 	idColumn        = "id"
 	machineIDColumn = "machine_id"
 	createdAtColumn = "created_at"
 	messageColumn   = "message"
 )
 
+// StoreManagerOption configures optional StoreManager behavior.
+type StoreManagerOption func(*StoreManager)
+
+// WithCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithCleanupCallback(cb func(int)) StoreManagerOption {
+	return func(m *StoreManager) {
+		m.onCleanup = cb
+	}
+}
+
 // StoreManager manages log stores for machines.
 type StoreManager struct {
-	state  state.State
-	db     *sqlitex.Pool
-	logger *zap.Logger
-	config config.LogsMachineStorage
+	state     state.State
+	db        *sqlitex.Pool
+	logger    *zap.Logger
+	onCleanup func(int)
+	config    config.LogsMachineStorage
 }
 
 // Run implements the LogStoreManager interface.
@@ -139,7 +151,7 @@ func (m *StoreManager) DoCleanup(ctx context.Context) error {
 		//   (A) Log is older than cutoff (Time-based cleanup)
 		//   OR
 		//   (B) Machine ID is NOT in the active list (Orphan cleanup)
-		deleteSQL := fmt.Sprintf(`DELETE FROM %s WHERE %s < $cutoff OR %s NOT IN (SELECT machine_id FROM machine_ids)`, tableName, createdAtColumn, machineIDColumn)
+		deleteSQL := fmt.Sprintf(`DELETE FROM %s WHERE %s < $cutoff OR %s NOT IN (SELECT machine_id FROM machine_ids)`, TableName, createdAtColumn, machineIDColumn)
 
 		var q *sqlitexx.Query
 
@@ -157,6 +169,10 @@ func (m *StoreManager) DoCleanup(ctx context.Context) error {
 
 		rowsDeleted = conn.Changes()
 
+		if m.onCleanup != nil {
+			m.onCleanup(rowsDeleted)
+		}
+
 		err = sqlitex.ExecScript(conn, `DROP TABLE IF EXISTS machine_ids`)
 		if err != nil {
 			return fmt.Errorf("failed to drop temporary table: %w", err)
@@ -195,7 +211,7 @@ func (m *StoreManager) Exists(ctx context.Context, id string) (bool, error) {
 
 	defer m.db.Put(conn)
 
-	query := fmt.Sprintf("SELECT 1 FROM %s WHERE %s=$machine_id LIMIT 1", tableName, machineIDColumn)
+	query := fmt.Sprintf("SELECT 1 FROM %s WHERE %s=$machine_id LIMIT 1", TableName, machineIDColumn)
 
 	q, err := sqlitexx.NewQuery(conn, query)
 	if err != nil {
@@ -225,7 +241,7 @@ func (m *StoreManager) Remove(ctx context.Context, id string) error {
 	ctx, cancel := context.WithTimeout(ctx, m.config.GetSqliteTimeout())
 	defer cancel()
 
-	query := fmt.Sprintf("DELETE FROM %s WHERE %s=$machine_id", tableName, machineIDColumn)
+	query := fmt.Sprintf("DELETE FROM %s WHERE %s=$machine_id", TableName, machineIDColumn)
 
 	conn, err := m.db.Take(ctx)
 	if err != nil {
@@ -247,6 +263,11 @@ func (m *StoreManager) Remove(ctx context.Context, id string) error {
 	}
 
 	numRowsDeleted := conn.Changes()
+
+	if m.onCleanup != nil {
+		m.onCleanup(numRowsDeleted)
+	}
+
 	m.logger.Info("removed logs for machine", zap.String("machine_id", id), zap.Int("rows_affected", numRowsDeleted))
 
 	return nil
@@ -273,9 +294,9 @@ type schemaParams struct {
 }
 
 // NewStoreManager creates a new StoreManager.
-func NewStoreManager(ctx context.Context, db *sqlitex.Pool, config config.LogsMachineStorage, omniState state.State, logger *zap.Logger) (*StoreManager, error) {
+func NewStoreManager(ctx context.Context, db *sqlitex.Pool, config config.LogsMachineStorage, omniState state.State, logger *zap.Logger, opts ...StoreManagerOption) (*StoreManager, error) {
 	templateParams := schemaParams{
-		TableName:       tableName,
+		TableName:       TableName,
 		IDColumn:        idColumn,
 		MachineIDColumn: machineIDColumn,
 		MessageColumn:   messageColumn,
@@ -306,15 +327,26 @@ func NewStoreManager(ctx context.Context, db *sqlitex.Pool, config config.LogsMa
 		return nil, fmt.Errorf("failed to create sqlite log table schema: %w", err)
 	}
 
-	return &StoreManager{
+	mgr := &StoreManager{
 		config: config,
 		db:     db,
 		state:  omniState,
 		logger: logger,
-	}, nil
+	}
+
+	for _, opt := range opts {
+		opt(mgr)
+	}
+
+	return mgr, nil
 }
 
 // Create implements the LogStoreManager interface.
 func (m *StoreManager) Create(id string) (logstore.LogStore, error) {
-	return NewStore(m.config, m.db, id, m.logger)
+	var opts []StoreOption
+	if m.onCleanup != nil {
+		opts = append(opts, WithStoreCleanupCallback(m.onCleanup))
+	}
+
+	return NewStore(m.config, m.db, id, m.logger, opts...)
 }
diff --git a/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog.go b/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog.go
index d744de96..bcb0cc3c 100644
--- a/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog.go
+++ b/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog.go
@@ -3,6 +3,7 @@
 // Use of this software is governed by the Business Source License
 // included in the LICENSE file.
 
+// Package sqlitelog implements a logstore.LogStore using SQLite as the backend.
 package sqlitelog
 
 import (
@@ -41,8 +42,18 @@ const (
 	messageMaxLength = 16 * 1024 // 16 KB
 )
 
+// StoreOption configures optional Store behavior.
+type StoreOption func(*Store)
+
+// WithStoreCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithStoreCleanupCallback(cb func(int)) StoreOption {
+	return func(s *Store) {
+		s.onCleanup = cb
+	}
+}
+
 // NewStore creates a new Store.
-func NewStore(config config.LogsMachineStorage, db *sqlitex.Pool, id string, logger *zap.Logger) (*Store, error) {
+func NewStore(config config.LogsMachineStorage, db *sqlitex.Pool, id string, logger *zap.Logger, opts ...StoreOption) (*Store, error) {
 	sqliteTimeout := config.GetSqliteTimeout()
 	if sqliteTimeout <= 0 {
 		sqliteTimeout = 30 * time.Second
@@ -56,6 +67,10 @@ func NewStore(config config.LogsMachineStorage, db *sqlitex.Pool, id string, log
 		sqliteTimeout: sqliteTimeout,
 	}
 
+	for _, opt := range opts {
+		opt(s)
+	}
+
 	return s, nil
 }
 
@@ -64,6 +79,7 @@ type Store struct {
 	config        config.LogsMachineStorage
 	db            *sqlitex.Pool
 	logger        *zap.Logger
+	onCleanup     func(int)
 	id            string
 	subscribers   []chan struct{}
 	mu            sync.Mutex
@@ -93,7 +109,7 @@ func (s *Store) WriteLine(ctx context.Context, message []byte) error {
 
 		defer s.db.Put(conn)
 
-		query := fmt.Sprintf(`INSERT INTO %s (%s, %s, %s) VALUES ($machine_id, $message, $created_at)`, tableName, machineIDColumn, messageColumn, createdAtColumn)
+		query := fmt.Sprintf(`INSERT INTO %s (%s, %s, %s) VALUES ($machine_id, $message, $created_at)`, TableName, machineIDColumn, messageColumn, createdAtColumn)
 
 		q, err := sqlitexx.NewQuery(conn, query)
 		if err != nil {
@@ -146,7 +162,7 @@ func (s *Store) doCleanup(ctx context.Context) error {
 
 	// find the cutoff ID
 	query := fmt.Sprintf("SELECT COALESCE(MAX(%s), 0) FROM (SELECT %s FROM %s WHERE %s = $machine_id ORDER BY %s DESC LIMIT 1 OFFSET $max_lines)",
-		idColumn, idColumn, tableName, machineIDColumn, idColumn)
+		idColumn, idColumn, TableName, machineIDColumn, idColumn)
 
 	var cutoffID int64
 
@@ -168,7 +184,7 @@ func (s *Store) doCleanup(ctx context.Context) error {
 	}
 
 	// delete logs older than cutoff ID
-	delQuery := fmt.Sprintf("DELETE FROM %s WHERE %s = $machine_id AND %s <= $cutoff_id", tableName, machineIDColumn, idColumn)
+	delQuery := fmt.Sprintf("DELETE FROM %s WHERE %s = $machine_id AND %s <= $cutoff_id", TableName, machineIDColumn, idColumn)
 
 	q, err = sqlitexx.NewQuery(conn, delQuery)
 	if err != nil {
@@ -184,6 +200,11 @@ func (s *Store) doCleanup(ctx context.Context) error {
 	}
 
 	numRowsDeleted := conn.Changes()
+
+	if s.onCleanup != nil {
+		s.onCleanup(numRowsDeleted)
+	}
+
 	s.logger.Debug("deleted old logs", zap.Int("num_rows_deleted", numRowsDeleted))
 
 	return nil
@@ -406,7 +427,7 @@ func (s *Store) readerRows(ctx context.Context, nLines int) (*zombiesqlite.Conn,
 		return nil, nil, nil, fmt.Errorf("failed to determine start ID: %w", err)
 	}
 
-	query := fmt.Sprintf("SELECT %s, %s FROM %s WHERE %s = $machine_id AND %s >= $start_id ORDER BY %s ASC", idColumn, messageColumn, tableName, machineIDColumn, idColumn, idColumn)
+	query := fmt.Sprintf("SELECT %s, %s FROM %s WHERE %s = $machine_id AND %s >= $start_id ORDER BY %s ASC", idColumn, messageColumn, TableName, machineIDColumn, idColumn, idColumn)
 
 	q, err := sqlitexx.NewQuery(conn, query)
 	if err != nil {
@@ -427,7 +448,7 @@ func (s *Store) readerRows(ctx context.Context, nLines int) (*zombiesqlite.Conn,
 
 func (s *Store) readerRowsAfter(conn *zombiesqlite.Conn, lastLogID int64) (func() (*zombiesqlite.Stmt, error, bool), func(), error) {
 	query := fmt.Sprintf("SELECT %s, %s FROM %s WHERE %s = $machine_id AND %s > $last_log_id ORDER BY %s ASC",
-		idColumn, messageColumn, tableName, machineIDColumn, idColumn, idColumn)
+		idColumn, messageColumn, TableName, machineIDColumn, idColumn, idColumn)
 
 	q, err := sqlitexx.NewQuery(conn, query)
 	if err != nil {
@@ -451,7 +472,7 @@ func (s *Store) readerStartID(conn *zombiesqlite.Conn, nLines int) (int64, error
 
 	// Do COALESCE to return 0 if there are no logs for the machine
 	query := fmt.Sprintf("SELECT COALESCE(MIN(id), 0) FROM (SELECT %s AS id FROM %s WHERE %s = $machine_id ORDER BY %s DESC LIMIT $limit)",
-		idColumn, tableName, machineIDColumn, idColumn)
+		idColumn, TableName, machineIDColumn, idColumn)
 
 	var startID int64
 
@@ -476,7 +497,7 @@ func (s *Store) readerStartID(conn *zombiesqlite.Conn, nLines int) (int64, error
 }
 
 func (s *Store) currentMaxID(ctx context.Context) (int64, error) {
-	query := fmt.Sprintf("SELECT COALESCE(MAX(%s), 0) FROM %s WHERE %s = $machine_id", idColumn, tableName, machineIDColumn)
+	query := fmt.Sprintf("SELECT COALESCE(MAX(%s), 0) FROM %s WHERE %s = $machine_id", idColumn, TableName, machineIDColumn)
 
 	ctx, cancel := context.WithTimeout(ctx, s.sqliteTimeout)
 	defer cancel()
diff --git a/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog_test.go b/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog_test.go
index 5d08fc4f..3df2e85b 100644
--- a/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog_test.go
+++ b/internal/pkg/siderolink/logstore/sqlitelog/sqlitelog_test.go
@@ -45,7 +45,13 @@ func TestReadWrite(t *testing.T) {
 	t.Cleanup(cancel)
 
 	logger := zaptest.NewLogger(t)
-	storeManager, _ := setupDB(ctx, t, logger)
+
+	// Disable cleanup to avoid connection pool contention between
+	// writers and cleanup queries. Cleanup correctness is covered by TestCleanupProbabilities.
+	storageConf := config.Default().Logs.Machine.Storage
+	storageConf.SetCleanupProbability(0)
+
+	storeManager, _ := setupDBWithStorageConfig(ctx, t, logger, storageConf)
 
 	sqliteStore1, err := storeManager.Create("test-1")
 	require.NoError(t, err)
@@ -61,10 +67,6 @@ func TestReadWrite(t *testing.T) {
 		require.NoError(t, sqliteStore2.Close())
 	})
 
-	t.Cleanup(func() {
-		require.NoError(t, sqliteStore1.Close())
-	})
-
 	defaultConfig := config.Default()
 
 	compressor, err := zstd.NewCompressor()
@@ -399,11 +401,18 @@ func TestFollowTail(t *testing.T) {
 func TestFollowRapidWrites(t *testing.T) {
 	t.Parallel()
 
-	ctx, cancel := context.WithTimeout(t.Context(), 15*time.Second)
+	ctx, cancel := context.WithTimeout(t.Context(), 30*time.Second)
 	t.Cleanup(cancel)
 
 	logger := zaptest.NewLogger(t)
-	storeManager, _ := setupDB(ctx, t, logger)
+
+	// Use a config with cleanup disabled to avoid connection pool contention
+	// between the writer, reader, and cleanup queries. Cleanup correctness
+	// is covered by TestCleanupProbabilities.
+	storageConf := config.Default().Logs.Machine.Storage
+	storageConf.SetCleanupProbability(0)
+
+	storeManager, _ := setupDBWithStorageConfig(ctx, t, logger, storageConf)
 	store, err := storeManager.Create("rapid-writes")
 	require.NoError(t, err)
 
@@ -688,6 +697,12 @@ func assertLine(ctx context.Context, t *testing.T, lineCh <-chan string, expecte
 func setupDB(ctx context.Context, t *testing.T, logger *zap.Logger) (*sqlitelog.StoreManager, state.State) {
 	t.Helper()
 
+	return setupDBWithStorageConfig(ctx, t, logger, config.Default().Logs.Machine.Storage)
+}
+
+func setupDBWithStorageConfig(ctx context.Context, t *testing.T, logger *zap.Logger, storageConf config.LogsMachineStorage) (*sqlitelog.StoreManager, state.State) {
+	t.Helper()
+
 	path := filepath.Join(t.TempDir(), "test.db")
 	conf := config.Default().Storage.Sqlite
 	conf.SetPath(path)
@@ -701,7 +716,7 @@ func setupDB(ctx context.Context, t *testing.T, logger *zap.Logger) (*sqlitelog.
 
 	state := state.WrapCore(namespaced.NewState(inmem.Build))
 
-	storeManager, err := sqlitelog.NewStoreManager(ctx, db, config.Default().Logs.Machine.Storage, state, logger)
+	storeManager, err := sqlitelog.NewStoreManager(ctx, db, storageConf, state, logger)
 	require.NoError(t, err)
 
 	return storeManager, state
diff --git a/internal/pkg/siderolink/machines.go b/internal/pkg/siderolink/machines.go
index 6aa62603..2da7c0ae 100644
--- a/internal/pkg/siderolink/machines.go
+++ b/internal/pkg/siderolink/machines.go
@@ -31,11 +31,22 @@ import (
 // ErrLogStoreNotFound is returned when the log store for a machine is not found.
 var ErrLogStoreNotFound = errors.New("log store not found")
 
+// MachineCacheOption configures optional MachineCache behavior.
+type MachineCacheOption func(*MachineCache)
+
+// WithMachineCacheCleanupCallback sets a callback that is called after cleanup with the number of deleted rows.
+func WithMachineCacheCleanupCallback(cb func(int)) MachineCacheOption {
+	return func(m *MachineCache) {
+		m.onCleanup = cb
+	}
+}
+
 // MachineCache stores a map of machines to their circular log stores. It also allows to access the log stores using the machine IP.
 type MachineCache struct {
 	machineLogStoreManager LogStoreManager
 	machineLogStores       map[MachineID]logstore.LogStore
 	logger                 *zap.Logger
+	onCleanup              func(int)
 	logsConfig             *config.LogsMachine
 	compressor             *zstd.Compressor
 	secondaryStorageDB     *sqlitex.Pool
@@ -45,19 +56,25 @@ type MachineCache struct {
 }
 
 // NewMachineCache returns a new MachineCache.
-func NewMachineCache(secondaryStorageDB *sqlitex.Pool, logStorageConfig *config.LogsMachine, omniState state.State, logger *zap.Logger) (*MachineCache, error) {
+func NewMachineCache(secondaryStorageDB *sqlitex.Pool, logStorageConfig *config.LogsMachine, omniState state.State, logger *zap.Logger, opts ...MachineCacheOption) (*MachineCache, error) {
 	compressor, err := zstd.NewCompressor()
 	if err != nil {
 		return nil, fmt.Errorf("failed to create log compressor: %w", err)
 	}
 
-	return &MachineCache{
+	cache := &MachineCache{
 		logsConfig:         logStorageConfig,
 		compressor:         compressor,
 		secondaryStorageDB: secondaryStorageDB,
 		state:              omniState,
 		logger:             logger,
-	}, nil
+	}
+
+	for _, opt := range opts {
+		opt(cache)
+	}
+
+	return cache, nil
 }
 
 // Run starts the side tasks required by the MachineCache.
@@ -191,7 +208,12 @@ func (m *MachineCache) init(ctx context.Context) error {
 		return nil
 	}
 
-	sqliteLogStoreManager, err := sqlitelog.NewStoreManager(ctx, m.secondaryStorageDB, m.logsConfig.Storage, m.state, m.logger)
+	var storeManagerOpts []sqlitelog.StoreManagerOption
+	if m.onCleanup != nil {
+		storeManagerOpts = append(storeManagerOpts, sqlitelog.WithCleanupCallback(m.onCleanup))
+	}
+
+	sqliteLogStoreManager, err := sqlitelog.NewStoreManager(ctx, m.secondaryStorageDB, m.logsConfig.Storage, m.state, m.logger, storeManagerOpts...)
 	if err != nil {
 		return fmt.Errorf("failed to create sqlite log store manager: %w", err)
 	}
diff --git a/internal/pkg/siderolink/provision_test.go b/internal/pkg/siderolink/provision_test.go
index 910bbace..c5cf3889 100644
--- a/internal/pkg/siderolink/provision_test.go
+++ b/internal/pkg/siderolink/provision_test.go
@@ -19,7 +19,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/inmem"
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	"github.com/google/uuid"
-	"github.com/siderolabs/go-pointer"
 	pb "github.com/siderolabs/siderolink/api/siderolink"
 	"github.com/siderolabs/siderolink/pkg/wireguard"
 	"github.com/stretchr/testify/assert"
@@ -166,8 +165,8 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:      "machine-1",
 			NodePublicKey: genKey(),
-			TalosVersion:  pointer.To("v1.9.0"),
-			JoinToken:     pointer.To(validToken),
+			TalosVersion:  new("v1.9.0"),
+			JoinToken:     new(validToken),
 		}
 
 		response, err := provisionHandler.Provision(ctx, request)
@@ -184,7 +183,7 @@ func TestProvision(t *testing.T) {
 		require.NotEmpty(t, response.ServerPublicKey)
 		require.NotEmpty(t, response.NodeAddressPrefix)
 
-		request.NodeUniqueToken = pointer.To(validToken)
+		request.NodeUniqueToken = new(validToken)
 
 		response, err = provisionHandler.Provision(ctx, request)
 		require.NoError(t, err)
@@ -233,8 +232,8 @@ func TestProvision(t *testing.T) {
 			request := &pb.ProvisionRequest{
 				NodeUuid:      fmt.Sprintf("machine-migration-%s", tt.name),
 				NodePublicKey: genKey(),
-				TalosVersion:  pointer.To("v1.9.0"),
-				JoinToken:     pointer.To(tt.token),
+				TalosVersion:  new("v1.9.0"),
+				JoinToken:     new(tt.token),
 			}
 
 			link := siderolinkres.NewLink(request.NodeUuid, &specs.SiderolinkSpec{
@@ -298,9 +297,9 @@ func TestProvision(t *testing.T) {
 				name: "same fingerprint, valid join token, talos installed",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(validFingerprintOnly),
-					TalosVersion:    pointer.To("v1.6.0"),
-					JoinToken:       pointer.To(validToken),
+					NodeUniqueToken: new(validFingerprintOnly),
+					TalosVersion:    new("v1.6.0"),
+					JoinToken:       new(validToken),
 				},
 				linkSpec:        &specs.SiderolinkSpec{},
 				nodeUniqueToken: validToken,
@@ -313,9 +312,9 @@ func TestProvision(t *testing.T) {
 				name: "same fingerprint, valid join token, talos not installed",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(validFingerprintOnly),
-					TalosVersion:    pointer.To("v1.6.0"),
-					JoinToken:       pointer.To(validToken),
+					NodeUniqueToken: new(validFingerprintOnly),
+					TalosVersion:    new("v1.6.0"),
+					JoinToken:       new(validToken),
 				},
 				talosNotInstalled: true,
 				linkSpec:          &specs.SiderolinkSpec{},
@@ -328,8 +327,8 @@ func TestProvision(t *testing.T) {
 				name: "sa %#vme fingerprint, in, provisionContext.requestNodeUniqueTokenvalid join token, talos not installed",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(validFingerprintOnly),
-					TalosVersion:    pointer.To("v1.6.0"),
+					NodeUniqueToken: new(validFingerprintOnly),
+					TalosVersion:    new("v1.6.0"),
 				},
 				talosNotInstalled: true,
 				nodeUniqueToken:   validToken,
@@ -342,8 +341,8 @@ func TestProvision(t *testing.T) {
 				name: "no join token, valid node token, has link",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(validToken),
-					TalosVersion:    pointer.To("v1.6.0"),
+					NodeUniqueToken: new(validToken),
+					TalosVersion:    new("v1.6.0"),
 				},
 				nodeUniqueToken: validToken,
 				linkSpec:        &specs.SiderolinkSpec{},
@@ -355,8 +354,8 @@ func TestProvision(t *testing.T) {
 				name: "no join token, valid node token, no link",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(validToken),
-					TalosVersion:    pointer.To("v1.6.0"),
+					NodeUniqueToken: new(validToken),
+					TalosVersion:    new("v1.6.0"),
 				},
 				nodeUniqueToken: validToken,
 				errcheck: func(t *testing.T, err error) {
@@ -367,9 +366,9 @@ func TestProvision(t *testing.T) {
 				name: "valid join token, invalid node token",
 				request: &pb.ProvisionRequest{
 					NodePublicKey:   genKey(),
-					NodeUniqueToken: pointer.To(invalidToken),
-					TalosVersion:    pointer.To("v1.9.0"),
-					JoinToken:       pointer.To(validToken),
+					NodeUniqueToken: new(invalidToken),
+					TalosVersion:    new("v1.9.0"),
+					JoinToken:       new(validToken),
 				},
 				nodeUniqueToken: validToken,
 				errcheck: func(t *testing.T, err error) {
@@ -380,8 +379,8 @@ func TestProvision(t *testing.T) {
 				name: "migration",
 				request: &pb.ProvisionRequest{
 					NodePublicKey: genKey(),
-					TalosVersion:  pointer.To("v1.9.0"),
-					JoinToken:     pointer.To(validToken),
+					TalosVersion:  new("v1.9.0"),
+					JoinToken:     new(validToken),
 				},
 				linkSpec: &specs.SiderolinkSpec{},
 				errcheck: func(t *testing.T, err error) {
@@ -392,8 +391,8 @@ func TestProvision(t *testing.T) {
 				name: "initial join",
 				request: &pb.ProvisionRequest{
 					NodePublicKey: genKey(),
-					TalosVersion:  pointer.To("v1.9.0"),
-					JoinToken:     pointer.To(validToken),
+					TalosVersion:  new("v1.9.0"),
+					JoinToken:     new(validToken),
 				},
 				errcheck: func(t *testing.T, err error) {
 					require.NoError(t, err)
@@ -403,7 +402,7 @@ func TestProvision(t *testing.T) {
 				name: "initial join, no valid token",
 				request: &pb.ProvisionRequest{
 					NodePublicKey: genKey(),
-					TalosVersion:  pointer.To("v1.9.0"),
+					TalosVersion:  new("v1.9.0"),
 				},
 				errcheck: func(t *testing.T, err error) {
 					require.Equal(t, codes.PermissionDenied, status.Code(err))
@@ -413,7 +412,7 @@ func TestProvision(t *testing.T) {
 				name: "below 1.6",
 				request: &pb.ProvisionRequest{
 					NodePublicKey: genKey(),
-					TalosVersion:  pointer.To("v1.4.0"),
+					TalosVersion:  new("v1.4.0"),
 					JoinToken:     &validToken,
 				},
 				errcheck: func(t *testing.T, err error) {
@@ -430,7 +429,7 @@ func TestProvision(t *testing.T) {
 				name: "below 1.6, no token",
 				request: &pb.ProvisionRequest{
 					NodePublicKey: genKey(),
-					TalosVersion:  pointer.To("v1.4.0"),
+					TalosVersion:  new("v1.4.0"),
 				},
 				errcheck: func(t *testing.T, err error) {
 					if mode.mode == config.SiderolinkServiceJoinTokensModeLegacyAllowed {
@@ -489,8 +488,8 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:      "machine-legacy",
 			NodePublicKey: genKey(),
-			TalosVersion:  pointer.To("v1.5.0"),
-			JoinToken:     pointer.To(validToken),
+			TalosVersion:  new("v1.5.0"),
+			JoinToken:     new(validToken),
 		}
 
 		link := siderolinkres.NewLink(request.NodeUuid, &specs.SiderolinkSpec{})
@@ -520,8 +519,8 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:      "machine-legacy",
 			NodePublicKey: genKey(),
-			TalosVersion:  pointer.To("v1.5.0"),
-			JoinToken:     pointer.To(validToken),
+			TalosVersion:  new("v1.5.0"),
+			JoinToken:     new(validToken),
 		}
 
 		link := siderolinkres.NewLink(request.NodeUuid, &specs.SiderolinkSpec{})
@@ -551,9 +550,9 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:        "so-duplicate",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
-			JoinToken:       pointer.To(validToken),
-			NodeUniqueToken: pointer.To(uniqueToken),
+			TalosVersion:    new("v1.9.4"),
+			JoinToken:       new(validToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request)
@@ -565,9 +564,9 @@ func TestProvision(t *testing.T) {
 		request2 := &pb.ProvisionRequest{
 			NodeUuid:        "so-duplicate",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
-			JoinToken:       pointer.To(validToken),
-			NodeUniqueToken: pointer.To(uniqueToken),
+			TalosVersion:    new("v1.9.4"),
+			JoinToken:       new(validToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request2)
@@ -610,9 +609,9 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:        "machine-from-provider",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
+			TalosVersion:    new("v1.9.4"),
 			JoinToken:       &encoded,
-			NodeUniqueToken: pointer.To(uniqueToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request)
@@ -666,9 +665,9 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:        "machine-from-provider",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
+			TalosVersion:    new("v1.9.4"),
 			JoinToken:       &encoded,
-			NodeUniqueToken: pointer.To(uniqueToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request)
@@ -718,9 +717,9 @@ func TestProvision(t *testing.T) {
 		request := &pb.ProvisionRequest{
 			NodeUuid:        "machine-from-provider",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
+			TalosVersion:    new("v1.9.4"),
 			JoinToken:       &encoded,
-			NodeUniqueToken: pointer.To(uniqueToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request)
@@ -738,9 +737,9 @@ func TestProvision(t *testing.T) {
 		request = &pb.ProvisionRequest{
 			NodeUuid:        "machine-from-provider",
 			NodePublicKey:   genKey(),
-			TalosVersion:    pointer.To("v1.9.4"),
+			TalosVersion:    new("v1.9.4"),
 			JoinToken:       &encoded,
-			NodeUniqueToken: pointer.To(uniqueToken),
+			NodeUniqueToken: new(uniqueToken),
 		}
 
 		_, err = provisionHandler.Provision(ctx, request)
diff --git a/internal/pkg/siderolink/siderolink_test.go b/internal/pkg/siderolink/siderolink_test.go
index d3c6e5f1..0225ecdf 100644
--- a/internal/pkg/siderolink/siderolink_test.go
+++ b/internal/pkg/siderolink/siderolink_test.go
@@ -23,7 +23,6 @@ import (
 	"github.com/cosi-project/runtime/pkg/state/impl/namespaced"
 	xmaps "github.com/siderolabs/gen/maps"
 	"github.com/siderolabs/gen/xtesting/must"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/go-retry/retry"
 	pb "github.com/siderolabs/siderolink/api/siderolink"
 	"github.com/siderolabs/siderolink/pkg/wireguard"
@@ -132,7 +131,7 @@ func (suite *SiderolinkSuite) SetupTest() {
 
 	suite.Require().NoError(err)
 
-	suite.nodeUniqueToken = pointer.To(nodeUniqueToken)
+	suite.nodeUniqueToken = new(nodeUniqueToken)
 
 	wgHandler := &fakeWireguardHandler{
 		peers: map[string]wgtypes.Peer{},
@@ -243,7 +242,7 @@ func (suite *SiderolinkSuite) TestNodes() {
 		NodeUuid:        "testnode",
 		NodePublicKey:   privateKey.PublicKey().String(),
 		JoinToken:       &joinToken,
-		TalosVersion:    pointer.To("v1.9.0"),
+		TalosVersion:    new("v1.9.0"),
 		NodeUniqueToken: suite.nodeUniqueToken,
 	})
 
@@ -274,7 +273,7 @@ func (suite *SiderolinkSuite) TestNodes() {
 		NodeUuid:        "testnode",
 		NodePublicKey:   privateKey.PublicKey().String(),
 		JoinToken:       &joinToken,
-		TalosVersion:    pointer.To("v1.9.0"),
+		TalosVersion:    new("v1.9.0"),
 		NodeUniqueToken: suite.nodeUniqueToken,
 	})
 
@@ -288,7 +287,7 @@ func (suite *SiderolinkSuite) TestNodes() {
 		NodeUuid:        "testnode",
 		NodePublicKey:   privateKey.PublicKey().String(),
 		JoinToken:       &joinToken,
-		TalosVersion:    pointer.To("v1.9.0"),
+		TalosVersion:    new("v1.9.0"),
 		NodeUniqueToken: suite.nodeUniqueToken,
 	})
 
@@ -328,7 +327,7 @@ func (suite *SiderolinkSuite) TestNodeWithSeveralAdvertisedIPs() {
 			NodeUuid:        "testnode",
 			NodePublicKey:   privateKey.PublicKey().String(),
 			JoinToken:       &spec.TokenId,
-			TalosVersion:    pointer.To("v1.9.0"),
+			TalosVersion:    new("v1.9.0"),
 			NodeUniqueToken: suite.nodeUniqueToken,
 		},
 	))(suite.T())
@@ -377,8 +376,8 @@ func (suite *SiderolinkSuite) TestVirtualNodes() {
 		NodeUuid:          "testnode",
 		NodePublicKey:     privateKey.PublicKey().String(),
 		JoinToken:         &joinToken,
-		WireguardOverGrpc: pointer.To(true),
-		TalosVersion:      pointer.To("v1.9.0"),
+		WireguardOverGrpc: new(true),
+		TalosVersion:      new("v1.9.0"),
 		NodeUniqueToken:   suite.nodeUniqueToken,
 	})
 
@@ -413,7 +412,7 @@ func (suite *SiderolinkSuite) TestVirtualNodes() {
 		NodeUuid:        "testnode",
 		NodePublicKey:   privateKey.PublicKey().String(),
 		JoinToken:       &joinToken,
-		TalosVersion:    pointer.To("v1.9.0"),
+		TalosVersion:    new("v1.9.0"),
 		NodeUniqueToken: suite.nodeUniqueToken,
 	})
 
@@ -432,7 +431,7 @@ func (suite *SiderolinkSuite) TestVirtualNodes() {
 		NodeUuid:        "testnode",
 		NodePublicKey:   privateKey.PublicKey().String(),
 		JoinToken:       &joinToken,
-		TalosVersion:    pointer.To("v1.9.0"),
+		TalosVersion:    new("v1.9.0"),
 		NodeUniqueToken: suite.nodeUniqueToken,
 	})
 
@@ -448,8 +447,8 @@ func (suite *SiderolinkSuite) TestVirtualNodes() {
 		NodeUuid:          "testnode",
 		NodePublicKey:     privateKey.PublicKey().String(),
 		JoinToken:         &joinToken,
-		WireguardOverGrpc: pointer.To(true),
-		TalosVersion:      pointer.To("v1.9.0"),
+		WireguardOverGrpc: new(true),
+		TalosVersion:      new("v1.9.0"),
 		NodeUniqueToken:   suite.nodeUniqueToken,
 	})
 
diff --git a/internal/pkg/siderolink/wireguard.go b/internal/pkg/siderolink/wireguard.go
index ed39e305..36ffa431 100644
--- a/internal/pkg/siderolink/wireguard.go
+++ b/internal/pkg/siderolink/wireguard.go
@@ -11,7 +11,6 @@ import (
 	"net/netip"
 
 	"github.com/siderolabs/gen/channel"
-	"github.com/siderolabs/go-pointer"
 	"github.com/siderolabs/siderolink/pkg/wireguard"
 	"go.uber.org/zap"
 	"golang.zx2c4.com/wireguard/wgctrl/wgtypes"
@@ -63,7 +62,7 @@ func (handler *PhysicalWireguardHandler) PeerEvent(ctx context.Context, spec *sp
 		Remove:                      deleted,
 		Endpoint:                    spec.LastEndpoint,
 		Address:                     address.Addr(),
-		PersistentKeepAliveInterval: pointer.To(wireguard.RecommendedPersistentKeepAliveInterval),
+		PersistentKeepAliveInterval: new(wireguard.RecommendedPersistentKeepAliveInterval),
 		VirtualAddr:                 virtualAddrPort.Addr(),
 	})
 
